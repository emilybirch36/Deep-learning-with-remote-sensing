{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "behavioral-panama",
   "metadata": {},
   "source": [
    "# Building EO training/validation/testing datasets with the Sentinelhub API"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "presidential-developer",
   "metadata": {},
   "source": [
    "#### The following modules/Libraries will be needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "9f5ea95e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentinelhub import BBox, CRS, DataCollection, SHConfig, WmsRequest, WcsRequest, DataSource, MimeType\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from datetime import date, timedelta\n",
    "from scipy.ndimage.filters import uniform_filter\n",
    "from scipy.ndimage.measurements import variance\n",
    "import rasterio\n",
    "import numpy as np\n",
    "import datetime\n",
    "\n",
    "import os \n",
    "from osgeo import gdal\n",
    "import glob\n",
    "\n",
    "import imageio\n",
    "\n",
    "from PIL import Image\n",
    "import io\n",
    "\n",
    "from rasterio.transform import from_bounds\n",
    "\n",
    "\n",
    "from matplotlib import pyplot\n",
    "from rasterio.plot import show"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "funny-nashville",
   "metadata": {},
   "source": [
    "### Prerequisites\n",
    "\n",
    "#### Sentinel Hub account\n",
    "\n",
    "In order to use Sentinel Hub services you will need a Sentinel Hub account. If you do not have one yet, you can create a free trial account at [Sentinel Hub webpage](https://services.sentinel-hub.com/oauth/subscription). If you are a researcher you can even apply for a free non-commercial account at [ESA OSEO page](https://earth.esa.int/aos/OSEO).\n",
    "\n",
    "Once you have the account set up, login to [Sentinel Hub Configurator](https://apps.sentinel-hub.com/configurator/). Inside there will already exist one configuration with an **instance ID** (alpha-numeric code of length 36). For this tutorial it is recommended that you create a new configuration (`\"Add new configuration\"`) and set the configuration to be based on **Python scripts template**. Such configuration will already contain all layers used in these examples. Otherwise you will have to define the layers for your  configuration yourself.\n",
    "\n",
    "After you have decided which configuration to use, you have two options. You can either put configuration's **instance ID** into `sentinelhub` package's configuration file following the [configuration instructions](http://sentinelhub-py.readthedocs.io/en/latest/configure.html) or you can write it down in the following cell:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "boolean-chancellor",
   "metadata": {},
   "source": [
    "Generate a configuration:\n",
    "This is done using the ID.\n",
    "This is so that sentinelhub knows you are authorised to use their service, and which parts of the service you want to use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "coral-conjunction",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"instance_id\": \"216732ac-7e0c-46f0-a5f8-243652a55bfb\",\n",
      "  \"sh_client_id\": \"\",\n",
      "  \"sh_client_secret\": \"\",\n",
      "  \"sh_base_url\": \"https://services.sentinel-hub.com\",\n",
      "  \"geopedia_wms_url\": \"https://service.geopedia.world\",\n",
      "  \"geopedia_rest_url\": \"https://www.geopedia.world/rest\",\n",
      "  \"aws_access_key_id\": \"\",\n",
      "  \"aws_secret_access_key\": \"\",\n",
      "  \"aws_metadata_url\": \"https://roda.sentinel-hub.com\",\n",
      "  \"aws_s3_l1c_bucket\": \"sentinel-s2-l1c\",\n",
      "  \"aws_s3_l2a_bucket\": \"sentinel-s2-l2a\",\n",
      "  \"opensearch_url\": \"http://opensearch.sentinel-hub.com/resto/api/collections/Sentinel2\",\n",
      "  \"max_wfs_records_per_query\": 100,\n",
      "  \"max_opensearch_records_per_query\": 500,\n",
      "  \"max_download_attempts\": 4,\n",
      "  \"download_sleep_time\": 5,\n",
      "  \"download_timeout_seconds\": 120,\n",
      "  \"number_of_download_processes\": 1\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "INSTANCE_ID = '216732ac-7e0c-46f0-a5f8-243652a55bfb'\n",
    "if INSTANCE_ID:\n",
    "    config = SHConfig()\n",
    "    config.instance_id = INSTANCE_ID\n",
    "else:\n",
    "    config = None\n",
    "\n",
    "print(config)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "virtual-civilization",
   "metadata": {},
   "source": [
    "Define a region and a random test date "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "1036f3f3",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time_from 2016-01-01\n",
      "time_to 2017-01-01\n",
      "WCS:  <sentinelhub.data_request.WcsRequest object at 0x7faca93bb090>\n",
      "avail dates list:  []\n",
      "time_from 2017-01-01\n",
      "time_to 2018-01-01\n",
      "WCS:  <sentinelhub.data_request.WcsRequest object at 0x7fac68752e90>\n",
      "avail dates list:  [datetime.datetime(2017, 9, 29, 18, 41, 58)]\n",
      "date 2017-09-29 18:41:58\n",
      "TYPE OF B08: <class 'numpy.ndarray'>\n",
      "(2214, 2474)\n",
      "height 2214\n",
      "width 2474\n",
      "TRANSFORM: | 0.00, 0.00,-116.09|\n",
      "| 0.00,-0.00, 51.03|\n",
      "| 0.00, 0.00, 1.00|\n",
      "OUT PATH b08_can_bbox1_1.tif\n",
      "Writing...b08_can_bbox1_1.tif\n",
      "None\n",
      "Returned data is of type = <class 'numpy.ndarray'> and length 2214.\n",
      "Single element in the list is of type <class 'numpy.ndarray'> and has shape (2474, 4)\n",
      "time_from 2018-01-01\n",
      "time_to 2019-01-01\n",
      "WCS:  <sentinelhub.data_request.WcsRequest object at 0x7fac583a9990>\n",
      "avail dates list:  [datetime.datetime(2018, 7, 16, 18, 39, 27), datetime.datetime(2018, 8, 10, 18, 41, 41)]\n",
      "date 2018-07-16 18:39:27\n",
      "TYPE OF B08: <class 'numpy.ndarray'>\n",
      "(2214, 2474)\n",
      "height 2214\n",
      "width 2474\n",
      "TRANSFORM: | 0.00, 0.00,-116.09|\n",
      "| 0.00,-0.00, 51.03|\n",
      "| 0.00, 0.00, 1.00|\n",
      "OUT PATH b08_can_bbox1_2.tif\n",
      "Writing...b08_can_bbox1_2.tif\n",
      "None\n",
      "Returned data is of type = <class 'numpy.ndarray'> and length 2214.\n",
      "Single element in the list is of type <class 'numpy.ndarray'> and has shape (2474, 4)\n",
      "date 2018-08-10 18:41:41\n",
      "TYPE OF B08: <class 'numpy.ndarray'>\n",
      "(2214, 2474)\n",
      "height 2214\n",
      "width 2474\n",
      "TRANSFORM: | 0.00, 0.00,-116.09|\n",
      "| 0.00,-0.00, 51.03|\n",
      "| 0.00, 0.00, 1.00|\n",
      "OUT PATH b08_can_bbox1_3.tif\n",
      "Writing...b08_can_bbox1_3.tif\n",
      "None\n",
      "Returned data is of type = <class 'numpy.ndarray'> and length 2214.\n",
      "Single element in the list is of type <class 'numpy.ndarray'> and has shape (2474, 4)\n",
      "time_from 2019-01-01\n",
      "time_to 2020-01-01\n",
      "WCS:  <sentinelhub.data_request.WcsRequest object at 0x7fac68752a50>\n",
      "avail dates list:  [datetime.datetime(2019, 8, 20, 18, 50, 23)]\n",
      "date 2019-08-20 18:50:23\n",
      "TYPE OF B08: <class 'numpy.ndarray'>\n",
      "(2214, 2474)\n",
      "height 2214\n",
      "width 2474\n",
      "TRANSFORM: | 0.00, 0.00,-116.09|\n",
      "| 0.00,-0.00, 51.03|\n",
      "| 0.00, 0.00, 1.00|\n",
      "OUT PATH b08_can_bbox1_4.tif\n",
      "Writing...b08_can_bbox1_4.tif\n",
      "None\n",
      "Returned data is of type = <class 'numpy.ndarray'> and length 2214.\n",
      "Single element in the list is of type <class 'numpy.ndarray'> and has shape (2474, 4)\n",
      "time_from 2020-01-01\n",
      "time_to 2021-01-01\n",
      "WCS:  <sentinelhub.data_request.WcsRequest object at 0x7faca95a2d90>\n",
      "avail dates list:  [datetime.datetime(2020, 10, 3, 18, 50, 21)]\n",
      "date 2020-10-03 18:50:21\n",
      "TYPE OF B08: <class 'numpy.ndarray'>\n",
      "(2214, 2474)\n",
      "height 2214\n",
      "width 2474\n",
      "TRANSFORM: | 0.00, 0.00,-116.09|\n",
      "| 0.00,-0.00, 51.03|\n",
      "| 0.00, 0.00, 1.00|\n",
      "OUT PATH b08_can_bbox1_5.tif\n",
      "Writing...b08_can_bbox1_5.tif\n",
      "None\n",
      "Returned data is of type = <class 'numpy.ndarray'> and length 2214.\n",
      "Single element in the list is of type <class 'numpy.ndarray'> and has shape (2474, 4)\n",
      "time_from 2014-01-01\n",
      "time_to 2015-01-01\n",
      "WCS:  <sentinelhub.data_request.WcsRequest object at 0x7fab8d3fdfd0>\n",
      "avail dates list:  []\n",
      "time_from 2015-01-01\n",
      "time_to 2016-01-01\n",
      "WCS:  <sentinelhub.data_request.WcsRequest object at 0x7fac583a9e10>\n",
      "avail dates list:  []\n"
     ]
    }
   ],
   "source": [
    "class SentinelData:\n",
    "    \"\"\"\n",
    "    Retreiveing Sentinel data from Sentinel Hub\n",
    "    initialise class with coordinates list, resolution, bounding box coordinates, years and month ranges\n",
    "    make a wcs request for data between November-April\n",
    "    \"\"\"\n",
    "    def __init__(self, coords_list, years, day_month_to, day_month_from):\n",
    "        self.coords_list = coords_list\n",
    "        self.resolution = '10m'\n",
    "        self.area_coords = BBox(bbox=self.coords_list, crs=CRS.WGS84)\n",
    "        self.year_range = years # make a set of years to iterate over \n",
    "        self.day_month_to = day_month_to\n",
    "        self.day_month_from = day_month_from\n",
    "        \n",
    "        \n",
    "        \n",
    "    def retrieve_data(self):\n",
    "        \"\"\" \n",
    "        Create a bounding box and assign CRS. \n",
    "        Create a wcs data request from Sentinel for Sentinel-2 data. \n",
    "        Define max clouds as 20%\n",
    "        \"\"\"\n",
    "        for year in self.year_range:\n",
    "            time_from = \"{}-{}\".format(year, self.day_month_from)\n",
    "            print(\"time_from\", time_from)\n",
    "            time_to = \"{}-{}\".format(year + 1,  self.day_month_to)\n",
    "            print(\"time_to\", time_to)\n",
    "            # make the request for the desired date range \n",
    "            wcs_true_color_request = WcsRequest (\n",
    "                data_collection=DataCollection.SENTINEL2_L1C,\n",
    "                layer='TRUE-COLOR-S2-L2A', # Layer you have configured\n",
    "                bbox=self.area_coords,\n",
    "                time= (time_from, time_to),\n",
    "                resx=self.resolution, # Stick to 10m resolution as this the maximum possible \n",
    "                resy=self.resolution, \n",
    "                config=config,\n",
    "                maxcc=0 # You can define the maximum ammount of cloud coverage you want to allow. \n",
    "            )\n",
    "            print(\"WCS: \", wcs_true_color_request)\n",
    "    \n",
    "            available_dates_list = wcs_true_color_request.get_dates()\n",
    "            print(\"avail dates list: \", available_dates_list)\n",
    "            yield from available_dates_list\n",
    "            \n",
    "    \n",
    "    def get_available_data(self):\n",
    "        \"\"\"\n",
    "        Use get_data() function from Sentinel to retrieve available data for the dates.\n",
    "        \"\"\"\n",
    "        available_dates_list = self.retrieve_data()\n",
    "        i = 0\n",
    "        for date in available_dates_list:\n",
    "            i += 1\n",
    "            print(\"date\", date)\n",
    "            \n",
    "            wcs_true_color_request = WcsRequest(\n",
    "                data_collection=DataCollection.SENTINEL2_L1C,\n",
    "                layer='TRUE-COLOR-S2-L2A', # Layer you have configured\n",
    "                bbox=self.area_coords, \n",
    "                time= date,\n",
    "                resx='10m', # Stick to 10m resolution as this the maximum possible \n",
    "                resy=self.resolution, \n",
    "                config=config,\n",
    "                maxcc=0,# You can define the maximum ammount of cloud coverage you want to allow.\n",
    "                data_folder='/Users/emilybirch/Documents/UCL_Dissertation' \n",
    "            )\n",
    "            \n",
    "            basemap = wcs_true_color_request.get_data()[0] \n",
    "            \n",
    "            # call the bands_req function to wms request for bands on available dates\n",
    "            call_wms = self.bands_req(basemap, date, i)\n",
    "            \n",
    "            print('Returned data is of type = %s and length %d.' % (type(basemap), len(basemap)))\n",
    "            print(f'Single element in the list is of type {type(basemap[-1])} and has shape {basemap[-1].shape}')\n",
    "           \n",
    "            \n",
    "            \n",
    "\n",
    "            \n",
    "    def bands_req(self, basemap, date, i):\n",
    "        \"\"\"\n",
    "        wms bands request for the bands making up the Sentinel pic\n",
    "        \"\"\"\n",
    "       # for basemap in self.get_available_wms_data():\n",
    "        basemap = np.array(basemap)\n",
    "        wms_bands_request = WmsRequest(\n",
    "            data_collection=DataCollection.SENTINEL2_L1C,\n",
    "            layer='BANDS-S2-L2A', # We are using the 'BANDS-S2-L2A layer now'\n",
    "            bbox=self.area_coords, \n",
    "            width=basemap.shape[1], # 10m resolution dims are sourced from the basemap. \n",
    "            height=basemap.shape[0],\n",
    "            time=(date),\n",
    "            image_format=MimeType.TIFF, \n",
    "            maxcc=0,\n",
    "            #resx='10m',\n",
    "           # resy = '10',\n",
    "            config=config,\n",
    "            data_folder='/Users/emilybirch/Documents/UCL_Dissertation/Data_collection/WMS_all_bands' \n",
    "        )        \n",
    "        \n",
    "        bands = wms_bands_request.get_data()[-1] # save_data=True\n",
    "        bands = np.array(bands)\n",
    "        bands = bands.astype('float32') \n",
    "           \n",
    "        # call the split_bands function\n",
    "        get_channels = self.split_bands(bands, basemap, i)\n",
    "     \n",
    "\n",
    "                  \n",
    "        \n",
    "        \n",
    "    \n",
    "    def plot_data(self):   \n",
    "        \"\"\"\n",
    "        Plot the RGB satellite pics to check its correct/cloud cover is acceptable\n",
    "        and that the image is not cropped.\n",
    "        \"\"\"\n",
    "        basemap = self.get_available_data()\n",
    "        i = 0\n",
    "        for sat_img in basemap:\n",
    "            i += 1\n",
    "            print(\"i\", i)\n",
    "            fig, ax = plt.subplots(1, 1, figsize=(10,10))\n",
    "            plt.imshow(sat_img)\n",
    "            plt.axis('off')\n",
    "            plt.savefig('ala_sat_4_{}.png'.format(i),\n",
    "                        bbox_inches='tight',\n",
    "                        dpi=300)\n",
    "            plt.show()\n",
    "          \n",
    "\n",
    "        \n",
    "        \n",
    "    # Download NIR (b08), DEM and Raw NDSI (no thresholding)          \n",
    "    def split_bands(self, bands, basemap, i):\n",
    "        \"\"\"\n",
    "        Split the bands req into individual bands\n",
    "        Download NIR b08 as single band .tif\n",
    "        Calculate NDSI and download this as .tif\n",
    "        \"\"\"\n",
    "        #bands = self.get_available_wms_data()\n",
    "            \n",
    "        b01 = bands[:,:,0] # Coastal Aerosol\n",
    "        b02 = bands[:,:,1] # Blue\n",
    "        b03 = bands[:,:,2] # Green\n",
    "        b04 = bands[:,:,3] # Red\n",
    "        b05 = bands[:,:,4] # Vegetation Red Edge \n",
    "        b06 = bands[:,:,5] # Vegetation Red Edge\n",
    "        b07 = bands[:,:,6] # Vegetation Red Edge\n",
    "        b08 = bands[:,:,7] # NIR\n",
    "        b08a = bands[:,:,8] # Vegetation Red Edge\n",
    "        b09 = bands[:,:,9] # Water Vapour\n",
    "        b11 = bands[:,:,10] # SWIR\n",
    "        b12 = bands[:,:,11] # SWIR\n",
    "        \n",
    "        \n",
    "        # check b08 is array\n",
    "        print(\"TYPE OF B08:\",(type(b08)))\n",
    "        \n",
    "        # calc NDSI from bands\n",
    "        NDSI = (b03 - b11)/(b03 + b11)\n",
    "        #os.chdir('/Users/emilybirch/Documents/UCL_Dissertation/Data_collection/NDSI')\n",
    "        #self, b03, b11, bands \n",
    " \n",
    "        # get NIR band as .tif\n",
    "        raster = b08\n",
    "        dim = raster.shape\n",
    "        print(dim)\n",
    "        height = dim[0] \n",
    "        print(\"height\", height)\n",
    "        width = dim[1] \n",
    "        print(\"width\", width)\n",
    "       # transform - NEEDS TO BE W,S,E,N. CURRENTLY THE BBOX COORDS ARE S,W,N,E. SO NEED TO SWITCH TO 116,50 NOT 50,116\n",
    "        transform=from_bounds(-116.08768, 50.82675, -115.73474, 51.02583, width, height) \n",
    "        print(\"TRANSFORM:\", transform)\n",
    "        os.chdir('/Users/emilybirch/Documents/UCL_Dissertation/Data_collection/NIR')\n",
    "        out_path = ('b08_can_bbox1_{}.tif'.format(i)) \n",
    "        print(\"OUT PATH\", out_path)\n",
    "\n",
    "        write_NIR_band = write_single_channel_gtiff(raster, height, width, transform, out_path)  # self. ?\n",
    "        print(write_NIR_band)\n",
    "            \n",
    "  \n",
    "\n",
    "                        \n",
    "\n",
    "\n",
    "def write_single_channel_gtiff(raster,height, width, transform, out_path): \n",
    "    \"\"\"\n",
    "    Function to write a single channel .tif file. \n",
    "    Retains the geographic info- extent, crs etc. \n",
    "    \"\"\"\n",
    "    assert len(raster.shape) == 2\n",
    "    print(f'Writing...{out_path}')\n",
    "    with rasterio.open(str(out_path),\n",
    "                       mode='w',\n",
    "                       crs= 'EPSG:4326',   # wgs84         \n",
    "                       driver= 'GTIFF',                \n",
    "                       nodata=np.nan,\n",
    "                       dtype= raster.dtype,           \n",
    "                       count= 1,                 \n",
    "                       height= height,         \n",
    "                       width= width,             \n",
    "                       transform=transform # w2, s2, e2, n2, width, height. From bbox\n",
    "                       ) as dst:\n",
    "        dst.write(raster, 1)\n",
    "        \n",
    "\n",
    "\n",
    "  \n",
    "    \n",
    "    \n",
    "\n",
    "# make sure to only keep the pics that match the good pics used from snow labelled            \n",
    "# merge DEM tiles, \n",
    "# crop tiles to extent of NIR band pics \n",
    "# resample ?\n",
    "    \n",
    "    \n",
    "# get NDSI single band .tif  \n",
    "# open NDSI, NIR and DEM and stack- put each 3 bands (NIR,DEM,NDSI) into one folder and stack\n",
    "\n",
    "\n",
    "# split into tiny inputs\n",
    "\n",
    "# model\n",
    "\n",
    "\n",
    "\n",
    " \n",
    "  \n",
    "      \n",
    "         \n",
    "# def stack_array(self, b08, NDSI):\n",
    "#        \"\"\"stack DEM, raw NDSI and NIR (b08)\n",
    "            # download multi-band .tif of all three bands\n",
    "#        \"\"\"       \n",
    "\n",
    "        # upload DEM files\n",
    "#        dem_path = '/Users/emilybirch/Documents/UCL_Dissertation/Data_collection/DEM/Directory_for_DEM/DEM/*tifs'\n",
    "#        dem_retrieve = glob.glob(dem_path)\n",
    "#        for data_path in dem_retrieve:\n",
    "#        raster_dataset = gdal.Open(data_path)\n",
    "        # read as array\n",
    "#        dem_array = raster_dataset.ReadAsArray()\n",
    "\n",
    "        # stack bands \n",
    "#        nir_dem_ndsi = np.stack((b08, dem, NDSI_im))\n",
    "#        os.chdir('/Users/emilybirch/Documents/UCL_Dissertation/Data_collection/final_jpegs_NIR_NDSI_DEM')\n",
    "#        imageio.imwrite(w_list[indx]+'.jpg', nir_dem_ndsi)\n",
    "\n",
    "#TO SAVE AS A MULTIBAND IMAGE:\n",
    "#gdal_merge.py -separate  -o new_rgb.tif -a_srs epsg:4326 -co PHOTOMETRIC=MINISBLACK C:\\input_r.tif C:\\input_g.tif C:\\input_b.tif\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "# canada 0%CC. BBOX1. CANADIAN ROCKIES\n",
    "s2, w2 = 50.82675, -116.08768\n",
    "n2, e2 = 51.02583, -115.73474       \n",
    "\n",
    "\n",
    "# CANADA BBOX2 0%CC. VANCOUVER. takes a long time to plot (90 plots)\n",
    "#s2, w2 = 49.60259, -123.27264\n",
    "#n2, e2 = 49.80043, -122.94511\n",
    "    \n",
    "\n",
    "# canada BBOX3. nr vancouver \n",
    "#s2, w2 = 49.98434, -124.25091\n",
    "#n2, e2 = 50.19579, -123.90758\n",
    "       \n",
    "    \n",
    "#bbox=self.area_coords \n",
    " \n",
    "coords_canada = [w2, s2, e2, n2]\n",
    "\n",
    "canada_years = {2014, 2015, 2016, 2017, 2018, 2019, 2020}\n",
    "\n",
    "# define the years and month ranges for data. Nov-April\n",
    "canada_day_month_to = \"01-01\"\n",
    "canada_day_month_from = \"01-01\"\n",
    "\n",
    "\n",
    "\n",
    "canada_data = SentinelData(coords_canada, canada_years, canada_day_month_to, canada_day_month_from)\n",
    "#plot_data_1 = canada_data.plot_data()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#plot_canada_data = canada_data.bands_req()\n",
    "# plot the individual channels for Canada wms/ web req data\n",
    "\n",
    "plot_canada_wms = canada_data.get_available_data()\n",
    "#print(\"PLOT\", plot_canada_wms)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#########################    \n",
    "    \n",
    " # define the years and month ranges for data. Nov-April so there is snow cover.\n",
    "# Sentinel 2 data is only available from 2015 onwards\n",
    "\n",
    "\n",
    "# FORESTED:\n",
    "\n",
    "# FRANCE BBOX 1. 0%CC\n",
    "#s2, w2 = 46.00263, 6.68625\n",
    "#n2, e2 = 46.21018, 7.00556\n",
    "\n",
    "\n",
    "# FRANCE BBOX 2. 0%CC\n",
    "#s2, w2 = 44.5032, 6.26995\n",
    "#n2, e2 = 44.71395, 6.57683\n",
    "\n",
    "# FRANCE BBOX 3. 0%CC. in Vosges mountains. \n",
    "#s2, w2 = 47.89925, 6.75874\n",
    "#n2, e2 = 48.0968, 7.0709\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "# NEW ZEALAND 0% CC. BBOX1. FORESTED. gets 3 3/4 pics \n",
    "#s2, w2 = -44.64093, 168.67527\n",
    "#n2,e2 = -44.42578, 168.99039\n",
    "\n",
    "\n",
    "# NZ BBOX 2 FORESTED. 3 pics  \n",
    "#s2,w2 = -44.46215, 169.15172\n",
    "#n2,e2 = -44.26874, 169.4559\n",
    "\n",
    "\n",
    "# NZ BBOX 3. 3 pics \n",
    "#s2,w2 = -45.57742, 167.32814\n",
    "#n2,e2 = -45.37906, 167.63988\n",
    "\n",
    "\n",
    "# NZ bbox 4. \n",
    "#s2,w2 = -44.21029, 168.7185\n",
    "#n2, e2 = -43.99234, 169.00415\n",
    "    \n",
    "\n",
    "##################################    \n",
    "    \n",
    "# NON-FORESTED:  \n",
    "# Norway. scandy mountains. works but forest?\n",
    "#s2, w2 = 61.19427, 6.71053\n",
    "#n2, e2 = 61.39842, 7.14765\n",
    "  \n",
    "\n",
    "# BBOX 2 \n",
    "# s2, w2 = 62.11413, 11.91172\n",
    "#n2, e2 = 62.31454, 12.35366\n",
    "\n",
    "\n",
    "# BBOX 3. nr namsos\n",
    "#s2, w2 = 64.5321, 11.68324\n",
    "#n2, e2 = 64.72623, 12.17067\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "# Argentina. bbox 1. \n",
    "#s2, w2 = -36.1615, -70.60757\n",
    "#n2, e2 = -36.35363, -70.87261\n",
    "    \n",
    "\n",
    "# Argentina BBOX2\n",
    "#s2, w2 = -36.90052, -71.07906\n",
    "#n2, e2 = -36.7103, -70.80853\n",
    "    \n",
    "   \n",
    " # Argentina BBOX3\n",
    "#s2, w2 = -48.25276, -72.33129\n",
    "#n2, e2 = -48.05762, -72.0168\n",
    "       \n",
    "  \n",
    "\n",
    "\n",
    "\n",
    "\n",
    " # Alaska bbox1 3 pics\n",
    "#s2, w2 = 60.58666, -144.4895\n",
    "#n2, e2 = 60.78174, -144.04753\n",
    "    \n",
    "    \n",
    "    \n",
    "# alaska bbox 2 2 pics\n",
    "#s2, w2 = 60.54723, -145.6761\n",
    "#n2, e2 = 60.74312, -145.24079\n",
    "    \n",
    "\n",
    "    \n",
    "# alaska bbox 3. 3 pics\n",
    "#s2, w2 = 60.86118, -146.57959\n",
    "#n2, e2 = 61.05052, -146.14288\n",
    "\n",
    "\n",
    "# alaska bbox 4. 3 pics \n",
    "#s2, w2 = 61.10963, -146.62525\n",
    "#n2, e2 = 61.30145, -146.18168\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "matched-setup",
   "metadata": {},
   "source": [
    "If you just wanted to download a true colour composite, you could use WcsRequest()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "touched-thread",
   "metadata": {},
   "source": [
    "If you want to access the full Sentinel-2 product (with all channels) you can use wms request. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "objective-tribune",
   "metadata": {},
   "source": [
    "We can  then use band 2 and band 11 (SWIR and Blue) to create a normalised difference snow index (NDSI) and the normalised difference water index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "f7b16386",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/Users/emilybirch/Documents/UCL_Dissertation/Data_collection/DEM/France/BOX2/tifs/ALPSMLC30_N044E006_DSM.tif'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m~/opt/anaconda3/envs/Dissertation_ML/lib/python3.7/shutil.py\u001b[0m in \u001b[0;36mmove\u001b[0;34m(src, dst, copy_function)\u001b[0m\n\u001b[1;32m    565\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 566\u001b[0;31m         \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrename\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreal_dst\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    567\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mOSError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/Users/emilybirch/Documents/UCL_Dissertation/Data_collection/DEM/France/BOX2/tifs/ALPSMLC30_N044E006_DSM.tif' -> '/Users/emilybirch/Documents/UCL_Dissertation/Data_collection/DEM/Directory_for_DEM/Final_DEM_pics/mergedFrDEM2.tif'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-65-e6eb94a5d629>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;31m# France bbox 2. only 1 tile, so move to final DEMs folder and rename\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mshutil\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mshutil\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmove\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/Users/emilybirch/Documents/UCL_Dissertation/Data_collection/DEM/France/BOX2/tifs/ALPSMLC30_N044E006_DSM.tif'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'/Users/emilybirch/Documents/UCL_Dissertation/Data_collection/DEM/Directory_for_DEM/Final_DEM_pics/mergedFrDEM2.tif'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;31m# Alaska: only 1 tif per. bbox2 and bbox4\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/Dissertation_ML/lib/python3.7/shutil.py\u001b[0m in \u001b[0;36mmove\u001b[0;34m(src, dst, copy_function)\u001b[0m\n\u001b[1;32m    578\u001b[0m             \u001b[0mrmtree\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    579\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 580\u001b[0;31m             \u001b[0mcopy_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreal_dst\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    581\u001b[0m             \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munlink\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    582\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mreal_dst\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/Dissertation_ML/lib/python3.7/shutil.py\u001b[0m in \u001b[0;36mcopy2\u001b[0;34m(src, dst, follow_symlinks)\u001b[0m\n\u001b[1;32m    264\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdst\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    265\u001b[0m         \u001b[0mdst\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdst\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbasename\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 266\u001b[0;31m     \u001b[0mcopyfile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdst\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfollow_symlinks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfollow_symlinks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    267\u001b[0m     \u001b[0mcopystat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdst\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfollow_symlinks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfollow_symlinks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    268\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mdst\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/Dissertation_ML/lib/python3.7/shutil.py\u001b[0m in \u001b[0;36mcopyfile\u001b[0;34m(src, dst, follow_symlinks)\u001b[0m\n\u001b[1;32m    118\u001b[0m         \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msymlink\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreadlink\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdst\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    119\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 120\u001b[0;31m         \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'rb'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mfsrc\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    121\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdst\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'wb'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mfdst\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    122\u001b[0m                 \u001b[0mcopyfileobj\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfsrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfdst\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/Users/emilybirch/Documents/UCL_Dissertation/Data_collection/DEM/France/BOX2/tifs/ALPSMLC30_N044E006_DSM.tif'"
     ]
    }
   ],
   "source": [
    "# FILES HAVE MOVED, DO NOT NEED TO RUN AGAIN\n",
    "\n",
    "# mMove and rename the single .tif tiles which do not need merging\n",
    "# France bbox 2. only 1 tile, so move to final DEMs folder and rename\n",
    "import shutil\n",
    "shutil.move('/Users/emilybirch/Documents/UCL_Dissertation/Data_collection/DEM/France/BOX2/tifs/ALPSMLC30_N044E006_DSM.tif', '/Users/emilybirch/Documents/UCL_Dissertation/Data_collection/DEM/Directory_for_DEM/Final_DEM_pics/mergedFrDEM2.tif')\n",
    "\n",
    "# Alaska: only 1 tif per. bbox2 and bbox4\n",
    "import shutil\n",
    "shutil.move('/Users/emilybirch/Documents/UCL_Dissertation/Data_collection/DEM/Alaska/BOX2/tifs/ALPSMLC30_N060W145_DSM.tif', '/Users/emilybirch/Documents/UCL_Dissertation/Data_collection/DEM/Directory_for_DEM/Final_DEM_pics/mergedAlDEM2.tif')\n",
    "shutil.move('/Users/emilybirch/Documents/UCL_Dissertation/Data_collection/DEM/Alaska/BOX4/tifs/ALPSMLC30_N061W146_DSM.tif', '/Users/emilybirch/Documents/UCL_Dissertation/Data_collection/DEM/Directory_for_DEM/Final_DEM_pics/mergedAlDEM4.tif')\n",
    "\n",
    "# Argentina\n",
    "import shutil\n",
    "shutil.move(\"/Users/emilybirch/Documents/UCL_Dissertation/Data_collection/DEM/Argentina/BOX1/tifs/ALPSMLC30_S036W070_DSM.tif\", '/Users/emilybirch/Documents/UCL_Dissertation/Data_collection/DEM/Directory_for_DEM/Final_DEM_pics/mergedArgDEM1.tif')\n",
    "shutil.move(\"/Users/emilybirch/Documents/UCL_Dissertation/Data_collection/DEM/Argentina/BOX2/tifs/ALPSMLC30_S036W071_DSM.tif\", '/Users/emilybirch/Documents/UCL_Dissertation/Data_collection/DEM/Directory_for_DEM/Final_DEM_pics/mergedArgDEM2.tif') \n",
    "shutil.move(\"/Users/emilybirch/Documents/UCL_Dissertation/Data_collection/DEM/Argentina/BOX3/tifs/ALPSMLC30_S048W072_DSM.tif\", '/Users/emilybirch/Documents/UCL_Dissertation/Data_collection/DEM/Directory_for_DEM/Final_DEM_pics/mergedArgDEM3.tif') \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "b74fef92",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['/Users/emilybirch/Documents/UCL_Dissertation/Data_collection/DEM/Canada/BBOX2/tifs/ALPSMLC30_N050W122_DSM.tif', '/Users/emilybirch/Documents/UCL_Dissertation/Data_collection/DEM/Canada/BBOX2/tifs/ALPSMLC30_N049W123_DSM.tif', '/Users/emilybirch/Documents/UCL_Dissertation/Data_collection/DEM/Canada/BBOX2/tifs/ALPSMLC30_N050W123_DSM.tif', '/Users/emilybirch/Documents/UCL_Dissertation/Data_collection/DEM/Canada/BBOX2/tifs/ALPSMLC30_N049W122_DSM.tif', '/Users/emilybirch/Documents/UCL_Dissertation/Data_collection/DEM/Canada/BBOX2/tifs/ALPSMLC30_N049W124_DSM.tif']\n",
      "['/Users/emilybirch/Documents/UCL_Dissertation/Data_collection/DEM/Canada/BBOX2/tifs/ALPSMLC30_N050W122_DSM.tif', '/Users/emilybirch/Documents/UCL_Dissertation/Data_collection/DEM/Canada/BBOX2/tifs/ALPSMLC30_N049W123_DSM.tif', '/Users/emilybirch/Documents/UCL_Dissertation/Data_collection/DEM/Canada/BBOX2/tifs/ALPSMLC30_N050W123_DSM.tif', '/Users/emilybirch/Documents/UCL_Dissertation/Data_collection/DEM/Canada/BBOX2/tifs/ALPSMLC30_N049W122_DSM.tif', '/Users/emilybirch/Documents/UCL_Dissertation/Data_collection/DEM/Canada/BBOX2/tifs/ALPSMLC30_N049W124_DSM.tif']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# merge DEM tiles for each bbox\n",
    "import os \n",
    "from osgeo import gdal\n",
    "import glob\n",
    "import subprocess\n",
    "import gdal\n",
    "from gdalconst import GA_ReadOnly\n",
    "\n",
    "\n",
    "# set dir\n",
    "os.chdir('/Users/emilybirch/Documents/UCL_Dissertation/Data_collection/DEM/Directory_for_DEM/DEM_merged')\n",
    "os.getcwd()\n",
    "\n",
    "# CANADA. make a list of DEM files to merge. get all with .tif extension\n",
    "can_bbox1_path = \"/Users/emilybirch/Documents/UCL_Dissertation/Data_collection/DEM/Canada/BBOX1/tifs/*.tif\"\n",
    "can_bbox2_path = \"/Users/emilybirch/Documents/UCL_Dissertation/Data_collection/DEM/Canada/BBOX2/tifs/*.tif\"\n",
    "can_bbox3_path = \"/Users/emilybirch/Documents/UCL_Dissertation/Data_collection/DEM/Canada/BBOX2/tifs/*.tif\"\n",
    "# retrieve files with this path name and extension\n",
    "CanDEMList_1 = glob.glob(can_bbox1_path)\n",
    "CanDEMList_2 = glob.glob(can_bbox2_path)\n",
    "CanDEMList_3 = glob.glob(can_bbox3_path)\n",
    "print(CanDEMList_3)\n",
    "\n",
    "# call subprocess gdal merge to merge the DEM tiles\n",
    "cmd = \"gdal_merge.py -o mergedCanDEM1.tif\"\n",
    "subprocess.call(cmd.split()+CanDEMList_1)\n",
    "# Canada bbox2 merge\n",
    "cmd = \"gdal_merge.py -o mergedCanDEM2.tif\"\n",
    "subprocess.call(cmd.split()+CanDEMList_2)\n",
    "# Canada bbox3 merge\n",
    "cmd = \"gdal_merge.py -o mergedCanDEM3.tif\"\n",
    "subprocess.call(cmd.split()+CanDEMList_3)\n",
    "\n",
    "\n",
    "# France. Set path to DEM tif files\n",
    "fr_bbox1 = \"/Users/emilybirch/Documents/UCL_Dissertation/Data_collection/DEM/France/BBOX1/tifs/*.tif\"\n",
    "fr_bbox3 = \"/Users/emilybirch/Documents/UCL_Dissertation/Data_collection/DEM/France/BOX3/tifs/*.tif\"\n",
    "#retrieve files with this path name and extension\n",
    "fr_list1 = glob.glob(fr_bbox1)\n",
    "fr_list3 = glob.glob(fr_bbox3)\n",
    "\n",
    "# merge the DEM tiles. bbox1\n",
    "cmd = \"gdal_merge.py -o mergedFrDEM1.tif\"\n",
    "subprocess.call(cmd.split()+fr_list1)\n",
    "# Fr bbox3 merge\n",
    "cmd = \"gdal_merge.py -o mergedFrDEM3.tif\"\n",
    "subprocess.call(cmd.split()+fr_list3)\n",
    "\n",
    "\n",
    "\n",
    "# Alaska. Set path to DEM tif files\n",
    "alask_path1 = \"/Users/emilybirch/Documents/UCL_Dissertation/Data_collection/DEM/Alaska/BBOX1/tifs/*.tif\"\n",
    "alask_path3 = \"/Users/emilybirch/Documents/UCL_Dissertation/Data_collection/DEM/Alaska/BOX3/tifs/*.tif\"\n",
    "#retrieve files with this path name and extension\n",
    "al_DEM_list1 = glob.glob(alask_path1)\n",
    "al_DEM_list3 = glob.glob(alask_path3)\n",
    "\n",
    "# call subprocess gdal merge to merge the DEM tiles\n",
    "cmd = \"gdal_merge.py -o mergedAlDEM1.tif\"\n",
    "subprocess.call(cmd.split()+al_DEM_list1)\n",
    "# bbox3 merge\n",
    "cmd = \"gdal_merge.py -o mergedAlDEM3.tif\"\n",
    "subprocess.call(cmd.split()+al_DEM_list3)\n",
    "\n",
    "\n",
    "# NZ. 4 bbox\n",
    "nz_path3 = '/Users/emilybirch/Documents/UCL_Dissertation/Data_collection/DEM/NZ/BBOX3/tifs/*.tif'\n",
    "nz_path4 = '/Users/emilybirch/Documents/UCL_Dissertation/Data_collection/DEM/NZ/BBOX4/tifs/*.tif'\n",
    "\n",
    "nz_DEM_list3 = glob.glob(nz_path3)\n",
    "nz_DEM_list4 = glob.glob(nz_path4)\n",
    "\n",
    "# call subprocess gdal merge to merge the DEM tiles\n",
    "cmd = \"gdal_merge.py -o mergedNzDEM3.tif\"\n",
    "subprocess.call(cmd.split()+nz_DEM_list3)\n",
    "# bbox3 merge\n",
    "cmd = \"gdal_merge.py -o mergedNzDEM4.tif\"\n",
    "subprocess.call(cmd.split()+nz_DEM_list4)\n",
    "\n",
    "\n",
    "# Norway\n",
    "nor_path1 = '/Users/emilybirch/Documents/UCL_Dissertation/Data_collection/DEM/Norway/bbox1/tifs/*.tif'\n",
    "nor_path2 = '/Users/emilybirch/Documents/UCL_Dissertation/Data_collection/DEM/Norway/bbox2/tifs/*.tif'\n",
    "nor_path3 = '/Users/emilybirch/Documents/UCL_Dissertation/Data_collection/DEM/Norway/bbox3/tifs/*.tif'\n",
    "\n",
    "NorDEMList_1 = glob.glob(nor_path1)\n",
    "NorDEMList_2 = glob.glob(nor_path2)\n",
    "NorDEMList_3 = glob.glob(nor_path3)\n",
    "print(CanDEMList_3)\n",
    "\n",
    "# call subprocess gdal merge to merge the DEM tiles\n",
    "cmd = \"gdal_merge.py -o mergedNorDEM1.tif\"\n",
    "subprocess.call(cmd.split()+NorDEMList_1)\n",
    "# Canada bbox2 merge\n",
    "cmd = \"gdal_merge.py -o mergedNorDEM2.tif\"\n",
    "subprocess.call(cmd.split()+NorDEMList_2)\n",
    "# Canada bbox3 merge\n",
    "cmd = \"gdal_merge.py -o mergedNorDEM3.tif\"\n",
    "subprocess.call(cmd.split()+NorDEMList_3)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3391be64",
   "metadata": {},
   "outputs": [],
   "source": [
    "# clip to extent of another raster file\n",
    "data = gdal.Open('can_sat_1_1.png', GA_ReadOnly)\n",
    "print(data)\n",
    "geoTransform = data.GetGeoTransform()\n",
    "print(\"GEO\", geoTransform)\n",
    "minx = geoTransform[0]\n",
    "print(\"MIN\", minx)\n",
    "maxy = geoTransform[3]\n",
    "print(\"MAX\", maxy)\n",
    "maxx = minx + geoTransform[1] * data.RasterXSize\n",
    "miny = maxy + geoTransform[5] * data.RasterYSize\n",
    "call('gdal_translate -projwin ' + ' '.join([str(x) for x in [minx, maxy, maxx, miny]]) + ' -of GTiff mergedCanDEM1.tif cropCanDEM1.tif', shell=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f531e589",
   "metadata": {},
   "outputs": [],
   "source": [
    "# clip to extent of sample pic\n",
    "import numpy as np\n",
    "import rasterio\n",
    "from rasterio import features\n",
    "from rasterio.mask import mask\n",
    "\n",
    "\n",
    "# ****** make this path have both dem and NIR pics in\n",
    "os.chdir('/Users/emilybirch/Documents/UCL_Dissertation/Data_collection/DEM/Directory_for_DEM/DEM_pics')\n",
    "os.getcwd()\n",
    "\n",
    "# the first one is your raster on the right. use the single band NIR .tif to crop to\n",
    "# and the second one your red raster\n",
    "with rasterio.open('b08_can_bbox1_1') as src, \\\n",
    "        rasterio.open('mergedCanDEM1.tif') as src_to_crop:\n",
    "    src_affine = src.meta.get(\"transform\") # this is s,w,n,e, height, width, pixel size etc.\n",
    "\n",
    "    # Read the first band of the \"mask\" raster\n",
    "    band = src.read(1)\n",
    "    # Use the same value on each pixel with data\n",
    "    # in order to speedup the vectorization\n",
    "    band[np.where(band!=src.nodata)] = 1\n",
    "\n",
    "    geoms = []\n",
    "    for geometry, raster_value in features.shapes(band, transform=src_affine):\n",
    "        # get the shape of the part of the raster\n",
    "        # not containing \"nodata\"\n",
    "        if raster_value == 1:\n",
    "            geoms.append(geometry)\n",
    "\n",
    "    # crop the second raster using the\n",
    "    # previously computed shapes\n",
    "    out_img, out_transform = mask(\n",
    "        dataset=src_to_crop,\n",
    "        shapes=geoms,\n",
    "        crop=True,\n",
    "    )\n",
    "\n",
    "    # save the result\n",
    "    # (don't forget to set the appropriate metadata)\n",
    "    with rasterio.open(\n",
    "        'result.tif',\n",
    "        'w',\n",
    "        driver='GTiff',\n",
    "        height=out_img.shape[1],\n",
    "        width=out_img.shape[2],\n",
    "        count=src.count,\n",
    "        dtype=out_img.dtype,\n",
    "        transform=out_transform,\n",
    "    ) as dst:\n",
    "        dst.write(out_img)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d1055eb",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Process DEM geomorphology pics \n",
    "# merge DEM tiles, reproject to projected crs with m units, resample to 10x10m pixel size, crop to bbox\n",
    "import os \n",
    "from osgeo import gdal\n",
    "import glob\n",
    "import subprocess\n",
    "from gdal import gdalconst\n",
    "\n",
    "\n",
    "\n",
    "# set directory to location of all final DEM pics \n",
    "os.chdir('/Users/emilybirch/Documents/UCL_Dissertation/Data_collection/DEM/Directory_for_DEM/Final_DEM_pics')\n",
    "os.getcwd()\n",
    "\n",
    "# can_list = [can_bbox1_path, can_bbox2_path, can_bbox3_path]\n",
    "# i = 0\n",
    "#for f in can_list:\n",
    "    # i += 1\n",
    "    # glob.glob(f)\n",
    "    # cmd = \"gdal_merge.py -o 'mergedCanDEM1_{}.tif'.format(i)\"\n",
    "    # subprocess.call(cmd.split()+f)\n",
    "\n",
    "# CANADA. make a list of DEM files to merge. get all with .tif extension\n",
    "can_bbox1_path = \"/Users/emilybirch/Documents/UCL_Dissertation/Data_collection/DEM/Canada/BBOX1/tifs/*.tif\"\n",
    "can_bbox2_path = \"/Users/emilybirch/Documents/UCL_Dissertation/Data_collection/DEM/Canada/BBOX2/tifs/*.tif\"\n",
    "can_bbox3_path = \"/Users/emilybirch/Documents/UCL_Dissertation/Data_collection/DEM/Canada/BBOX2/tifs/*.tif\"\n",
    "# retrieve files with this path name and extension\n",
    "CanDEMList_1 = glob.glob(can_bbox1_path)\n",
    "CanDEMList_2 = glob.glob(can_bbox2_path)\n",
    "CanDEMList_3 = glob.glob(can_bbox3_path)\n",
    "print(CanDEMList_3)\n",
    "\n",
    "# call subprocess gdal merge to merge the DEM tiles\n",
    "cmd = \"gdal_merge.py -o mergedCanDEM1.tif\"\n",
    "subprocess.call(cmd.split()+CanDEMList_1)\n",
    "# Canada bbox2 merge\n",
    "cmd = \"gdal_merge.py -o mergedCanDEM2.tif\"\n",
    "subprocess.call(cmd.split()+CanDEMList_2)\n",
    "# Canada bbox3 merge\n",
    "cmd = \"gdal_merge.py -o mergedCanDEM3.tif\"\n",
    "subprocess.call(cmd.split()+CanDEMList_3)\n",
    "\n",
    "\n",
    "\n",
    "# France. Set path to DEM tif files\n",
    "fr_bbox1 = \"/Users/emilybirch/Documents/UCL_Dissertation/Data_collection/DEM/France/BBOX1/tifs/*.tif\"\n",
    "fr_bbox3 = \"/Users/emilybirch/Documents/UCL_Dissertation/Data_collection/DEM/France/BOX3/tifs/*.tif\"\n",
    "#retrieve files with this path name and extension\n",
    "fr_list1 = glob.glob(fr_bbox1)\n",
    "fr_list3 = glob.glob(fr_bbox3)\n",
    "\n",
    "# merge the DEM tiles. bbox1\n",
    "cmd = \"gdal_merge.py -o mergedFrDEM1.tif\"\n",
    "subprocess.call(cmd.split()+fr_list1)\n",
    "# Fr bbox3 merge\n",
    "cmd = \"gdal_merge.py -o mergedFrDEM3.tif\"\n",
    "subprocess.call(cmd.split()+fr_list3)\n",
    "\n",
    "\n",
    "\n",
    "# Alaska. Set path to DEM tif files\n",
    "alask_path1 = \"/Users/emilybirch/Documents/UCL_Dissertation/Data_collection/DEM/Alaska/BBOX1/tifs/*.tif\"\n",
    "alask_path3 = \"/Users/emilybirch/Documents/UCL_Dissertation/Data_collection/DEM/Alaska/BOX3/tifs/*.tif\"\n",
    "#retrieve files with this path name and extension\n",
    "al_DEM_list1 = glob.glob(alask_path1)\n",
    "al_DEM_list3 = glob.glob(alask_path3)\n",
    "\n",
    "# call subprocess gdal merge to merge the DEM tiles\n",
    "cmd = \"gdal_merge.py -o mergedAlDEM1.tif\"\n",
    "subprocess.call(cmd.split()+al_DEM_list1)\n",
    "# bbox3 merge\n",
    "cmd = \"gdal_merge.py -o mergedAlDEM3.tif\"\n",
    "subprocess.call(cmd.split()+al_DEM_list3)\n",
    "\n",
    "\n",
    "\n",
    "# reproject coordinate system into UTM to use metres as units \n",
    "def reproj(out_file, in_file, dstSRS):\n",
    "    gdal.Warp(out_file, in_file, dstSRS = crs)\n",
    "\n",
    "# zip over lists?\n",
    "# reproj for Canada: into EPSG:3978\n",
    "canada_reproj_list = ['mergedCanDEM1.tif', 'mergedCanDEM2.tif', 'mergedCanDEM3.tif']\n",
    "i = 0\n",
    "# for in_file in zip_longest(canada_reproj_list, fr_reproj_list,al_reproj_list,... )\n",
    "for in_file in canada_reproj_list:\n",
    "    i += 1\n",
    "    print(\"I:\", i)\n",
    "    out_file = 'reprojCanDEM_{}.tif'.format(i)\n",
    "    crs = 'EPSG:3978'\n",
    "    call = reproj(out_file, in_file, crs)\n",
    "    print(call)\n",
    "    \n",
    "    \n",
    "# France: into EPSG:23030 ED50 / UTM zone 30N\n",
    "fr_reproj_list =  ['mergedFrDEM1.tif', 'mergedFrDEM2.tif', 'mergedFrDEM3.tif']\n",
    "i = 0\n",
    "for in_file in fr_reproj_list:\n",
    "    i += 1\n",
    "    print(\"I:\", i)\n",
    "    out_file = 'reprojFrDEM_{}.tif'.format(i)\n",
    "    crs = 'EPSG:23030'\n",
    "    call = reproj(out_file, in_file, crs)\n",
    "    print(call)\n",
    " \n",
    " \n",
    "# reproj for Alaska: into EPSG:3338\n",
    "al_reproj_list = ['mergedAlDEM1.tif', 'mergedAlDEM2.tif', 'mergedAlDEM3.tif', 'mergedAlDEM4.tif']\n",
    "i = 0\n",
    "for in_file in al_reproj_list:\n",
    "    i += 1\n",
    "    print(\"I:\", i)\n",
    "    out_file = 'reprojAlDEM_{}.tif'.format(i)\n",
    "    crs = 'EPSG:3338'\n",
    "    call = reproj(out_file, in_file, crs)\n",
    "    print(call)\n",
    "    \n",
    "# reproj for Argentina: into EPSG:5343\n",
    "Arg_reproj_list = ['mergedArgDEM1.tif', 'mergedArgDEM2.tif', 'mergedArgDEM3.tif']\n",
    "i = 0\n",
    "\n",
    "for in_file in Arg_reproj_list:\n",
    "    i += 1\n",
    "    print(\"I:\", i)\n",
    "    out_file = 'reprojArgDEM_{}.tif'.format(i)\n",
    "    crs = 'EPSG:5343'\n",
    "    call = reproj(out_file, in_file, crs)\n",
    "    print(call)\n",
    "    \n",
    "    \n",
    "    \n",
    "\n",
    "# Resample to 10x10m pixel size to match Sentinel images\n",
    "def resample(out_file, in_file):\n",
    "    gdal.Warp(out_file, in_file, xRes = 10, yRes = 10, resampleAlg = \"bilinear\")\n",
    "    print(\"HI\")\n",
    "        \n",
    "\n",
    "# list the files to resample and process then in a loop \n",
    "resamp_files_list = ['reprojCanDEM_1.tif', 'reprojCanDEM_2.tif', 'reprojCanDEM_3.tif']    \n",
    "i = 0\n",
    "for in_file in resamp_files_list:\n",
    "    i += 1\n",
    "    print(\"i\", i)\n",
    "    out_file = \"resamp_Can_DEM_{}.tif\".format(i)\n",
    "    print(\"OUTfile\", out_file)\n",
    "    resample(out_file, in_file)\n",
    "            \n",
    "\n",
    "# France: resample\n",
    "resamp_list = ['reprojFrDEM_1.tif', 'reprojFrDEM_2.tif', 'reprojFrDEM_3.tif']    \n",
    "i = 0\n",
    "for in_file in resamp_list:\n",
    "    i += 1\n",
    "    print(\"i\", i)\n",
    "    out_file = \"resamp_Fr_DEM_{}.tif\".format(i)\n",
    "    print(\"OUTfile\", out_file)\n",
    "    resample(out_file, in_file)\n",
    "\n",
    "    \n",
    "# Alaska resample. \n",
    "# list of files to resample\n",
    "resamp_list = ['reprojAlDEM_1.tif', 'reprojalDEM_2.tif', 'reprojAlDEM_3.tif', 'reprojAlDEM_4.tif']    \n",
    "i = 0\n",
    "for in_file in resamp_list:\n",
    "    i += 1\n",
    "    print(\"i\", i)\n",
    "    out_file = \"resamp_Al_DEM_{}.tif\".format(i)\n",
    "    print(\"OUTfile\", out_file)\n",
    "    resample(out_file, in_file)\n",
    "\n",
    "\n",
    "\n",
    "# list the files to resample and process then in a loop \n",
    "resamp_files_list = ['reprojArgDEM_1.tif', 'reprojArgDEM_2.tif', 'reprojArgDEM_3.tif']    \n",
    "i = 0\n",
    "for in_file in resamp_files_list:\n",
    "    i += 1\n",
    "    print(\"i\", i)\n",
    "    out_file = \"resamp_Arg_DEM_{}.tif\".format(i)\n",
    "    print(\"OUTfile\", out_file)\n",
    "    resample(out_file, in_file)\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "# Crop .tif to boudning box coords\n",
    "def crop(out_file, source_file, ulx, uly, lrx, lry):\n",
    "    gdal.Translate(out_file, source_file,\n",
    "                  projWin = [ulx, uly, lrx, lry])\n",
    "  \n",
    "\n",
    " \n",
    "# Canada: crop .tif to boudning box coords\n",
    "can1crop = crop('cropCanDEM_1.tif','resamp_Can_DEM_1.tif', -1442222.5901271082, 465767.00799028383, -1425280.668026976, 437053.54995778797) \n",
    "can2crop = crop('cropCanDEM_2.tif','resamp_Can_DEM_2.tif', -1963467.662479708, 532524.2456295489, -1950948.5651828928, 502730.9493941085)  \n",
    "can3crop = crop('cropCanDEM_3.tif','resamp_Can_DEM_3.tif',-2007237.3331321548, 602651.3553773408, -1994916.2627411576, 570806.9080293514) \n",
    "       \n",
    "# France: crop .tif to boudning box coords\n",
    "Fr1crop = crop('cropFrDEM_1.tif','resamp_Can_DEM_1.tif',1246969.3962645088, 5163267.284300569,1274934.6912586447, 5143545.166937985) \n",
    "Fr2crop = crop('cropFrDEM_2.tif','resamp_Can_DEM_2.tif',1234624.7084396454, 4993062.539814649, 1261497.750934254, 4974014.1117675835)  \n",
    "Fr3crop = crop('cropFrDEM_3.tif','resamp_Can_DEM_3.tif', 1225777.8855382334, 5373591.730970369,1252683.6911129407, 5355278.076760378) \n",
    "\n",
    "# Alaska: Crop .tif to boudning box coords\n",
    "Al1crop = crop('cropAlDEM_1.tif','resamp_Al_DEM_1.tif', 514481.90383768355, 1236449.1310469457, 541830.6619147946, 1218503.1192803124) \n",
    "Al2crop = crop('cropAlDEM_2.tif','resamp_Al_DEM_2.tif', 450815.2605629388, 1223929.9128310417, 477228.41344957944, 1204727.699233261)  \n",
    "Al3crop = crop('cropAlDEM_3.tif','resamp_Al_DEM_3.tif', 397957.2487422569, 1251934.8385985517,425182.4670500502, 1234086.2585198171) \n",
    "Al4crop = crop('cropAlDEM_4.tif','resamp_Al_DEM_4.tif',393282.9896072386, 1280321.0557472059,419319.2191957479, 1261199.193909528) \n",
    "  \n",
    "\n",
    "# close datasets to read properly to disk\n",
    "#ds = dsReproj = dsResamp = dsClip = None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "438178e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot to check DEM is reprojected, resampled and cropped to bbox\n",
    "final_DEM = gdal.Open(\"cropDEM_2.tif\")\n",
    "array = final_DEM.ReadAsArray()\n",
    "plt.imshow(array)\n",
    "plt.colorbar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96a43db4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Argentina\n",
    "import os \n",
    "from osgeo import gdal\n",
    "import glob\n",
    "import subprocess\n",
    "from gdal import gdalconst\n",
    "\n",
    "\n",
    "# set directory to location of all final DEM pics \n",
    "os.chdir('/Users/emilybirch/Documents/UCL_Dissertation/Data_collection/DEM/Directory_for_DEM/Final_DEM_pics')\n",
    "os.getcwd()\n",
    "\n",
    "def crop(out_file, source_file, ulx, uly, lrx, lry):\n",
    "    gdal.Translate(out_file, source_file,\n",
    "                  projWin = [ulx, uly, lrx, lry])\n",
    "    \n",
    "  \n",
    "\n",
    "\n",
    " \n",
    "# FIX THESE- CANT CROP BC NOT IN SAME AREA?\n",
    "# Argentina: crop .tif to boudning box coords\n",
    "Ar1crop = crop('cropArgDEM_1.tif','resamp_Arg_DEM_1.tif',5998451.786827491, 1601005.619190992,5976249.0203732345, 1625961.998551086) \n",
    "Ar2crop = crop('cropArgDEM_2.tif','resamp_Arg_DEM_2.tif',5937593.134678965, 1582258.6827567841,5916218.082539896, 1605918.8959056677)\n",
    "Ar3crop = crop('cropArgDEM_3.tif','resamp_Arg_DEM_3.tif', 4676913.660264564, 1475051.4449760758, 4656287.012900037, 1499619.73136248) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e08cb194",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Norway\n",
    "# merge\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87137982",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Norway\n",
    "Nor1crop = crop('cropNorDEM_1.tif','resamp_Nor_DEM_1.tif',1611541.2847414473, -1150463.0893291135,1581199.9787365836, -1136330.787145058)\n",
    "Nor2crop = crop('cropNorDEM_2.tif','resamp_Nor_DEM_2.tif',1619389.5743942696, -854804.3331045215,1591676.3046402216, -836971.2418011383)\n",
    "Nor3crop = crop('cropNorDEM_3.tif','resamp_Nor_DEM_3.tif', 1882899.119273985, -786917.6157957469,1855046.293116921, -769771.7641124884) \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fossil-tamil",
   "metadata": {},
   "outputs": [],
   "source": [
    "# use more than one channel as input into my model. use geomorphology too.\n",
    "\n",
    "# taking the TIFF data and encoding it to a TFRecords format for some machine learning in Tensorflow.  \n",
    "# take the TIFF data, convert it to 8bit format, encode it as a string and write it to TFRecords.  \n",
    "\n",
    "\n",
    "# A guide for Spectral indicies:\n",
    "# https://www.geo.university/pages/blog?p=spectral-indices-with-multispectral-satellite-data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "electoral-concept",
   "metadata": {},
   "source": [
    "I chose a region where both water and snow are present. \n",
    "This shows that when trying to isolate snow, we also isolate water. \n",
    "\n",
    "But when isolating water, we, the snow is mostly left out.\n",
    "This means that we can use both indicies to generate some training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "working-painting",
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_mask(input_image, threshold):\n",
    "    input_image[input_image <= threshold] = np.nan\n",
    "    input_image[input_image > threshold] = 1\n",
    "    return input_image\n",
    "    \n",
    "NDVI_mask = to_mask(NDVI, 0.2)\n",
    "NDSI_mask = to_mask(NDSI, 0.)\n",
    "fig, ax = plt.subplots(1, 4, figsize=(15,10))\n",
    "ax[0].set_title('NDVI Vegetation mask')\n",
    "ax[0].imshow(basemap)\n",
    "ax[0].imshow(NDVI_mask, cmap='cubehelix')\n",
    "ax[1].set_title('NDSI Snow mask')\n",
    "ax[1].imshow(basemap)\n",
    "ax[1].imshow(NDSI_mask, cmap='cubehelix')\n",
    "\n",
    "NDVI_binary_mask = np.nan_to_num(NDVI_mask)\n",
    "NDSI_binary_mask = np.nan_to_num(NDSI_mask)\n",
    "both = NDVI_binary_mask + NDSI_binary_mask\n",
    "\n",
    "ax[2].set_title('NDSI mask + NDVI mask')\n",
    "ax[2].imshow(both, cmap='cubehelix')\n",
    "\n",
    "ax[3].set_title('Snow mask - Vegetation removed')\n",
    "snow_only = both.copy()\n",
    "snow_only[snow_only == 2] = 0\n",
    "ax[3].imshow(snow_only, cmap='cubehelix')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "gorgeous-dominant",
   "metadata": {},
   "source": [
    "CNN's usually don't accept big inputs, so the image needs to be cropped into smaller samples.\n",
    "\n",
    "The bigger and more complex the CNN, the more processing power will be required, therefore the smaller the input samples will need to be. \n",
    "\n",
    "Rather than crushing the original sample, a good idea is to splice it. \n",
    "This way we get a lot more data, and the 10m resolution is maintained. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "registered-better",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "# Split the Images\n",
    "def split_image(dim_pix, im):\n",
    "    # Find the number of sub-Images that fit in rows\n",
    "    rows = []\n",
    "    tiles = []\n",
    "    for i in range((math.floor(im.shape[0] / dim_pix))):\n",
    "        rows.append(i)\n",
    "    # Find the number of sub-Images that fit in rows\n",
    "    columns = []\n",
    "    for i in range((math.floor(im.shape[1] / dim_pix))):\n",
    "        columns.append(i)\n",
    "\n",
    "    # Numerically identify the sub-Images\n",
    "    a = 0\n",
    "    for i in rows:\n",
    "        for j in columns:\n",
    "            # Check for 244 x 244 (Mask) or 244 x 244 x 3 (TC Images)\n",
    "            if (im[0 + (dim_pix * j): dim_pix + (dim_pix * j),\n",
    "                  0 + dim_pix * i: dim_pix + (dim_pix * i)].shape[0]) == dim_pix:\n",
    "                if (im[0 + (dim_pix * j): dim_pix + (dim_pix * j),\n",
    "                  0 + dim_pix * i: dim_pix + (dim_pix * i)].shape[1]) == dim_pix:\n",
    "\n",
    "                    tile = im[0 + (dim_pix * j): dim_pix + (dim_pix * j),\n",
    "                            0 + dim_pix * i: dim_pix + (dim_pix * i)]\n",
    "\n",
    "                    # Stop white tiles for positive results\n",
    "                    count = np.count_nonzero(tile == 1) == (dim_pix * dim_pix)\n",
    "                    if count:\n",
    "                        all_black = np.tile(1, (dim_pix, dim_pix))\n",
    "                        tiles.append(tile)\n",
    "                    else:\n",
    "                        tiles.append(tile)\n",
    "                    a += 1\n",
    "                else:\n",
    "                    print(\"Out of shape\")\n",
    "    return tiles\n",
    "\n",
    "input_tensor_dimensions = 50\n",
    "                    \n",
    "basemap_tiles = split_image(dim_pix=input_tensor_dimensions, im=basemap)\n",
    "label_tiles = split_image(dim_pix=input_tensor_dimensions, im=snow_only)\n",
    "\n",
    "fig, ax = plt.subplots(len(label_tiles), 2, figsize=(2 ,len(label_tiles)))\n",
    "for index in range(len(label_tiles)):\n",
    "    ax[index, 0].axis('off')\n",
    "    ax[index, 1].axis('off')\n",
    "    ax[index, 0].imshow(basemap_tiles[index])\n",
    "    ax[index, 1].imshow(label_tiles[index], cmap='Blues')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f5376d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# EXTRA!!!!\n",
    "\n",
    "# EXTRA. func to convert bbox coords from geographic into projected system \n",
    "import os\n",
    "import pyproj\n",
    "from pyproj import Proj, transform\n",
    "\n",
    "os.environ['PROJ_NETWORK'] = 'OFF'\n",
    "\n",
    "\n",
    "def coord_conv(x1, y1, in_proj, out_proj):\n",
    "    proj = pyproj.Transformer.from_crs(in_proj, out_proj)\n",
    "    x2, y2 = proj.transform(x1, y1)\n",
    "    print((x1, y1))\n",
    "    print((x2, y2))\n",
    "    return x2,y2\n",
    "\n",
    "\n",
    " \n",
    "# 1. Canada:   #\"epsg:4326\", \"epsg:3978\"\n",
    "#can_DEM_bbox1_ulc = coord_conv(51.02521, -116.09311, 4326, 3978)\n",
    "#can_DEM_bbox1_lrc = coord_conv(50.82872, -115.73064, 4326, 3978)\n",
    "# box2\n",
    "#can_DEM_bbox2_ulc = coord_conv(49.7991, -123.27756,4326, 3978)\n",
    "#can_DEM_bbox2_lrc = coord_conv(49.60459, -122.94316,4326, 3978)\n",
    "# box3\n",
    "#can_bbox3_ulc = coord_conv(50.19571, -124.25775,4326, 3978)\n",
    "#can_bbox3_lrc = coord_conv(49.98687, -123.90537,4326, 3978)\n",
    "\n",
    "\n",
    "\n",
    "# 2. France \n",
    "# bbox 1 \n",
    "#Fr_bbox1_ulc = coord_conv(46.20907, 6.68394, 4326, 23030)\n",
    "#Fr_bbox1_lrc = coord_conv(46.00317, 7.009, 4326, 23030)\n",
    "# box2\n",
    "#Fr_bbox1_ulc = coord_conv(44.71102, 6.27264,4326, 23030)\n",
    "#Fr_bbox1_lrc = coord_conv(44.51403, 6.57913,4326, 23030)\n",
    "# box3\n",
    "#Fr_bbox1_ulc = coord_conv(48.09807, 6.75178,4326, 23030)\n",
    "#Fr_bbox1_lrc = coord_conv(47.90479, 7.07567, 4326, 23030)\n",
    "\n",
    "\n",
    "# Alaska\n",
    "#Al_bbox1_uly = coord_conv(60.78013, -144.48842,4326, 3338)\n",
    "#Al_bbox1_lrc = coord_conv(60.58568, -144.03959, 4326, 3338)\n",
    "\n",
    "#Al_bbox2_uly = coord_conv(60.74539, -145.68114, 4326, 3338)\n",
    "#Al_bbox2_lrc = coord_conv(60.54485, -145.24568, 4326, 3338)\n",
    "\n",
    "#Al_bbox3_uly = coord_conv(61.04986, -146.59057, 4326, 3338)\n",
    "#Al_bbox3_lrc = coord_conv(60.86339, -146.12749, 4326, 3338)\n",
    "\n",
    "#Al_bbox4_uly = coord_conv(61.30673, -146.61838, 4326, 3338) \n",
    "#Al_bbox4_lrc = coord_conv(61.11029, -146.17618, 4326, 3338)\n",
    "\n",
    "\n",
    "# Argentina\n",
    "#Ar_bbox1_uly = coord_conv(-36.1567, -70.87755,4326, 5343)\n",
    "#Ar_bbox1_lrc = coord_conv(-36.35381, -70.59671, 4326, 5343)\n",
    "\n",
    "#Ar_bbox2_uly = coord_conv(-36.70684, -71.0794, 4326, 5343)\n",
    "#Ar_bbox2_lrc = coord_conv(-36.89707, -70.81168, 4326, 5343)\n",
    "\n",
    "#Ar_bbox3_uly = coord_conv(-48.05909, -72.3347, 4326, 5343)\n",
    "#Ar_bbox3_lrc = coord_conv(-48.24508, -72.00512, 4326, 5343)\n",
    "\n",
    "\n",
    "# Norway. ETRS89 / UTM is the projected CRS for Norway\n",
    "Nor_bbox1_uly = coord_conv(61.39974, 6.71094,4326, 5130)\n",
    "Ar_bbox1_lrc = coord_conv(61.19466, 7.15113, 4326, 5130)\n",
    "\n",
    "Nor_bbox2_uly = coord_conv(62.31192, 11.90014, 4326, 5130)\n",
    "Ar_bbox2_lrc = coord_conv(62.12052, 12.37392, 4326, 5130)\n",
    "\n",
    "Nor_bbox3_uly = coord_conv(64.72578, 11.67157, 4326, 5130)\n",
    "Nor_bbox3_lrc = coord_conv(64.53323, 12.179, 4326, 5130)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#####################\n",
    "#can_list = []\n",
    "# [51.02521, -116.09311,(49.7991, -123.27756), (50.19571, -124.25775)]\n",
    "#x = [51.02521.....\n",
    "# y = ...\n",
    "#x.append\n",
    "#y.append\n",
    "#for coord in can_list:\n",
    "#    in_proj = 4326\n",
    "#    out_proj = 3978\n",
    "#    x1, y1 = ulc.split(',')\n",
    "#    coord_conv(x1,y1,in_proj,out_proj)\n",
    "\n",
    "\n",
    "#NZ\n",
    "#-44.42977, 168.66256\n",
    "#-44.63339, 168.99731\n",
    "\n",
    "#-44.26552, 169.14185\n",
    "#-44.45747, 169.46413\n",
    "\n",
    "#-45.37762, 167.32743\n",
    "#-45.58001, 167.63521\n",
    "\n",
    "#-44.00659, 168.70122\n",
    "#-44.19769, 169.022\n",
    "\n",
    "#EPSG:27200\n",
    "    \n",
    "    \n",
    "    \n",
    "\n",
    "# Norway\n",
    "#61.39974, 6.71094\n",
    "#61.19466, 7.15113\n",
    "\n",
    "#62.31192, 11.90014\n",
    "#62.12052, 12.37392\n",
    "\n",
    "#64.72578, 11.67157\n",
    "#64.53323, 12.179\n",
    "\n",
    "#EPSG:5776"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08297252",
   "metadata": {},
   "outputs": [],
   "source": [
    "# reading/ writing rasters EXTRA CODE\n",
    "def access_raster(path, aoi=None):\n",
    "    \"\"\"\n",
    "    This func says if the raster is the bbox shape, then just get info,\n",
    "    if its not the bbox shape (aoi coords), then make a shape to cut the new tif to\n",
    "    \"\"\" \n",
    "    # aoi is canada_coords\n",
    "    if aoi == None:\n",
    "        with rasterio.open(path) as src:\n",
    "            array = src.read()\n",
    "            meta = src.meta\n",
    "            transform = src.meta['transform']\n",
    "            extent = src.bounds\n",
    "            extent_dims = {'north': extent.top, 'south': extent.bottom, 'west': extent.left, 'east': extent.right}\n",
    "            polygon_extent = polygon_generator(extent_dims)\n",
    "\n",
    " \n",
    "\n",
    "        return {'array': array, 'meta': meta, 'transform': transform, 'extent': extent, 'polygom':polygon_extent}\n",
    "\n",
    " \n",
    "\n",
    "    else:\n",
    "        with fiona.open(aoi, \"r\") as shapefile:\n",
    "            shapes = [feature[\"geometry\"] for feature in shapefile]\n",
    "\n",
    " \n",
    "\n",
    "        with rasterio.open(path) as src:\n",
    "            array, transform = rasterio.mask.mask(src, shapes, crop=True)\n",
    "            meta = src.meta\n",
    "            extent = src.bounds\n",
    "        return {'array': array, 'meta': meta, 'transform': transform, 'extent': extent}\n",
    "\n",
    "\n",
    "    \n",
    "def write_single_channel_gtiff(raster, transform, meta,  out_path):\n",
    "    assert len(raster.shape) == 2\n",
    "    print(f'Writing...{out_path}')\n",
    "    with rasterio.open(str(out_path),\n",
    "                       mode='w',\n",
    "                       crs=meta['crs'],\n",
    "                       driver=meta['driver'],\n",
    "                       nodata=np.nan,\n",
    "                       dtype=meta['dtype'],\n",
    "                       count=meta['count'],\n",
    "                       height=raster.shape[0],\n",
    "                       width=raster.shape[1],\n",
    "                       transform=transform\n",
    "                       ) as dst:\n",
    "        dst.write(raster, 1)\n",
    "        \n",
    "    \n",
    "    \n",
    "##############\n",
    "From raster.crs import CRS\n",
    "\n",
    "def get_raster_info(raster):\n",
    "    data_type = raster.dtype\n",
    "    print(data_type)\n",
    "    dim = raster.shape\n",
    "    print(dim)\n",
    "    height = dim[1]\n",
    "    width = dim[2]\n",
    "\n",
    "    \n",
    "\n",
    "transform=from_bounds(w2, s2, e2, n2, width, height)\n",
    "\n",
    "\n",
    "#With raster.open(./output.tif, w, \n",
    "#    driver = driver,\n",
    "#    height = height,\n",
    "#    width = width,\n",
    "#    count = count,\n",
    "#    typed = dtype,\n",
    "#    crs = crs,\n",
    "#    transform = transform) as dst:\n",
    "#dst.write(array)\n",
    "\n",
    "###################\n",
    "\n",
    "\n",
    "transform=from_bounds(w2, s2, e2, n2, width, height)\n",
    "# rasterio.transform.from_bounds(west, south, east, north, width, height)\n",
    "\n",
    "crs_img='EPSG:4326'\n",
    "\n",
    "from rasterio.transform import from_bounds\n",
    "with rasterio.open('test1.tif', \n",
    "                    'w',\n",
    "                    driver='GTiff',\n",
    "                    height=NDSI.shape[0],\n",
    "                    width=NDSI.shape[1],\n",
    "                    count=1,\n",
    "                    dtype=NDSI.dtype,\n",
    "                    crs=crs_img,\n",
    "                    nodata=None, # change if data has nodata value\n",
    "                    transform=transform) as dst:\n",
    "        dst.write(ndvi, 1)\n",
    " \n",
    "\n",
    "\n",
    " \n",
    "################\n",
    "# write an array into a new single band .tiff\n",
    "with rasterio.Env():\n",
    "    # write an array as a raster band to a new 8bit file\n",
    "    profile.update(\n",
    "        dtype=rasterio.unit8,\n",
    "        count=1,\n",
    "        compress='lzw')\n",
    "    \n",
    "    with rasterio.open('example.tif', 'w', **profile) as dst:\n",
    "        dst.write(array.astype(rasterio.unit8), 1) \n",
    "        \n",
    "        \n",
    "        \n",
    "############        \n",
    "import gdal\n",
    "# read raster\n",
    "gdal.AllRegister()\n",
    "inRaster ='input raster'\n",
    "inDS=gdal.Open(inRaster,1)\n",
    "geoTransform = inDs.GetGeoTransform()\n",
    "band=inDS.GetRasterBand(1)\n",
    "datatype=band.DataType\n",
    "proj=inDS.GetProjection()\n",
    "        \n",
    "# write raster\n",
    "driver = inDS.GetDriver()\n",
    "outDS= driver.Create(outRaster,No_cols,No_rows,1,datatype)\n",
    "geoTransform = inDS.GetGeoTransform()\n",
    "outDS.SetProjection(proj)\n",
    "outBand=outDS.GetRasterBand(1)\n",
    "# data is the output array written in.tiff file\n",
    "outBand.WriteArray(data,0,0)\n",
    "outDS=None\n",
    "\n",
    "            \n",
    "############\n",
    "from osgeo import gdal\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# import \n",
    "ds = gdal.Open(\"dem.tif\")\n",
    "gt = ds.GetGeoTransform()\n",
    "proj = ds.GetProjection()\n",
    "\n",
    "band = ds.GetRasterBand(1)\n",
    "array = band.ReadAsArray()\n",
    "\n",
    "plt.figure()\n",
    "plt.imshow(array)\n",
    "\n",
    "# manipulate\n",
    "#binmask = np.where((array \\&gt = np.mean(array)),1,0)\n",
    "#plt.figure()\n",
    "#plt.imshow(binmask)\n",
    "\n",
    "# export\n",
    "driver = gdal.GetDriverByName(\"GTiff\")\n",
    "driver.Register()\n",
    "outds = driver.Create(\"output.tif\", xsize = array.shape[1],\n",
    "                      ysize = array.shape[0], bands = 1, \n",
    "                      eType = gdal.GDT_Int16) # GDT_Byte \n",
    "outds.SetGeoTransform(gt)\n",
    "outds.SetProjection(proj)\n",
    "outband = outds.GetRasterBand(1)\n",
    "outband.WriteArray(array)\n",
    "outband.SetNoDataValue(np.nan)\n",
    "outband.FlushCache()\n",
    "\n",
    "# close your datasets and bands!!!\n",
    "outband = None\n",
    "outds = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83289b31",
   "metadata": {},
   "outputs": [],
   "source": [
    "# EXTRA FOR PLOTTING/ SAVING BAND AS PNG\n",
    "\n",
    "\n",
    "      # extra to plot the NDSI and NIR  \n",
    "      #  for channels in bands:\n",
    "       #     i += 1\n",
    "       #     print(\"i\", i)\n",
    "          #  fig, ax = plt.subplots(2, 6, figsize=(15,10))\n",
    "          #  ax[0, 2].imshow(b03, cmap='cubehelix')\n",
    "          #  ax[0, 2].set_title('Green')\n",
    "          #  ax[1, 0].imshow(b08, cmap='cubehelix')\n",
    "          #  ax[1, 0].set_title('Vegetation Red Edge ')\n",
    "          #  ax[1, 3].imshow(b11, cmap='cubehelix')\n",
    "          #  ax[1, 3].set_title('SWIR')\n",
    "          #  ax[1, 3].axis('off')\n",
    "\n",
    "        #    os.chdir('/Users/emilybirch/Documents/UCL_Dissertation/Data_collection/WMS_all_bands')\n",
    "        #    plt.savefig(\"can_bands_{}.tif\".format(i),\n",
    "        #                bbox_inches='tight',\n",
    "        #                    dpi=600)\n",
    "\n",
    "         #   plt.show()\n",
    "       \n",
    "\n",
    "      \n",
    " #   def calc_ndsi(self, b03, b11, bands):\n",
    "        \"\"\"\n",
    "        Plot ndsi using certain bands\n",
    "        EXPORT AS PNG\n",
    "        \"\"\"\n",
    "       # NDVI = (b04  b03) / (b04 + b03)       \n",
    "        # plot true colour image:\n",
    "       # ax[0].imshow(basemap)\n",
    "       # ax[0].set_title('True Colour Composite')  \n",
    "        # Normalised difference snow index \n",
    "    \n",
    "  #      os.chdir('/Users/emilybirch/Documents/UCL_Dissertation/Data_collection/NDSI')\n",
    "  #      i = 0\n",
    "  #      NDSI = (b03 - b11)/(b03 + b11)\n",
    "  #      for ndsi_im in bands:\n",
    "  #          i += 1\n",
    "        #   ndsi_im = Image.fromarray(NDSI) #.save('can_NDSI_{}.tif'.format(i)) # NDSI.astype(np.uint8)\n",
    " #           fig, ax = plt.subplots(1, 1, figsize=(15,10))\n",
    "  #          plt.imshow(NDSI, cmap='Blues')\n",
    "   #         plt.axis('off')            \n",
    "   ##         plt.savefig('can_NDSI_{}.tif'.format(i),\n",
    "   #                     bbox_inches='tight', dpi=600, format=\"tiff\")\n",
    "   #         plt.show()  "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
