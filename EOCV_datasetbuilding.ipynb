{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "behavioral-panama",
   "metadata": {},
   "source": [
    "# Building EO training/validation/testing datasets with the Sentinelhub API"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "presidential-developer",
   "metadata": {},
   "source": [
    "#### The following modules/Libraries will be needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9f5ea95e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentinelhub import BBox, CRS, DataCollection, SHConfig, WmsRequest, WcsRequest, DataSource, MimeType\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from datetime import date, timedelta\n",
    "from scipy.ndimage.filters import uniform_filter\n",
    "from scipy.ndimage.measurements import variance\n",
    "import rasterio\n",
    "import numpy as np\n",
    "import datetime\n",
    "\n",
    "import os \n",
    "from osgeo import gdal\n",
    "import glob\n",
    "\n",
    "import imageio\n",
    "\n",
    "from PIL import Image\n",
    "import io\n",
    "\n",
    "from rasterio.transform import from_bounds\n",
    "\n",
    "import rasterio\n",
    "from matplotlib import pyplot\n",
    "from rasterio.plot import show\n",
    "\n",
    "import numpy as np\n",
    "import os "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "funny-nashville",
   "metadata": {},
   "source": [
    "### Prerequisites\n",
    "\n",
    "#### Sentinel Hub account\n",
    "\n",
    "In order to use Sentinel Hub services you will need a Sentinel Hub account. If you do not have one yet, you can create a free trial account at [Sentinel Hub webpage](https://services.sentinel-hub.com/oauth/subscription). If you are a researcher you can even apply for a free non-commercial account at [ESA OSEO page](https://earth.esa.int/aos/OSEO).\n",
    "\n",
    "Once you have the account set up, login to [Sentinel Hub Configurator](https://apps.sentinel-hub.com/configurator/). Inside there will already exist one configuration with an **instance ID** (alpha-numeric code of length 36). For this tutorial it is recommended that you create a new configuration (`\"Add new configuration\"`) and set the configuration to be based on **Python scripts template**. Such configuration will already contain all layers used in these examples. Otherwise you will have to define the layers for your  configuration yourself.\n",
    "\n",
    "After you have decided which configuration to use, you have two options. You can either put configuration's **instance ID** into `sentinelhub` package's configuration file following the [configuration instructions](http://sentinelhub-py.readthedocs.io/en/latest/configure.html) or you can write it down in the following cell:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "boolean-chancellor",
   "metadata": {},
   "source": [
    "Generate a configuration:\n",
    "This is done using the ID.\n",
    "This is so that sentinelhub knows you are authorised to use their service, and which parts of the service you want to use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "coral-conjunction",
   "metadata": {},
   "outputs": [],
   "source": [
    "INSTANCE_ID = '432b0edf-79be-4d35-99b5-ac3414ba9b4f'\n",
    "if INSTANCE_ID:\n",
    "    config = SHConfig()\n",
    "    config.instance_id = INSTANCE_ID\n",
    "else:\n",
    "    config = None\n",
    "\n",
    "print(config)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13999317",
   "metadata": {},
   "source": [
    "If you just wanted to download a true colour composite, you could use WcsRequest()\n",
    "If you want to access the full Sentinel-2 product (with all channels) you can use wms request.\n",
    "We can  then use band 2 and band 11 (SWIR and Blue) to create a normalised difference snow index (NDSI) and the normalised difference water index"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "virtual-civilization",
   "metadata": {},
   "source": [
    "Define a region and a random test date "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1036f3f3",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "class SentinelData:\n",
    "    \"\"\"\n",
    "    Retreiveing Sentinel data from Sentinel Hub\n",
    "    initialise class with coordinates list, resolution, bounding box coordinates, years and month ranges\n",
    "    make a wcs request for data between November-April\n",
    "    \"\"\"\n",
    "    def __init__(self, coords_list, years, day_month_to, day_month_from):\n",
    "        self.coords_list = coords_list\n",
    "        self.resolution = '10m'\n",
    "        self.area_coords = BBox(bbox=self.coords_list, crs=CRS.WGS84)\n",
    "        self.year_range = years # make a set of years to iterate over \n",
    "        self.day_month_to = day_month_to\n",
    "        self.day_month_from = day_month_from\n",
    "        \n",
    "        \n",
    "        \n",
    "    def retrieve_data(self):\n",
    "        \"\"\" \n",
    "        Create a bounding box and assign CRS. \n",
    "        Create a wcs data request from Sentinel for Sentinel-2 data. \n",
    "        Define max clouds as 20%\n",
    "        \"\"\"\n",
    "        for year in self.year_range:\n",
    "            time_from = \"{}-{}\".format(year, self.day_month_from)\n",
    "            print(\"time_from\", time_from)\n",
    "            time_to = \"{}-{}\".format(year + 1,  self.day_month_to)\n",
    "            print(\"time_to\", time_to)\n",
    "            # make the request for the desired date range \n",
    "            wcs_true_color_request = WcsRequest (\n",
    "                data_collection=DataCollection.SENTINEL2_L1C,\n",
    "                layer='TRUE-COLOR-S2-L2A', # Layer you have configured\n",
    "                bbox=self.area_coords,\n",
    "                time= (time_from, time_to),\n",
    "                resx=self.resolution, # Stick to 10m resolution as this the maximum possible \n",
    "                resy=self.resolution, \n",
    "                config=config,\n",
    "                maxcc=0 # You can define the maximum ammount of cloud coverage you want to allow. \n",
    "            )\n",
    "            print(\"WCS: \", wcs_true_color_request)\n",
    "    \n",
    "            available_dates_list = wcs_true_color_request.get_dates()\n",
    "            print(\"avail dates list: \", available_dates_list)\n",
    "            yield from available_dates_list\n",
    "            \n",
    "    \n",
    "    def get_available_data(self):\n",
    "        \"\"\"\n",
    "        Use get_data() function from Sentinel to retrieve available data for the dates.\n",
    "        \"\"\"\n",
    "        available_dates_list = self.retrieve_data()\n",
    "        i = 0\n",
    "        for date in available_dates_list:\n",
    "            i += 1\n",
    "            print(\"date\", date)\n",
    "            \n",
    "            wcs_true_color_request = WcsRequest(\n",
    "                data_collection=DataCollection.SENTINEL2_L1C,\n",
    "                layer='TRUE-COLOR-S2-L2A', # Layer you have configured\n",
    "                bbox=self.area_coords, \n",
    "                time= date,\n",
    "                resx=self.resolution, # Stick to 10m resolution as this the maximum possible \n",
    "                resy=self.resolution, \n",
    "                config=config,\n",
    "                maxcc=0,# You can define the maximum ammount of cloud coverage you want to allow.\n",
    "                data_folder='/Users/emilybirch/Documents/UCL_Dissertation' \n",
    "            )\n",
    "            \n",
    "            basemap = wcs_true_color_request.get_data()[0] \n",
    "            \n",
    "            # call the bands_req function to wms request for bands on available dates\n",
    "            call_wms = self.bands_req(basemap, date, i) # basemap,\n",
    "            \n",
    "            print('Returned data is of type = %s and length %d.' % (type(basemap), len(basemap)))\n",
    "            print(f'Single element in the list is of type {type(basemap[-1])} and has shape {basemap[-1].shape}')\n",
    "           \n",
    "            \n",
    "            \n",
    "\n",
    "            \n",
    "    def bands_req(self, basemap, date, i):\n",
    "        \"\"\"\n",
    "        wms bands request for the bands making up the Sentinel pic\n",
    "        \"\"\"\n",
    "       # for basemap in self.get_available_wms_data():\n",
    "        basemap = np.array(basemap)\n",
    "        wms_bands_request = WmsRequest(\n",
    "            data_collection=DataCollection.SENTINEL2_L1C,\n",
    "            layer='BANDS-S2-L2A', # We are using the 'BANDS-S2-L2A layer now'\n",
    "            bbox= self.area_coords, # [50.19571, -124.25775, 49.98687, -123.90537], \n",
    "            width=basemap.shape[1], # 10m resolution dims are sourced from the basemap. \n",
    "            height=basemap.shape[0],\n",
    "            time=(date),\n",
    "            image_format=MimeType.TIFF, \n",
    "            maxcc=0,\n",
    "            #resx='10m',\n",
    "           # resy = '10',\n",
    "            config=config,\n",
    "            data_folder='/Users/emilybirch/Documents/UCL_Dissertation/Data_collection/WMS_all_bands' \n",
    "        )        \n",
    "        \n",
    "        bands = wms_bands_request.get_data()[-1] # save_data=True\n",
    "        bands = np.array(bands)\n",
    "        bands = bands.astype('float32') \n",
    "           \n",
    "        # call the split_bands function\n",
    "        get_channels = self.split_bands(bands, basemap, i)\n",
    "\n",
    " \n",
    " \n",
    "# Four coordinates representing the top-left and bottom-right of the bounding box must be separated by comma\n",
    "# The bounding box in WGS84 coordinate system is (longitude and latitude coordinates of upper left and lower right corners)\n",
    "# n,w, s,e\n",
    "\n",
    " #a list of comma-separated numbers of the form \"minx,miny,maxx,maxy\".       \n",
    " # s2, w2 = 49.98434, -124.25091 w,s,n,e\n",
    "#n2, e2 = 50.19579, -123.90758   \n",
    "\n",
    "# wms should be latitude, long\n",
    "\n",
    "\n",
    "    \n",
    "    def plot_data(self):   \n",
    "        \"\"\"\n",
    "        Plot the RGB satellite pics to check its correct/cloud cover is acceptable\n",
    "        and that the image is not cropped.\n",
    "        \"\"\"\n",
    "        basemap = self.get_available_data()\n",
    "        i = 0\n",
    "        for sat_img in basemap:\n",
    "            i += 1\n",
    "            print(\"i\", i)\n",
    "            fig, ax = plt.subplots(1, 1, figsize=(10,10))\n",
    "            plt.imshow(sat_img)\n",
    "            plt.axis('off')\n",
    "            plt.savefig('ala_sat_4_{}.png'.format(i),\n",
    "                        bbox_inches='tight',\n",
    "                        dpi=300)\n",
    "            plt.show()\n",
    "          \n",
    "\n",
    " \n",
    "       \n",
    "        \n",
    "    # Download NIR (b08), DEM and Raw NDSI (no thresholding)          \n",
    "    def split_bands(self, bands, basemap, i):\n",
    "        \"\"\"\n",
    "        Split the bands req into individual bands\n",
    "        Download NIR b08 as single band .tif\n",
    "        Calculate NDSI and download this as .tif\n",
    "        \"\"\"\n",
    "        #bands = self.get_available_wms_data()\n",
    "            \n",
    "        b01 = bands[:,:,0] # Coastal Aerosol\n",
    "        b02 = bands[:,:,1] # Blue\n",
    "        b03 = bands[:,:,2] # Green\n",
    "        b04 = bands[:,:,3] # Red\n",
    "        b05 = bands[:,:,4] # Vegetation Red Edge \n",
    "        b06 = bands[:,:,5] # Vegetation Red Edge\n",
    "        b07 = bands[:,:,6] # Vegetation Red Edge\n",
    "        b08 = bands[:,:,7] # NIR\n",
    "        b08a = bands[:,:,8] # Vegetation Red Edge\n",
    "        b09 = bands[:,:,9] # Water Vapour\n",
    "        b11 = bands[:,:,10] # SWIR\n",
    "        b12 = bands[:,:,11] # SWIR\n",
    "        \n",
    "        \n",
    "        # check b08 is array\n",
    "        print(\"TYPE OF B08:\",(type(b08)))\n",
    " \n",
    "        # get NIR band as .tif\n",
    "        raster = b08\n",
    "        dim = raster.shape\n",
    "        print(dim)\n",
    "        height = dim[0] \n",
    "        print(\"height\", height)\n",
    "        width = dim[1] \n",
    "        print(\"width\", width)\n",
    "       # transform - NEEDS TO BE W,S,E,N. CURRENTLY THE BBOX COORDS ARE S,W,N,E. SO NEED TO SWITCH TO 116,50 NOT 50,116\n",
    "        transform=from_bounds(168.67527, -44.64093, 168.99039, -44.42578, width, height)  # self.coords_list\n",
    "        print(\"TRANSFORM:\", transform)\n",
    "        os.chdir('/Users/emilybirch/Documents/UCL_Dissertation/Data_collection/NIR')\n",
    "        out_path = ('b08_nz_bbox1_{}.tif'.format(i)) \n",
    "        print(\"OUT PATH\", out_path)\n",
    "\n",
    "        write_NIR_band = write_single_channel_gtiff(raster, width, height, transform, out_path)  # self. ?\n",
    "        print(write_NIR_band)\n",
    "\n",
    "        ###########\n",
    "        # calc NDSI from bands\n",
    "        NDSI = (b03 - b11)/(b03 + b11)\n",
    "        raster = NDSI\n",
    "        dim = raster.shape\n",
    "        print(dim)\n",
    "        height = dim[0] \n",
    "        print(\"height\", height)\n",
    "        width = dim[1] \n",
    "        print(\"width\", width)\n",
    "       # transform - NEEDS TO BE W,S,E,N. CURRENTLY THE BBOX COORDS ARE S,W,N,E. SO NEED TO SWITCH TO 116,50 NOT 50,116\n",
    "        transform=from_bounds(168.67527, -44.64093, 168.99039, -44.42578, width, height)  # self.coords_list\n",
    "        print(\"TRANSFORM:\", transform)\n",
    "        os.chdir('/Users/emilybirch/Documents/UCL_Dissertation/Data_collection/NDSI')\n",
    "        out_path = ('NDSI_nz_bbox1_{}.tif'.format(i)) \n",
    "        print(\"OUT PATH\", out_path)\n",
    "\n",
    "        write_NDSI_band = write_single_channel_gtiff(raster, width, height, transform, out_path)  # self. ?\n",
    "        print(write_NDSI_band)\n",
    "\n",
    "        \n",
    "\n",
    "# W,S,E,N. SO NEED TO SWITCH TO 116,50\n",
    "\n",
    "# can box1- -116.08768, 50.82675, -115.73474,51.02583 \n",
    "# canbb0x 2. -123.27264, 49.60259, -122.94511, 49.80043. b08_can_bbox2_{}.tif\n",
    "# can box3. -124.25091, 49.98434, -123.90758, 50.19579. b08_can_bbox3_{}.tif\n",
    "\n",
    "# france box1. 6.68625, 46.00263, 7.00556, 46.21018. b08_fr_bbox1_{}.tif\n",
    "# fr box2. 6.26995, 44.5032, 6.57683, 44.71395. b08_fr_bbox2_{}.tif\n",
    "# fr box3. 6.75874, 47.89925, 7.0709, 48.0968. b08_fr_bbox3_{}.tif\n",
    "\n",
    "# Nz box1. 168.67527, -44.64093, 168.99039, -44.42578. b08_nz_bbox1_{}.tif\n",
    "# nz box 2. 169.15172, -44.46215, 169.4559,-44.26874. b08_nz_bbox2_{}.tif\n",
    "# nz box 3. 167.32814, -45.57742, 167.63988, -45.37906. b08_nz_bbox3_{}.tif\n",
    "# nz box 4. 168.7185, -44.21029, 169.00415, -43.99234. b08_nz_bbox4_{}.tif\n",
    "\n",
    "# norway box1. 6.71053, 61.19427, 7.14765, 61.39842. b08_nor_bbox1_{}.tif\n",
    "# nor box2. 11.91172, 62.11413, 12.35366, 62.31454. b08_nor_bbox2_{}.tif\n",
    "# nor box3. 11.68324, 64.5321, 12.17067, 64.72623. b08_nor_bbox3_{}.tif\n",
    "\n",
    "# argentina box1. -70.60757, -36.1615, -70.87261, -36.35363. b08_arg_bbox1_{}.tif\n",
    "# arg box2. -71.07906, -36.90052,-70.80853, -36.7103. b08_arg_bbox2_{}.tif\n",
    "# arg box3. -72.33129, -48.25276, -72.0168, -48.05762. b08_arg_bbox3_{}.tif\n",
    "\n",
    "# alaska box1. -144.4895, 60.58666, -144.04753, 60.78174. b08_al_bbox1_{}.tif\n",
    "# al box2. -145.6761, 60.54723, -145.24079, 60.74312. b08_al_bbox2_{}.tif\n",
    "# al box 3. -146.57959, 60.86118, -146.14288, 61.05052. b08_al_bbox3_{}.tif\n",
    "# al box 4. -146.62525, 61.10963, -146.18168, 61.30145. b08_al_bbox4_{}.tif\n",
    "\n",
    "\n",
    "def write_single_channel_gtiff(raster, width, height, transform, out_path): \n",
    "    \"\"\"\n",
    "    Function to write a single channel .tif file. \n",
    "    Retains the geographic info- extent, crs etc. \n",
    "    \"\"\"\n",
    "    assert len(raster.shape) == 2\n",
    "    print(f'Writing...{out_path}')\n",
    "    with rasterio.open(str(out_path),\n",
    "                       mode='w',\n",
    "                       crs= 'EPSG:4326',   # wgs84         \n",
    "                       driver= 'GTIFF',                \n",
    "                       nodata=  np.nan,\n",
    "                       dtype= rasterio.float32,   # raster.dtype   #  rasterio.uint8,               \n",
    "                       count= 1,                 \n",
    "                       height= height,         \n",
    "                       width= width,     \n",
    "                       # compress='lzw'\n",
    "                       transform=transform # w2, s2, e2, n2, width, height. From bbox\n",
    "                       ) as dst:\n",
    "        dst.write(raster, 1) #.astype(np.uint8)\n",
    "        \n",
    "\n",
    "\n",
    "# call\n",
    "# define the years and month ranges for data. Nov-April so there is snow cover.\n",
    "# Sentinel 2 data is only available from 2015 onwards\n",
    "canada_years = {2014, 2015, 2016, 2017, 2018, 2019, 2020}\n",
    "\n",
    "# define the years and month ranges for data. Nov-April\n",
    "canada_day_month_to = \"01-01\"\n",
    "canada_day_month_from = \"01-01\"\n",
    "\n",
    "# canada 0%CC. BBOX1. CANADIAN ROCKIES\n",
    "s4, w4 = 50.82675, -116.08768\n",
    "n4, e4 = 51.02583, -115.73474       \n",
    "\n",
    "\n",
    "# CANADA BBOX2 0%CC. VANCOUVER. takes a long time to plot (90 plots)\n",
    "s5, w5 = 49.60259, -123.27264\n",
    "n5, e5 = 49.80043, -122.94511\n",
    "    \n",
    "\n",
    "# canada BBOX3. nr vancouver \n",
    "s6, w6 = 49.98434, -124.25091\n",
    "n6, e6 = 50.19579, -123.90758\n",
    "       \n",
    "    \n",
    "coords_canada1 = [w4, s4, e4, n4]\n",
    "coords_canada2 = [w5, s5, e5, n5]\n",
    "coords_canada3 = [w6, s6, e6, n6]\n",
    "\n",
    "can_data1 = SentinelData(coords_canada1, canada_years, canada_day_month_to, canada_day_month_from)\n",
    "can_data2 = SentinelData(coords_canada2, canada_years, canada_day_month_to, canada_day_month_from)\n",
    "can_data3 = SentinelData(coords_canada3, canada_years, canada_day_month_to, canada_day_month_from)\n",
    "\n",
    "# wcs \n",
    "#plot_data_1 = canada_data.plot_data()\n",
    "\n",
    "\n",
    "# get wms\n",
    "#plot_canada_wms1 = can_data1.get_available_data()\n",
    "#plot_canada_wms2 = can_data2.get_available_data()\n",
    "#plot_canada_wms3 = can_data3.get_available_data() \n",
    "    \n",
    "  \n",
    " \n",
    "# FORESTED:\n",
    "\n",
    "# 1. \n",
    "\n",
    "# FRANCE BBOX 1. 0%CC\n",
    "s, w = 46.00263, 6.68625\n",
    "n, e = 46.21018, 7.00556\n",
    "\n",
    "\n",
    "# FRANCE BBOX 2. 0%CC\n",
    "s2, w2 = 44.5032, 6.26995\n",
    "n2, e2 = 44.71395, 6.57683\n",
    "\n",
    "# FRANCE BBOX 3. 0%CC. in Vosges mountains. \n",
    "s3, w3 = 47.89925, 6.75874\n",
    "n3, e3 = 48.0968, 7.0709\n",
    "    \n",
    "coords_fr1 = [w, s, e, n]\n",
    "coords_fr2 = [w2, s2, e2, n2]\n",
    "coords_fr3 = [w3, s3, e3, n3]\n",
    "\n",
    "fr_data1 = SentinelData(coords_fr1, canada_years, canada_day_month_to, canada_day_month_from)\n",
    "fr_data2 = SentinelData(coords_fr2, canada_years, canada_day_month_to, canada_day_month_from)\n",
    "fr_data3 = SentinelData(coords_fr3, canada_years, canada_day_month_to, canada_day_month_from)\n",
    "\n",
    "\n",
    "# get wms\n",
    "#plot_fr_wms1 = fr_data1.get_available_data()\n",
    "#plot_fr_wms2 = fr_data2.get_available_data()\n",
    "#plot_fr_wms3 = fr_data3.get_available_data()\n",
    "\n",
    "\n",
    "# NEW ZEALAND 0% CC. BBOX1. FORESTED. gets 3 3/4 pics \n",
    "s7, w7 = -44.64093, 168.67527\n",
    "n7,e7 = -44.42578, 168.99039\n",
    "\n",
    "\n",
    "# NZ BBOX 2 FORESTED. 3 pics  \n",
    "s8,w8 = -44.46215, 169.15172\n",
    "n8,e8 = -44.26874, 169.4559\n",
    "\n",
    "\n",
    "# NZ BBOX 3. 3 pics \n",
    "s9,w9 = -45.57742, 167.32814\n",
    "n9,e9 = -45.37906, 167.63988\n",
    "\n",
    "\n",
    "# NZ bbox 4. \n",
    "s10,w10 = -44.21029, 168.7185\n",
    "n10, e10 = -43.99234, 169.00415\n",
    "    \n",
    "\n",
    "\n",
    "coords_nz1 = [w7, s7, e7, n7]\n",
    "coords_nz2 = [w8, s8, e8, n8]\n",
    "coords_nz3 = [w9, s9, e9, n9]\n",
    "coords_nz4 = [w10, s10, e10, n10]\n",
    "\n",
    "\n",
    "nz_data1 = SentinelData(coords_nz1, canada_years, canada_day_month_to, canada_day_month_from)\n",
    "nz_data2 = SentinelData(coords_nz2, canada_years, canada_day_month_to, canada_day_month_from)\n",
    "nz_data3 = SentinelData(coords_nz3, canada_years, canada_day_month_to, canada_day_month_from)\n",
    "nz_data4 = SentinelData(coords_nz4, canada_years, canada_day_month_to, canada_day_month_from)\n",
    "\n",
    "\n",
    "# get wms\n",
    "#plot_nz_wms1 = nz_data1.get_available_data()\n",
    "#plot_nz_wms2 = nz_data2.get_available_data()\n",
    "#plot_nz_wms3 = nz_data3.get_available_data()\n",
    "#plot_nz_wms4 = nz_data4.get_available_data()\n",
    "        \n",
    "\n",
    "    \n",
    "    # NON-FORESTED:  \n",
    "\n",
    "\n",
    "# 4. \n",
    "\n",
    "\n",
    "\n",
    "# Norway. scandy mountains. \n",
    "s11, w11 = 61.19427, 6.71053\n",
    "n11, e11 = 61.39842, 7.14765\n",
    "  \n",
    "\n",
    "# BBOX 2 \n",
    "s12, w12 = 62.11413, 11.91172\n",
    "n12, e12 = 62.31454, 12.35366\n",
    "\n",
    "\n",
    "# BBOX 3. nr namsos\n",
    "s13, w13 = 64.5321, 11.68324\n",
    "n13, e13 = 64.72623, 12.17067\n",
    "\n",
    "\n",
    "\n",
    "coords_nor1 = [w11, s11, e11, n11]\n",
    "coords_nor2 = [w12, s12, e12, n12]\n",
    "coords_nor3 = [w13, s13, e13, n13]\n",
    "\n",
    "nor_data1 = SentinelData(coords_nor1, canada_years, canada_day_month_to, canada_day_month_from)\n",
    "nor_data2 = SentinelData(coords_nor2, canada_years, canada_day_month_to, canada_day_month_from)\n",
    "nor_data3 = SentinelData(coords_nor3, canada_years, canada_day_month_to, canada_day_month_from)\n",
    "\n",
    "\n",
    "# get wms\n",
    "#plot_nor_wms1 = nor_data1.get_available_data()\n",
    "#plot_nor_wms2 = nor_data2.get_available_data()\n",
    "#plot_nor_wms3 = nor_data3.get_available_data()\n",
    "\n",
    "# 5. \n",
    "\n",
    "\n",
    "# Argentina. bbox 1. \n",
    "s14, w14 = -36.1615, -70.60757\n",
    "n14, e14 = -36.35363, -70.87261\n",
    "    \n",
    "\n",
    "# Argentina BBOX2\n",
    "s15, w15 = -36.90052, -71.07906\n",
    "n15, e15 = -36.7103, -70.80853\n",
    "    \n",
    "   \n",
    " # Argentina BBOX3\n",
    "s16, w16 = -48.25276, -72.33129\n",
    "n16, e16 = -48.05762, -72.0168\n",
    "       \n",
    "coords_arg1 = [w14, s14, e14, n14]\n",
    "coords_arg2 = [w15, s15, e15, n15]\n",
    "coords_arg3 = [w16, s16, e16, n16]\n",
    "\n",
    "arg_data1 = SentinelData(coords_arg1, canada_years, canada_day_month_to, canada_day_month_from)\n",
    "arg_data2 = SentinelData(coords_arg2, canada_years, canada_day_month_to, canada_day_month_from)\n",
    "arg_data3 = SentinelData(coords_arg3, canada_years, canada_day_month_to, canada_day_month_from)\n",
    "\n",
    "\n",
    "# get wms\n",
    "plot_arg_wms1 = arg_data1.get_available_data()\n",
    "#plot_arg_wms2 = arg_data2.get_available_data()\n",
    "# plot_arg_wms3 = arg_data3.get_available_data()\n",
    "  \n",
    "\n",
    " \n",
    "# 6. \n",
    "\n",
    " # Alaska bbox1 3 pics\n",
    "s17, w17 = 60.58666, -144.4895\n",
    "n17, e17 = 60.78174, -144.04753\n",
    "    \n",
    "    \n",
    "    \n",
    "# alaska bbox 2 2 pics\n",
    "s18, w18 = 60.54723, -145.6761\n",
    "n18, e18 = 60.74312, -145.24079\n",
    "    \n",
    "\n",
    "    \n",
    "# alaska bbox 3. 3 pics\n",
    "s19, w19 = 60.86118, -146.57959\n",
    "n19, e19 = 61.05052, -146.14288\n",
    "\n",
    "\n",
    "# alaska bbox 4. 3 pics \n",
    "s20, w20 = 61.10963, -146.62525\n",
    "n20, e20 = 61.30145, -146.18168\n",
    "\n",
    "\n",
    "coords_al1 = [w17, s17, e17, n17]\n",
    "coords_al2 = [w18, s18, e18, n18]\n",
    "coords_al3 = [w19, s19, e19, n19]\n",
    "coords_al4 = [w20, s20, e20, n20]\n",
    "\n",
    "\n",
    "al_data1 = SentinelData(coords_al1, canada_years, canada_day_month_to, canada_day_month_from)\n",
    "al_data2 = SentinelData(coords_al2, canada_years, canada_day_month_to, canada_day_month_from)\n",
    "al_data3 = SentinelData(coords_al3, canada_years, canada_day_month_to, canada_day_month_from)\n",
    "al_data4 = SentinelData(coords_al4, canada_years, canada_day_month_to, canada_day_month_from)\n",
    "\n",
    "\n",
    "# get wms\n",
    "#plot_al_wms1 = al_data1.get_available_data()\n",
    "#plot_al_wms2 = al_data2.get_available_data()\n",
    "#plot_al_wms3 = al_data3.get_available_data()\n",
    "#plot_al_wms4 = al_data4.get_available_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "084ade12",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ON QGIS CONVERT DEM FROM INT 16 TO FLOAT 32\n",
    "#Algorithm Translate (convert format) starting…\n",
    "#Input parameters:\n",
    "#{'COPY_SUBDATASETS': True,\n",
    "#'DATA_TYPE': 6,\n",
    "#'EXTRA': '',\n",
    "#'INPUT': 'mergedNzDEM4_3381f8a4_705b_4477_982b_57a90f59bddb',\n",
    "#'NODATA': None,\n",
    "#'OPTIONS': '',\n",
    "#'OUTPUT': <QgsProcessingOutputLayerDefinition {'sink':/Users/emilybirch/Documents/UCL_Dissertation/Data_collection/DEM/Directory_for_DEM/DEM_float32/al_DEM1mergedNzDEM4.tif, 'createOptions': {}}>,\n",
    "#'TARGET_CRS': None}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f73d575",
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://stackoverflow.com/questions/10454316/how-to-project-and-resample-a-grid-to-match-another-grid-with-gdal-python \n",
    "# crops AND resamples!!\n",
    "\n",
    "from osgeo import gdal, gdalconst\n",
    "\n",
    "# dems have already been converted to the same data type float 32 on qgis\n",
    "# cropping and matching the resolution of DEMs to the b08 band\n",
    "# only need to resample and crop 1 dem per bbox. \n",
    "# then duplicate this for however many pics are at this bbox:\n",
    "# - canada: box1 x 4 , b2 x 3, b3 x 5\n",
    "# - France: box1 x 4, b2 x 4, b3 x 4\n",
    "# - NZ: box1 x 3, b2 x 3, b3 x 3, b4 x 3\n",
    "# - Alaska: box1 x 4, b2 x 2, b3 x 3, b4 x 3\n",
    "# - Argentina: b1 x 5, b2 x 3, b3 x 4 \n",
    "#- Norway: b1 x5, b2 x 4, b3 x 4\n",
    "\n",
    "# 20 boxes in total so need to resamp and crop 20 DEM pics\n",
    "\n",
    "\n",
    "\n",
    "def resamp_crop(dem_file, nir_file, out_file):\n",
    "    \"\"\"\n",
    "    resample the DEM to the same resolution as the NIR band\n",
    "    crop the DEM to the same extent as the NIR band\n",
    "    \"\"\"\n",
    "    # Source. the DEM from DEM_float32 folder \n",
    "    os.chdir('/Users/emilybirch/Documents/UCL_Dissertation/Data_collection/DEM/Directory_for_DEM/DEM_float32')\n",
    "    src_filename = dem_file\n",
    "    print(\"DEM_PATH\", dem_file)\n",
    "    src = gdal.Open(src_filename, gdalconst.GA_ReadOnly)\n",
    "    src_proj = src.GetProjection()\n",
    "    src_geotrans = src.GetGeoTransform()\n",
    "\n",
    "    # section of source that matches this. using band 8 (NIR) as the one to crop and resample to\n",
    "    os.chdir('/Users/emilybirch/Documents/UCL_Dissertation/Data_collection/NIR')\n",
    "    match_filename = nir_file\n",
    "    match_ds = gdal.Open(match_filename, gdalconst.GA_ReadOnly)\n",
    "    match_proj = match_ds.GetProjection()\n",
    "    match_geotrans = match_ds.GetGeoTransform()\n",
    "    wide = match_ds.RasterXSize\n",
    "    high = match_ds.RasterYSize\n",
    "\n",
    "    # Output / destination\n",
    "    os.chdir('/Users/emilybirch/Documents/UCL_Dissertation/Data_collection/DEM/resamp_crop_DEM')\n",
    "    dst_filename = out_file\n",
    "    print(\"out_put file:\", dst_filename)\n",
    "    dst = gdal.GetDriverByName('GTiff').Create(dst_filename, wide, high, 1, gdalconst.GDT_Float32)\n",
    "    dst.SetGeoTransform( match_geotrans )\n",
    "    dst.SetProjection( match_proj)\n",
    "\n",
    "    # Do the work\n",
    "    gdal.ReprojectImage(src, dst, src_proj, match_proj, gdalconst.GRA_Bilinear)\n",
    "\n",
    "    del dst # Flush\n",
    "\n",
    "    \n",
    "    \n",
    "# call. Arg bbox1 pic 1\n",
    "dem_file14 = 'DEM_Argb1.tif' \n",
    "nir_file14 = 'new_NIR_box1_pic2.tif' \n",
    "out_file14 = 'RESAMPLED_PIC.tif' \n",
    "callArg14 = resamp_crop(dem_file14, nir_file14, out_file14)\n",
    "\n",
    "    \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29c59093",
   "metadata": {},
   "outputs": [],
   "source": [
    "# call. Alaska bbox3 \n",
    "dem_file13 = 'AlaskaDEMbox3.tif'\n",
    "nir_file13 = 'b08_al_bbox3_2.tif'\n",
    "out_file13 = 'Resampled_Alb3.tif'\n",
    "callAl13 = resamp_crop(dem_file13, nir_file13, out_file13)\n",
    "\n",
    "\n",
    "# alaska box 4. alaska_box4_DEM\n",
    "dem_file11 = 'alaska_box4_DEM.tif'\n",
    "nir_file11 = 'b08_al_bbox4_2.tif'\n",
    "out_file11 = 'Resampled_Alb4.tif'\n",
    "callAl11 = resamp_crop(dem_file11, nir_file11, out_file11)\n",
    "\n",
    "# call. Alaska bbox2 \n",
    "dem_file12 = 'alaskabox2_DEMfloat.tif'\n",
    "nir_file12 = 'b08_al_bbox2_2.tif'\n",
    "out_file12 = 'Resampled_Alb2_final.tif'\n",
    "callAl12 = resamp_crop(dem_file12, nir_file12, out_file12)\n",
    "\n",
    "\n",
    "# call. Arg bbox1 \n",
    "dem_file14 = 'argentinabox1DEM.tif'\n",
    "nir_file14 = 'b08_arg_bbox1_1.tif'\n",
    "out_file14 = 'Resampled_Argb1.tif'\n",
    "callArg14 = resamp_crop(dem_file14, nir_file14, out_file14)\n",
    "\n",
    "\n",
    "\n",
    "# call. Arg bbox3 \n",
    "dem_file16 = 'argentinaDEMbox3.tif'\n",
    "nir_file16 = 'b08_arg_bbox3_32.tif'\n",
    "out_file14 = 'Resampled_Argb3.tif'\n",
    "callArg14 = resamp_crop(dem_file14, nir_file14, out_file14)\n",
    "\n",
    "# call. NZ bbox2 \n",
    "dem_file8 = 'mNZbox2DEM.tif'\n",
    "nir_file8 = 'b08_nz_bbox2_3.tif'\n",
    "out_file8 = 'Resampled_Nzb2.tif'\n",
    "callnz8 = resamp_crop(dem_file8, nir_file8, out_file8)\n",
    "\n",
    "# call. NZ bbox3 \n",
    "dem_file9 = 'mNZbox3DEM.tif'\n",
    "nir_file9 = 'b08_nz_bbox3_2.tif'\n",
    "out_file9 = 'Resampled_Nzb3.tif'\n",
    "callnz9 = resamp_crop(dem_file9, nir_file9, out_file9)\n",
    "\n",
    "\n",
    "\n",
    "# call. Alaska bbox2 \n",
    "dem_file12 = 'mAlaskaBox2.tif'\n",
    "nir_file12 = 'b08_al_bbox2_2.tif'\n",
    "out_file12 = 'Resampled_Alb2.tif'\n",
    "callAl12 = resamp_crop(dem_file12, nir_file12, out_file12)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# call. Alaska bbox1 \n",
    "dem_file11 = 'al_DEM1mergedAlDEM1.tif'\n",
    "nir_file11 = 'b08_al_bbox1_2.tif'\n",
    "out_file11 = 'Resampled_Alb1.tif'\n",
    "callAl11 = resamp_crop(dem_file11, nir_file11, out_file11)\n",
    "\n",
    "\n",
    "# call. Al bbox2 \n",
    "dem_file12 = 'al_DEM1mergedAlDEM2.tif'\n",
    "nir_file12 = 'b08_al_bbox2_2.tif'\n",
    "out_file12 = 'Resampled_Alb2.tif'\n",
    "callAl12 = resamp_crop(dem_file12, nir_file12, out_file12)\n",
    "\n",
    "\n",
    "# call. Al bbox3 \n",
    "dem_file13 = 'al_DEM1mergedAlDEM3.tif'\n",
    "nir_file13 = 'b08_al_bbox3_2.tif'\n",
    "out_file13 = 'Resampled_Alb3.tif'\n",
    "callAl13 = resamp_crop(dem_file13, nir_file13, out_file13)\n",
    "\n",
    "\n",
    "# call. Arg bbox1 \n",
    "dem_file14 = 'al_DEM1mergedArgDEM1.tif'\n",
    "nir_file14 = 'b08_arg_bbox1_1.tif'\n",
    "out_file14 = 'Resampled_Argb1.tif'\n",
    "callArg14 = resamp_crop(dem_file14, nir_file14, out_file14)\n",
    "\n",
    "\n",
    "# call. Arg bbox2 \n",
    "dem_file15 = 'al_DEM1mergedArgDEM2.tif'\n",
    "nir_file15 = 'b08_arg_bbox2_1.tif'\n",
    "out_file15 = 'Resampled_Argb2.tif'\n",
    "callArg15 = resamp_crop(dem_file15, nir_file15, out_file15)\n",
    "\n",
    "\n",
    "# call. Arg bbox3 \n",
    "dem_file16 = 'al_DEM1mergedArgDEM3.tif'\n",
    "nir_file16 = 'b08_arg_bbox3_32.tif'\n",
    "out_file14 = 'Resampled_Argb3.tif'\n",
    "callArg14 = resamp_crop(dem_file14, nir_file14, out_file14)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# call. Norway bbox1 \n",
    "dem_file17 = 'al_DEM1mergedNorDEM1.tif'\n",
    "nir_file17 = 'b08_nor_bbox1_14.tif'\n",
    "out_file17 = 'Resampled_Norb1.tif'\n",
    "callArg17 = resamp_crop(dem_file17, nir_file17, out_file17)\n",
    "\n",
    "\n",
    "# call. Nor bbox2 \n",
    "dem_file18 = 'al_DEM1mergedNorDEM2.tif'\n",
    "nir_file18 = 'b08_nor_bbox2_1.tif'\n",
    "out_file18 = 'Resampled_Norb2.tif'\n",
    "callArg18 = resamp_crop(dem_file18, nir_file18, out_file18)\n",
    "\n",
    "\n",
    "# call. Nor bbox3 \n",
    "dem_file19 = 'al_DEM1mergedNorDEM3.tif'\n",
    "nir_file19 = 'b08_nor_bbox3_3.tif'\n",
    "out_file19 = 'Resampled_Norb3.tif'\n",
    "callArg19 = resamp_crop(dem_file19, nir_file19, out_file19)\n",
    "\n",
    "\n",
    "# call. NZ bbox1 \n",
    "dem_file7 = 'al_DEM1mergedNzDEM1.tif'\n",
    "nir_file7 = 'b08_nz_bbox1_6.tif'\n",
    "out_file7 = 'Resampled_Nzb1.tif'\n",
    "callnz7 = resamp_crop(dem_file7, nir_file7, out_file7)\n",
    "\n",
    "# call. NZ bbox2 \n",
    "dem_file8 = 'al_DEM1mergedNzDEM2.tif'\n",
    "nir_file8 = 'b08_nz_bbox2_3.tif'\n",
    "out_file8 = 'Resampled_Nzb2.tif'\n",
    "callnz8 = resamp_crop(dem_file8, nir_file8, out_file8)\n",
    "\n",
    "# call. NZ bbox3 \n",
    "dem_file9 = 'al_DEM1mergedNzDEM3.tif'\n",
    "nir_file9 = 'b08_nz_bbox3_2.tif'\n",
    "out_file9 = 'Resampled_Nzb3.tif'\n",
    "callnz9 = resamp_crop(dem_file9, nir_file9, out_file9)\n",
    "\n",
    "# call. NZ bbox4\n",
    "dem_file10 = 'al_DEM1mergedNzDEM4.tif'\n",
    "nir_file10 = 'b08_nz_bbox4_3.tif'\n",
    "out_file10 = 'Resampled_Nzb4.tif'\n",
    "callnz10 = resamp_crop(dem_file10, nir_file10, out_file10)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# call. Alaska bbox1 \n",
    "dem_file11 = 'al_DEM1mergedAlDEM1.tif'\n",
    "nir_file11 = 'b08_al_bbox1_2.tif'\n",
    "out_file11 = 'Resampled_Alb1.tif'\n",
    "callAl11 = resamp_crop(dem_file11, nir_file11, out_file11)\n",
    "\n",
    "\n",
    "# call. Al bbox2 \n",
    "dem_file12 = 'al_DEM1mergedAlDEM2.tif'\n",
    "nir_file12 = 'b08_al_bbox2_2.tif'\n",
    "out_file12 = 'Resampled_Alb2.tif'\n",
    "callAl12 = resamp_crop(dem_file12, nir_file12, out_file12)\n",
    "\n",
    "\n",
    "# call. Al bbox3 \n",
    "dem_file13 = 'al_DEM1mergedAlDEM3.tif'\n",
    "nir_file13 = 'b08_al_bbox3_2.tif'\n",
    "out_file13 = 'Resampled_Alb3.tif'\n",
    "callAl13 = resamp_crop(dem_file13, nir_file13, out_file13)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# call. Arg bbox1 \n",
    "dem_file14 = 'al_DEM1mergedArgDEM1.tif'\n",
    "nir_file14 = 'b08_arg_bbox1_1.tif'\n",
    "out_file14 = 'Resampled_Argb1.tif'\n",
    "callArg14 = resamp_crop(dem_file14, nir_file14, out_file14)\n",
    "\n",
    "\n",
    "# call. Arg bbox2 \n",
    "dem_file15 = 'al_DEM1mergedArgDEM2.tif'\n",
    "nir_file15 = 'b08_arg_bbox2_1.tif'\n",
    "out_file15 = 'Resampled_Argb2.tif'\n",
    "callArg15 = resamp_crop(dem_file15, nir_file15, out_file15)\n",
    "\n",
    "\n",
    "# call. Arg bbox3 \n",
    "dem_file16 = 'al_DEM1mergedArgDEM3.tif'\n",
    "nir_file16 = 'b08_arg_bbox3_32.tif'\n",
    "out_file14 = 'Resampled_Argb3.tif'\n",
    "callArg14 = resamp_crop(dem_file14, nir_file14, out_file14)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# call. Norway bbox1 \n",
    "dem_file17 = 'al_DEM1mergedNorDEM1.tif'\n",
    "nir_file17 = 'b08_nor_bbox1_8.tif'\n",
    "out_file17 = 'Resampled_Norb1.tif'\n",
    "callArg17 = resamp_crop(dem_file17, nir_file17, out_file17)\n",
    "\n",
    "\n",
    "# call. Nor bbox2 \n",
    "dem_file18 = 'al_DEM1mergedNorDEM2.tif'\n",
    "nir_file18 = 'b08_nor_bbox2_1.tif'\n",
    "out_file18 = 'Resampled_Norb2.tif'\n",
    "callArg18 = resamp_crop(dem_file18, nir_file18, out_file18)\n",
    "\n",
    "\n",
    "# call. Nor bbox3 \n",
    "dem_file19 = 'al_DEM1mergedNorDEM3.tif'\n",
    "nir_file19 = 'b08_nor_bbox3_3.tif'\n",
    "out_file19 = 'Resampled_Norb3.tif'\n",
    "callArg19 = resamp_crop(dem_file19, nir_file19, out_file19)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e4274fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "    \n",
    "# call. Canada bbox1 \n",
    "dem_file1 = 'al_DEM1mergedCanDEM1.tif'\n",
    "nir_file1 = 'b08_can_bbox1_1.tif'\n",
    "out_file1 = 'Resampled_Canb1.tif'\n",
    "call_can1 = resamp_crop(dem_file1, nir_file1, out_file1)\n",
    "\n",
    "\n",
    "# call. Canada bbox2\n",
    "dem_file2 = 'al_DEM1mergedCanDEM2.tif'\n",
    "nir_file2 = 'b08_can_bbox2_82.tif'\n",
    "out_file2 = 'Resampled_Canb2.tif'\n",
    "call_can2 = resamp_crop(dem_file2, nir_file2, out_file2)\n",
    "\n",
    "\n",
    "\n",
    "# call. Canada bbox3 \n",
    "dem_file3 = 'Can_merged_DEM3.tif'\n",
    "nir_file3 = 'b08_can_bbox3_1.tif'\n",
    "out_file3 = 'Resampled_Canb3.tif'\n",
    "call_can3 = resamp_crop(dem_file3, nir_file3, out_file3)\n",
    "\n",
    "\n",
    "\n",
    "# call. FR bbox1 \n",
    "dem_file4 = 'al_DEM1mergedFrDEM1.tif'\n",
    "nir_file4 = 'b08_fr_bbox1_2.tif'\n",
    "out_file4 = 'Resampled_Frb1.tif'\n",
    "call_fr4 = resamp_crop(dem_file4, nir_file4, out_file4)\n",
    "\n",
    "# call. FR bbox2 \n",
    "dem_file5 = 'al_DEM1mergedFrDEM2.tif'\n",
    "nir_file5 = 'b08_fr_bbox2_4.tif'\n",
    "out_file5 = 'Resampled_Frb2.tif'\n",
    "call_fr5 = resamp_crop(dem_file5, nir_file5, out_file5)\n",
    "\n",
    "# call. FR bbox3 \n",
    "dem_file6 ='al_DEM1mergedFrDEM3.tif'\n",
    "nir_file6 = 'b08_fr_bbox3_15.tif'\n",
    "out_file6 = 'Resampled_Frb3.tif'\n",
    "call_fr6 = resamp_crop(dem_file6, nir_file6, out_file6)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7cfffd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1ec8f02",
   "metadata": {},
   "outputs": [],
   "source": [
    "# stack DEM, NIR and NDSI and save as final .tif\n",
    "# EarthPy has a stack() function that allows you to take a set of .tif files that are all in the same \n",
    "# spatial extent, CRS and resolution and either export them together a single stacked .tif file or work with them in Python directly as a stacked numpy array.\n",
    "\n",
    "# use es.stack() function of earthpy library to create a raster stack of multi-band raster. It need three steps:\n",
    "\n",
    "#Create a raster list using glob() function\n",
    "#Create a path and define a name for mutli-band raster\n",
    "#Apply es.stack() to creat new stacked raster with all bands save as multi tif\n",
    "#Then apply rio.open to read the raster bands\n",
    "\n",
    "\n",
    "import os\n",
    "import glob\n",
    "import earthpy.plot as ep\n",
    "import earthpy.spatial as es\n",
    "import rasterio as rio\n",
    "\n",
    "import os\n",
    "os.chdir('/Users/emilybirch/Documents/UCL_Dissertation/Data_collection/stacked/Argentina') \n",
    "\n",
    "directory_to_check = \"/Users/emilybirch/Documents/UCL_Dissertation/Data_collection/stacked/Argentina\" \n",
    "\n",
    "# Get all the subdirectories of directory_to_check recursively and store them in a list:\n",
    "directories = [os.path.abspath(x[0]) for x in os.walk(directory_to_check)]\n",
    "directories.remove(os.path.abspath(directory_to_check)) # If you don't want your main directory included\n",
    "\n",
    "\n",
    "\n",
    "def stack_array(all_bands_list, new_tif_path):  \n",
    "    \"\"\"\n",
    "    stack DEM, raw NDSI and NIR (b08)\n",
    "    download multi-band .tif of all three bands\n",
    "\n",
    "    \"\"\" \n",
    "    print(\"\\t-\" + \"\\n\\t-\".join(os.listdir(\".\"))) # List current working directory\n",
    "    all_bands_list = all_bands_list \n",
    "    print(\"ALL BANDS path:\", all_bands_list)\n",
    "    with rio.open(all_bands_list[0]) as src:\n",
    "        meta = src.meta\n",
    "        print(\"META:\",meta)\n",
    "        # Update meta to reflect the number of layers\n",
    "        meta.update(count = len(all_bands_list))\n",
    "        new_stacked_tif = new_tif_path\n",
    "        print(\"NEW TIF:\", new_stacked_tif)\n",
    "        band_stack, bands_meta = es.stack(all_bands_list,\n",
    "                                        new_stacked_tif)      \n",
    "        with rio.open(new_stacked_tif) as src:\n",
    "            sentinel_multi = src.read() \n",
    "        os.chdir('/Users/emilybirch/Documents/UCL_Dissertation/Data_collection/stacked/Final_stacked_imagery')\n",
    "        # plot all bands\n",
    "        band_titles = [\"NIR\", \"NDSI\", \"DEM\"]\n",
    "        ep.plot_bands(sentinel_multi,\n",
    "                  title=band_titles, cbar=False)\n",
    "        plt.show()\n",
    "  \n",
    "\n",
    "\n",
    "\n",
    " \n",
    "#i = 0\n",
    "#for subdir in directories:\n",
    "#    i += 1\n",
    "#    os.chdir(subdir)         # Change working Directory\n",
    "#    new_tif_path = 'Arg_snow_labelled_{}.tif'.format(i)\n",
    "#    print(\"NEW file name:\", new_tif_path)\n",
    "#    list_files = glob.glob('*.tif')\n",
    "#    print(\"FILE LIST\", list_files)\n",
    "#    stack = stack_array(list_files, new_tif_path)  # run func\n",
    "    \n",
    "    \n",
    "        \n",
    "# LABEL SAME AS SNOW LABELLED PICS\n",
    "\n",
    "# Arg_snow_labelled_ !!!!!! convert to float32\n",
    "# FR_snow_labelled_\n",
    "#CN_snow_labelled_\n",
    "# NZ_snow_labelled_\n",
    "# Al_snow_\n",
    "# Nor_snow_\n",
    "\n",
    "                    \n",
    "        \n",
    "\n",
    "# Call for one individual pic:\n",
    "os.chdir('/Users/emilybirch/Documents/UCL_Dissertation/Data_collection/stacked/Argentina/ArgB3_pic12')\n",
    "os.getcwd()\n",
    "arg_bands_list = ['new_DEM_box3_pic10.tif', 'float_NDSI_arg_bbox3_5.tif', 'float_b08_arg_bbox3_5.tif'] \n",
    "# export as same name as snow labelled pis  \n",
    "\n",
    "new_tif_path = 'Arg_snow_labelled_12.tif'\n",
    "\n",
    "# call stack func\n",
    "arg_box3_pic10 = stack_array(arg_bands_list, new_tif_path)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "158a7974",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-7c80088bead2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     96\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     97\u001b[0m     \u001b[0;31m# REDEFINE THIS TO TIF DIMENSIONS\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 98\u001b[0;31m     \u001b[0mresized_array\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0marray_height\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marray_width\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# all pixels resized to\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     99\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    100\u001b[0m     \u001b[0mbasemap_tiles\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msplit_image\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdim_pix\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_tensor_dimensions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mresized_array\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/Dissertation_ML/lib/python3.7/site-packages/skimage/transform/_warps.py\u001b[0m in \u001b[0;36mresize\u001b[0;34m(image, output_shape, order, mode, cval, clip, preserve_range, anti_aliasing, anti_aliasing_sigma)\u001b[0m\n\u001b[1;32m    146\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    147\u001b[0m         image = ndi.gaussian_filter(image, anti_aliasing_sigma,\n\u001b[0;32m--> 148\u001b[0;31m                                     cval=cval, mode=ndi_mode)\n\u001b[0m\u001b[1;32m    149\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    150\u001b[0m     \u001b[0;31m# 2-dimensional interpolation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/Dissertation_ML/lib/python3.7/site-packages/scipy/ndimage/filters.py\u001b[0m in \u001b[0;36mgaussian_filter\u001b[0;34m(input, sigma, order, output, mode, cval, truncate)\u001b[0m\n\u001b[1;32m    340\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msigma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m \u001b[0;32min\u001b[0m \u001b[0maxes\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    341\u001b[0m             gaussian_filter1d(input, sigma, axis, order, output,\n\u001b[0;32m--> 342\u001b[0;31m                               mode, cval, truncate)\n\u001b[0m\u001b[1;32m    343\u001b[0m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    344\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/Dissertation_ML/lib/python3.7/site-packages/scipy/ndimage/filters.py\u001b[0m in \u001b[0;36mgaussian_filter1d\u001b[0;34m(input, sigma, axis, order, output, mode, cval, truncate)\u001b[0m\n\u001b[1;32m    258\u001b[0m     \u001b[0;31m# Since we are calling correlate, not convolve, revert the kernel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    259\u001b[0m     \u001b[0mweights\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_gaussian_kernel1d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msigma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 260\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mcorrelate1d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweights\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcval\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    261\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    262\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/Dissertation_ML/lib/python3.7/site-packages/scipy/ndimage/filters.py\u001b[0m in \u001b[0;36mcorrelate1d\u001b[0;34m(input, weights, axis, output, mode, cval, origin)\u001b[0m\n\u001b[1;32m    132\u001b[0m     \u001b[0mmode\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_ni_support\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_extend_mode_to_code\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    133\u001b[0m     _nd_image.correlate1d(input, weights, axis, output, mode, cval,\n\u001b[0;32m--> 134\u001b[0;31m                           origin)\n\u001b[0m\u001b[1;32m    135\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    136\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#split data\n",
    "# WORKS !!!!\n",
    "\n",
    "\n",
    "import image_slicer\n",
    "import math\n",
    "import os\n",
    "from PIL import Image\n",
    "from skimage.transform import resize   \n",
    "import numpy as np  \n",
    "\n",
    "\n",
    "# Split the Images\n",
    "def split_image(dim_pix, im):\n",
    "    # Find the number of sub-Images that fit in rows\n",
    "    rows = []\n",
    "    tiles = []\n",
    "    for i in range((math.floor(im.shape[0] / dim_pix))):\n",
    "        rows.append(i)\n",
    "    # Find the number of sub-Images that fit in rows\n",
    "    columns = []\n",
    "    for i in range((math.floor(im.shape[1] / dim_pix))):\n",
    "        columns.append(i)\n",
    "\n",
    "    # Numerically identify the sub-Images\n",
    "    a = 0\n",
    "    for i in rows:\n",
    "        for j in columns:\n",
    "            # Check for 244 x 244 (Mask) or 244 x 244 x 3 (TC Images)\n",
    "            if (im[0 + (dim_pix * j): dim_pix + (dim_pix * j),\n",
    "                  0 + dim_pix * i: dim_pix + (dim_pix * i)].shape[0]) == dim_pix:\n",
    "                if (im[0 + (dim_pix * j): dim_pix + (dim_pix * j),\n",
    "                  0 + dim_pix * i: dim_pix + (dim_pix * i)].shape[1]) == dim_pix:\n",
    "\n",
    "                    tile = im[0 + (dim_pix * j): dim_pix + (dim_pix * j),\n",
    "                            0 + dim_pix * i: dim_pix + (dim_pix * i)]\n",
    "\n",
    "                    # Stop white tiles for positive results\n",
    "                    count = np.count_nonzero(tile == 1) == (dim_pix * dim_pix)\n",
    "                    if count:\n",
    "                        all_black = np.tile(1, (dim_pix, dim_pix))\n",
    "                        tiles.append(tile)\n",
    "                    else:\n",
    "                        tiles.append(tile)\n",
    "                    a += 1\n",
    "                else:\n",
    "                    print(\"Out of shape\")\n",
    "    return tiles\n",
    "\n",
    "\n",
    "######################################################################\n",
    "\n",
    "# set dir\n",
    "label_dir = os.listdir('/Users/emilybirch/Documents/UCL_Dissertation/Data_collection/FINAL/ALL_snow_labelled')\n",
    "img_dir = os.listdir('/Users/emilybirch/Documents/UCL_Dissertation/Data_collection/FINAL/ALL_stacked_tifs')\n",
    "\n",
    "input_tensor_dimensions = 244\n",
    "\n",
    "\n",
    "\n",
    "for i in range(len(img_dir)):\n",
    "    i_label = label_dir[i]\n",
    "    # split the individual files in dir\n",
    "    name = i_label.split(\".\")[0]\n",
    "    os.chdir('/Users/emilybirch/Documents/UCL_Dissertation/Data_collection/FINAL/ALL_snow_labelled')\n",
    "    # read png labelled pics in as array\n",
    "    label_png = np.array(Image.open(i_label))\n",
    "    \n",
    "    array = label_png\n",
    "    # Resize the array for the correct splitting dimensions\n",
    "    array_height = int((array.shape[0] / 244)) * 244\n",
    "    array_width = int((array.shape[1] / 244)) * 244\n",
    "    \n",
    "    # all pixels are resized to 0-1 after resize function\n",
    "    resized_array = resize(array, (array_height, array_width))\n",
    "\n",
    "    label_tiles = split_image(dim_pix=input_tensor_dimensions, im=resized_array)\n",
    "    n = len(label_tiles)\n",
    "    if n!= min(array_height/244,array_width/244) **2:\n",
    "        print(name)\n",
    "    \n",
    "    os.chdir('/Users/emilybirch/Documents/UCL_Dissertation/Data_collection/FINAL/Split_labelled') #save path to split labelled pic\n",
    "    for index in range(n):\n",
    "        # name the output labelled pic and save as png file \n",
    "        outfile_png = name + \"_\" + str(index+1) + \".png\"\n",
    "        # make array of output file\n",
    "        im = Image.fromarray((label_tiles[index] * 255).astype(np.uint8))\n",
    "        # save output \n",
    "        im.save(outfile_png)\n",
    "    \n",
    "    # the 3 channnel pic. (NIR, DEM, NDSI) pic\n",
    "    i_image = img_dir[i]\n",
    "    os.chdir('/Users/emilybirch/Documents/UCL_Dissertation/Data_collection/FINAL/ALL_stacked_tifs')\n",
    "    img_jpg = gdal.Open(i_image)\n",
    "    array = img_jpg.ReadAsArray()\n",
    "    # Resize the array for the correct splitting dimensions for a tif \n",
    "    array_height = int((array.shape[1] / 244)) * 244 # all pixels are resized to 0-1 after resize function\n",
    "    array_width = int((array.shape[2] / 244)) * 244\n",
    "    \n",
    "    # REDEFINE THIS TO TIF DIMENSIONS\n",
    "    resized_array = resize(array, (array_height, array_width, 3)) # all pixels resized to\n",
    "    \n",
    "    basemap_tiles = split_image(dim_pix=input_tensor_dimensions, im=resized_array)\n",
    "    \n",
    "    os.chdir('/Users/emilybirch/Documents/UCL_Dissertation/Data_collection/FINAL/Split_original') #save path\n",
    "    for index in range(n):\n",
    "        # save the .tifs as jpegs for input into model?\n",
    "        outfile_jpg = name + \"_\" + str(index+1) + \".jpg\"\n",
    "        im = Image.fromarray((basemap_tiles[index] * 255).astype(np.uint8))\n",
    "        \n",
    "        im.save(outfile_jpg)\n",
    "\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df1d1d92",
   "metadata": {},
   "outputs": [],
   "source": [
    "###################################################"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3f1c1ca",
   "metadata": {},
   "source": [
    "BELOW IS ALL THE EXTRA CODE USEFUL FOR PREPROCESSING:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7b16386",
   "metadata": {},
   "outputs": [],
   "source": [
    "# FILES HAVE MOVED, DO NOT NEED TO RUN AGAIN\n",
    "\n",
    "# mMove and rename the single .tif tiles which do not need merging\n",
    "# France bbox 2. only 1 tile, so move to final DEMs folder and rename\n",
    "import shutil\n",
    "shutil.move('/Users/emilybirch/Documents/UCL_Dissertation/Data_collection/DEM/France/BOX2/tifs/ALPSMLC30_N044E006_DSM.tif', '/Users/emilybirch/Documents/UCL_Dissertation/Data_collection/DEM/Directory_for_DEM/Final_DEM_pics/mergedFrDEM2.tif')\n",
    "\n",
    "# Alaska: only 1 tif per. bbox2 and bbox4\n",
    "import shutil\n",
    "shutil.move('/Users/emilybirch/Documents/UCL_Dissertation/Data_collection/DEM/Alaska/BOX2/tifs/ALPSMLC30_N060W145_DSM.tif', '/Users/emilybirch/Documents/UCL_Dissertation/Data_collection/DEM/Directory_for_DEM/Final_DEM_pics/mergedAlDEM2.tif')\n",
    "shutil.move('/Users/emilybirch/Documents/UCL_Dissertation/Data_collection/DEM/Alaska/BOX4/tifs/ALPSMLC30_N061W146_DSM.tif', '/Users/emilybirch/Documents/UCL_Dissertation/Data_collection/DEM/Directory_for_DEM/Final_DEM_pics/mergedAlDEM4.tif')\n",
    "\n",
    "# Argentina\n",
    "import shutil\n",
    "shutil.move(\"/Users/emilybirch/Documents/UCL_Dissertation/Data_collection/DEM/Argentina/BOX1/tifs/ALPSMLC30_S036W070_DSM.tif\", '/Users/emilybirch/Documents/UCL_Dissertation/Data_collection/DEM/Directory_for_DEM/Final_DEM_pics/mergedArgDEM1.tif')\n",
    "shutil.move(\"/Users/emilybirch/Documents/UCL_Dissertation/Data_collection/DEM/Argentina/BOX2/tifs/ALPSMLC30_S036W071_DSM.tif\", '/Users/emilybirch/Documents/UCL_Dissertation/Data_collection/DEM/Directory_for_DEM/Final_DEM_pics/mergedArgDEM2.tif') \n",
    "shutil.move(\"/Users/emilybirch/Documents/UCL_Dissertation/Data_collection/DEM/Argentina/BOX3/tifs/ALPSMLC30_S048W072_DSM.tif\", '/Users/emilybirch/Documents/UCL_Dissertation/Data_collection/DEM/Directory_for_DEM/Final_DEM_pics/mergedArgDEM3.tif') \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b74fef92",
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge DEM tiles for each bbox\n",
    "import os \n",
    "from osgeo import gdal\n",
    "import glob\n",
    "import subprocess\n",
    "import gdal\n",
    "from gdalconst import GA_ReadOnly\n",
    "\n",
    "\n",
    "# set dir\n",
    "os.chdir('/Users/emilybirch/Documents/UCL_Dissertation/Data_collection/DEM/Directory_for_DEM/merge')\n",
    "os.getcwd()\n",
    "\n",
    "\n",
    "\n",
    "# Alaska.2,3,4\n",
    "# Set path to DEM tif files\n",
    "\n",
    "\n",
    "alask_path3 = \"/Users/emilybirch/Documents/UCL_Dissertation/Data_collection/DEM/Alaska/BOX3/tifs/*.tif\"\n",
    "alask_path4 = \"/Users/emilybirch/Documents/UCL_Dissertation/Data_collection/DEM/Alaska/BOX4/tifs/*.tif\"\n",
    "#retrieve files with this path name and extension\n",
    "\n",
    "al_DEM_list3 = glob.glob(alask_path3)\n",
    "al_DEM_list4 = glob.glob(alask_path4)\n",
    "\n",
    "\n",
    "# bbox3 merge\n",
    "cmd = \"gdal_merge.py -o mergedAlDEM3.tif\"\n",
    "subprocess.call(cmd.split()+al_DEM_list3)\n",
    "\n",
    "cmd = \"gdal_merge.py -o mergedAlDEM4.tif\"\n",
    "subprocess.call(cmd.split()+al_DEM_list4)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# merge Argentina \n",
    "arg_path2 = \"/Users/emilybirch/Documents/UCL_Dissertation/Data_collection/DEM/Alaska/BOX2/tifs/*.tif\"\n",
    "arg_path3 = \"/Users/emilybirch/Documents/UCL_Dissertation/Data_collection/DEM/Alaska/BOX3/tifs/*.tif\"\n",
    "#retrieve files with this path name and extension\n",
    "\n",
    "al_DEM_list2 = glob.glob(arg_path2)\n",
    "al_DEM_list3 = glob.glob(arg_path3)\n",
    "\n",
    "\n",
    "# bbox3 merge\n",
    "cmd = \"gdal_merge.py -o mergedArgDEM2.tif\"\n",
    "subprocess.call(cmd.split()+al_DEM_list2)\n",
    "\n",
    "cmd = \"gdal_merge.py -o mergedArgDEM3.tif\"\n",
    "subprocess.call(cmd.split()+al_DEM_list3)\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68aa4f5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# NZ. 4 bbox\n",
    "nz_path3 = '/Users/emilybirch/Documents/UCL_Dissertation/Data_collection/DEM/NZ/BBOX3/tifs/*.tif'\n",
    "nz_path4 = '/Users/emilybirch/Documents/UCL_Dissertation/Data_collection/DEM/NZ/BBOX4/tifs/*.tif'\n",
    "\n",
    "nz_DEM_list3 = glob.glob(nz_path3)\n",
    "nz_DEM_list4 = glob.glob(nz_path4)\n",
    "\n",
    "# call subprocess gdal merge to merge the DEM tiles\n",
    "cmd = \"gdal_merge.py -o mergedNzDEM3.tif\"\n",
    "subprocess.call(cmd.split()+nz_DEM_list3)\n",
    "# bbox3 merge\n",
    "cmd = \"gdal_merge.py -o mergedNzDEM4.tif\"\n",
    "subprocess.call(cmd.split()+nz_DEM_list4)\n",
    "\n",
    "\n",
    "# CANADA. make a list of DEM files to merge. get all with .tif extension\n",
    "can_bbox1_path = \"/Users/emilybirch/Documents/UCL_Dissertation/Data_collection/DEM/Canada/BBOX1/tifs/*.tif\"\n",
    "can_bbox2_path = \"/Users/emilybirch/Documents/UCL_Dissertation/Data_collection/DEM/Canada/BBOX2/tifs/*.tif\"\n",
    "can_bbox3_path = \"/Users/emilybirch/Documents/UCL_Dissertation/Data_collection/DEM/Canada/BBOX3/tifs/*.tif\"\n",
    "# retrieve files with this path name and extension\n",
    "CanDEMList_1 = glob.glob(can_bbox1_path)\n",
    "CanDEMList_2 = glob.glob(can_bbox2_path)\n",
    "CanDEMList_3 = glob.glob(can_bbox3_path)\n",
    "print(\"CANB3:\", CanDEMList_3)\n",
    "print(CanDEMList_3)\n",
    "\n",
    "# call subprocess gdal merge to merge the DEM tiles\n",
    "cmd = \"gdal_merge.py -o mergedCanDEM1.tif\"\n",
    "subprocess.call(cmd.split()+CanDEMList_1)\n",
    "# Canada bbox2 merge\n",
    "cmd = \"gdal_merge.py -o mergedCanDEM2.tif\"\n",
    "subprocess.call(cmd.split()+CanDEMList_2)\n",
    "# Canada bbox3 merge\n",
    "cmd = \"gdal_merge.py -o mergedCanDEM3.tif\"\n",
    "subprocess.call(cmd.split()+CanDEMList_3)\n",
    "\n",
    "\n",
    "# France. Set path to DEM tif files\n",
    "fr_bbox1 = \"/Users/emilybirch/Documents/UCL_Dissertation/Data_collection/DEM/France/BBOX1/tifs/*.tif\"\n",
    "fr_bbox3 = \"/Users/emilybirch/Documents/UCL_Dissertation/Data_collection/DEM/France/BOX3/tifs/*.tif\"\n",
    "#retrieve files with this path name and extension\n",
    "fr_list1 = glob.glob(fr_bbox1)\n",
    "fr_list3 = glob.glob(fr_bbox3)\n",
    "\n",
    "# merge the DEM tiles. bbox1\n",
    "cmd = \"gdal_merge.py -o mergedFrDEM1.tif\"\n",
    "subprocess.call(cmd.split()+fr_list1)\n",
    "# Fr bbox3 merge\n",
    "cmd = \"gdal_merge.py -o mergedFrDEM3.tif\"\n",
    "subprocess.call(cmd.split()+fr_list3)\n",
    "\n",
    "\n",
    "\n",
    "# Norway\n",
    "nor_path1 = '/Users/emilybirch/Documents/UCL_Dissertation/Data_collection/DEM/Norway/bbox1/tifs/*.tif'\n",
    "nor_path2 = '/Users/emilybirch/Documents/UCL_Dissertation/Data_collection/DEM/Norway/bbox2/tifs/*.tif'\n",
    "nor_path3 = '/Users/emilybirch/Documents/UCL_Dissertation/Data_collection/DEM/Norway/bbox3/tifs/*.tif'\n",
    "\n",
    "NorDEMList_1 = glob.glob(nor_path1)\n",
    "NorDEMList_2 = glob.glob(nor_path2)\n",
    "NorDEMList_3 = glob.glob(nor_path3)\n",
    "print(CanDEMList_3)\n",
    "\n",
    "# call subprocess gdal merge to merge the DEM tiles\n",
    "cmd = \"gdal_merge.py -o mergedNorDEM1.tif\"\n",
    "subprocess.call(cmd.split()+NorDEMList_1)\n",
    "# Canada bbox2 merge\n",
    "cmd = \"gdal_merge.py -o mergedNorDEM2.tif\"\n",
    "subprocess.call(cmd.split()+NorDEMList_2)\n",
    "# Canada bbox3 merge\n",
    "cmd = \"gdal_merge.py -o mergedNorDEM3.tif\"\n",
    "subprocess.call(cmd.split()+NorDEMList_3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3391be64",
   "metadata": {},
   "outputs": [],
   "source": [
    "# clip to extent of another raster file\n",
    "data = gdal.Open('can_sat_1_1.png', GA_ReadOnly)\n",
    "print(data)\n",
    "geoTransform = data.GetGeoTransform()\n",
    "print(\"GEO\", geoTransform)\n",
    "minx = geoTransform[0]\n",
    "print(\"MIN\", minx)\n",
    "maxy = geoTransform[3]\n",
    "print(\"MAX\", maxy)\n",
    "maxx = minx + geoTransform[1] * data.RasterXSize\n",
    "miny = maxy + geoTransform[5] * data.RasterYSize\n",
    "call('gdal_translate -projwin ' + ' '.join([str(x) for x in [minx, maxy, maxx, miny]]) + ' -of GTiff mergedCanDEM1.tif cropCanDEM1.tif', shell=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f531e589",
   "metadata": {},
   "outputs": [],
   "source": [
    "# clip to extent of sample pic\n",
    "import numpy as np\n",
    "import rasterio\n",
    "from rasterio import features\n",
    "from rasterio.mask import mask\n",
    "\n",
    "\n",
    "# ****** make this path have both dem and NIR pics in\n",
    "os.chdir('/Users/emilybirch/Documents/UCL_Dissertation/Data_collection/DEM/Directory_for_DEM/DEM_pics')\n",
    "os.getcwd()\n",
    "\n",
    "# the first one is your raster on the right. use the single band NIR .tif to crop to\n",
    "# and the second one your red raster\n",
    "with rasterio.open('b08_can_bbox1_1') as src, \\\n",
    "        rasterio.open('mergedCanDEM1.tif') as src_to_crop:\n",
    "    src_affine = src.meta.get(\"transform\") # this is s,w,n,e, height, width, pixel size etc.\n",
    "\n",
    "    # Read the first band of the \"mask\" raster\n",
    "    band = src.read(1)\n",
    "    # Use the same value on each pixel with data\n",
    "    # in order to speedup the vectorization\n",
    "    band[np.where(band!=src.nodata)] = 1\n",
    "\n",
    "    geoms = []\n",
    "    for geometry, raster_value in features.shapes(band, transform=src_affine):\n",
    "        # get the shape of the part of the raster\n",
    "        # not containing \"nodata\"\n",
    "        if raster_value == 1:\n",
    "            geoms.append(geometry)\n",
    "\n",
    "    # crop the second raster using the\n",
    "    # previously computed shapes\n",
    "    out_img, out_transform = mask(\n",
    "        dataset=src_to_crop,\n",
    "        shapes=geoms,\n",
    "        crop=True,\n",
    "    )\n",
    "\n",
    "    # save the result\n",
    "    # (don't forget to set the appropriate metadata)\n",
    "    with rasterio.open(\n",
    "        'result.tif',\n",
    "        'w',\n",
    "        driver='GTiff',\n",
    "        height=out_img.shape[1],\n",
    "        width=out_img.shape[2],\n",
    "        count=src.count,\n",
    "        dtype=out_img.dtype,\n",
    "        transform=out_transform,\n",
    "    ) as dst:\n",
    "        dst.write(out_img)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d1055eb",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Process DEM geomorphology pics \n",
    "# merge DEM tiles, reproject to projected crs with m units, resample to 10x10m pixel size, crop to bbox\n",
    "import os \n",
    "from osgeo import gdal\n",
    "import glob\n",
    "import subprocess\n",
    "from gdal import gdalconst\n",
    "\n",
    "\n",
    "\n",
    "# set directory to location of all final DEM pics \n",
    "os.chdir('/Users/emilybirch/Documents/UCL_Dissertation/Data_collection/DEM/Directory_for_DEM/Final_DEM_pics')\n",
    "os.getcwd()\n",
    "\n",
    "# can_list = [can_bbox1_path, can_bbox2_path, can_bbox3_path]\n",
    "# i = 0\n",
    "#for f in can_list:\n",
    "    # i += 1\n",
    "    # glob.glob(f)\n",
    "    # cmd = \"gdal_merge.py -o 'mergedCanDEM1_{}.tif'.format(i)\"\n",
    "    # subprocess.call(cmd.split()+f)\n",
    "\n",
    "# CANADA. make a list of DEM files to merge. get all with .tif extension\n",
    "can_bbox1_path = \"/Users/emilybirch/Documents/UCL_Dissertation/Data_collection/DEM/Canada/BBOX1/tifs/*.tif\"\n",
    "can_bbox2_path = \"/Users/emilybirch/Documents/UCL_Dissertation/Data_collection/DEM/Canada/BBOX2/tifs/*.tif\"\n",
    "can_bbox3_path = \"/Users/emilybirch/Documents/UCL_Dissertation/Data_collection/DEM/Canada/BBOX2/tifs/*.tif\"\n",
    "# retrieve files with this path name and extension\n",
    "CanDEMList_1 = glob.glob(can_bbox1_path)\n",
    "CanDEMList_2 = glob.glob(can_bbox2_path)\n",
    "CanDEMList_3 = glob.glob(can_bbox3_path)\n",
    "print(CanDEMList_3)\n",
    "\n",
    "# call subprocess gdal merge to merge the DEM tiles\n",
    "cmd = \"gdal_merge.py -o mergedCanDEM1.tif\"\n",
    "subprocess.call(cmd.split()+CanDEMList_1)\n",
    "# Canada bbox2 merge\n",
    "cmd = \"gdal_merge.py -o mergedCanDEM2.tif\"\n",
    "subprocess.call(cmd.split()+CanDEMList_2)\n",
    "# Canada bbox3 merge\n",
    "cmd = \"gdal_merge.py -o mergedCanDEM3.tif\"\n",
    "subprocess.call(cmd.split()+CanDEMList_3)\n",
    "\n",
    "\n",
    "\n",
    "# France. Set path to DEM tif files\n",
    "fr_bbox1 = \"/Users/emilybirch/Documents/UCL_Dissertation/Data_collection/DEM/France/BBOX1/tifs/*.tif\"\n",
    "fr_bbox3 = \"/Users/emilybirch/Documents/UCL_Dissertation/Data_collection/DEM/France/BOX3/tifs/*.tif\"\n",
    "#retrieve files with this path name and extension\n",
    "fr_list1 = glob.glob(fr_bbox1)\n",
    "fr_list3 = glob.glob(fr_bbox3)\n",
    "\n",
    "# merge the DEM tiles. bbox1\n",
    "cmd = \"gdal_merge.py -o mergedFrDEM1.tif\"\n",
    "subprocess.call(cmd.split()+fr_list1)\n",
    "# Fr bbox3 merge\n",
    "cmd = \"gdal_merge.py -o mergedFrDEM3.tif\"\n",
    "subprocess.call(cmd.split()+fr_list3)\n",
    "\n",
    "\n",
    "\n",
    "# Alaska. Set path to DEM tif files\n",
    "alask_path1 = \"/Users/emilybirch/Documents/UCL_Dissertation/Data_collection/DEM/Alaska/BBOX1/tifs/*.tif\"\n",
    "alask_path3 = \"/Users/emilybirch/Documents/UCL_Dissertation/Data_collection/DEM/Alaska/BOX3/tifs/*.tif\"\n",
    "#retrieve files with this path name and extension\n",
    "al_DEM_list1 = glob.glob(alask_path1)\n",
    "al_DEM_list3 = glob.glob(alask_path3)\n",
    "\n",
    "# call subprocess gdal merge to merge the DEM tiles\n",
    "cmd = \"gdal_merge.py -o mergedAlDEM1.tif\"\n",
    "subprocess.call(cmd.split()+al_DEM_list1)\n",
    "# bbox3 merge\n",
    "cmd = \"gdal_merge.py -o mergedAlDEM3.tif\"\n",
    "subprocess.call(cmd.split()+al_DEM_list3)\n",
    "\n",
    "\n",
    "\n",
    "# reproject coordinate system into UTM to use metres as units \n",
    "def reproj(out_file, in_file, dstSRS):\n",
    "    gdal.Warp(out_file, in_file, dstSRS = crs)\n",
    "\n",
    "# zip over lists?\n",
    "# reproj for Canada: into EPSG:3978\n",
    "canada_reproj_list = ['mergedCanDEM1.tif', 'mergedCanDEM2.tif', 'mergedCanDEM3.tif']\n",
    "i = 0\n",
    "# for in_file in zip_longest(canada_reproj_list, fr_reproj_list,al_reproj_list,... )\n",
    "for in_file in canada_reproj_list:\n",
    "    i += 1\n",
    "    print(\"I:\", i)\n",
    "    out_file = 'reprojCanDEM_{}.tif'.format(i)\n",
    "    crs = 'EPSG:3978'\n",
    "    call = reproj(out_file, in_file, crs)\n",
    "    print(call)\n",
    "    \n",
    "    \n",
    "# France: into EPSG:23030 ED50 / UTM zone 30N\n",
    "fr_reproj_list =  ['mergedFrDEM1.tif', 'mergedFrDEM2.tif', 'mergedFrDEM3.tif']\n",
    "i = 0\n",
    "for in_file in fr_reproj_list:\n",
    "    i += 1\n",
    "    print(\"I:\", i)\n",
    "    out_file = 'reprojFrDEM_{}.tif'.format(i)\n",
    "    crs = 'EPSG:23030'\n",
    "    call = reproj(out_file, in_file, crs)\n",
    "    print(call)\n",
    " \n",
    " \n",
    "# reproj for Alaska: into EPSG:3338\n",
    "al_reproj_list = ['mergedAlDEM1.tif', 'mergedAlDEM2.tif', 'mergedAlDEM3.tif', 'mergedAlDEM4.tif']\n",
    "i = 0\n",
    "for in_file in al_reproj_list:\n",
    "    i += 1\n",
    "    print(\"I:\", i)\n",
    "    out_file = 'reprojAlDEM_{}.tif'.format(i)\n",
    "    crs = 'EPSG:3338'\n",
    "    call = reproj(out_file, in_file, crs)\n",
    "    print(call)\n",
    "    \n",
    "# reproj for Argentina: into EPSG:5343\n",
    "Arg_reproj_list = ['mergedArgDEM1.tif', 'mergedArgDEM2.tif', 'mergedArgDEM3.tif']\n",
    "i = 0\n",
    "\n",
    "for in_file in Arg_reproj_list:\n",
    "    i += 1\n",
    "    print(\"I:\", i)\n",
    "    out_file = 'reprojArgDEM_{}.tif'.format(i)\n",
    "    crs = 'EPSG:5343'\n",
    "    call = reproj(out_file, in_file, crs)\n",
    "    print(call)\n",
    "    \n",
    "    \n",
    "    \n",
    "\n",
    "# Resample to 10x10m pixel size to match Sentinel images\n",
    "def resample(out_file, in_file):\n",
    "    gdal.Warp(out_file, in_file, xRes = 10, yRes = 10, resampleAlg = \"bilinear\")\n",
    "    print(\"HI\")\n",
    "        \n",
    "\n",
    "# list the files to resample and process then in a loop \n",
    "resamp_files_list = ['reprojCanDEM_1.tif', 'reprojCanDEM_2.tif', 'reprojCanDEM_3.tif']    \n",
    "i = 0\n",
    "for in_file in resamp_files_list:\n",
    "    i += 1\n",
    "    print(\"i\", i)\n",
    "    out_file = \"resamp_Can_DEM_{}.tif\".format(i)\n",
    "    print(\"OUTfile\", out_file)\n",
    "    resample(out_file, in_file)\n",
    "            \n",
    "\n",
    "# France: resample\n",
    "resamp_list = ['reprojFrDEM_1.tif', 'reprojFrDEM_2.tif', 'reprojFrDEM_3.tif']    \n",
    "i = 0\n",
    "for in_file in resamp_list:\n",
    "    i += 1\n",
    "    print(\"i\", i)\n",
    "    out_file = \"resamp_Fr_DEM_{}.tif\".format(i)\n",
    "    print(\"OUTfile\", out_file)\n",
    "    resample(out_file, in_file)\n",
    "\n",
    "    \n",
    "# Alaska resample. \n",
    "# list of files to resample\n",
    "resamp_list = ['reprojAlDEM_1.tif', 'reprojalDEM_2.tif', 'reprojAlDEM_3.tif', 'reprojAlDEM_4.tif']    \n",
    "i = 0\n",
    "for in_file in resamp_list:\n",
    "    i += 1\n",
    "    print(\"i\", i)\n",
    "    out_file = \"resamp_Al_DEM_{}.tif\".format(i)\n",
    "    print(\"OUTfile\", out_file)\n",
    "    resample(out_file, in_file)\n",
    "\n",
    "\n",
    "\n",
    "# list the files to resample and process then in a loop \n",
    "resamp_files_list = ['reprojArgDEM_1.tif', 'reprojArgDEM_2.tif', 'reprojArgDEM_3.tif']    \n",
    "i = 0\n",
    "for in_file in resamp_files_list:\n",
    "    i += 1\n",
    "    print(\"i\", i)\n",
    "    out_file = \"resamp_Arg_DEM_{}.tif\".format(i)\n",
    "    print(\"OUTfile\", out_file)\n",
    "    resample(out_file, in_file)\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "# Crop .tif to boudning box coords\n",
    "def crop(out_file, source_file, ulx, uly, lrx, lry):\n",
    "    gdal.Translate(out_file, source_file,\n",
    "                  projWin = [ulx, uly, lrx, lry])\n",
    "  \n",
    "\n",
    " \n",
    "# Canada: crop .tif to boudning box coords\n",
    "can1crop = crop('cropCanDEM_1.tif','resamp_Can_DEM_1.tif', -1442222.5901271082, 465767.00799028383, -1425280.668026976, 437053.54995778797) \n",
    "can2crop = crop('cropCanDEM_2.tif','resamp_Can_DEM_2.tif', -1963467.662479708, 532524.2456295489, -1950948.5651828928, 502730.9493941085)  \n",
    "can3crop = crop('cropCanDEM_3.tif','resamp_Can_DEM_3.tif',-2007237.3331321548, 602651.3553773408, -1994916.2627411576, 570806.9080293514) \n",
    "       \n",
    "# France: crop .tif to boudning box coords\n",
    "Fr1crop = crop('cropFrDEM_1.tif','resamp_Can_DEM_1.tif',1246969.3962645088, 5163267.284300569,1274934.6912586447, 5143545.166937985) \n",
    "Fr2crop = crop('cropFrDEM_2.tif','resamp_Can_DEM_2.tif',1234624.7084396454, 4993062.539814649, 1261497.750934254, 4974014.1117675835)  \n",
    "Fr3crop = crop('cropFrDEM_3.tif','resamp_Can_DEM_3.tif', 1225777.8855382334, 5373591.730970369,1252683.6911129407, 5355278.076760378) \n",
    "\n",
    "# Alaska: Crop .tif to boudning box coords\n",
    "Al1crop = crop('cropAlDEM_1.tif','resamp_Al_DEM_1.tif', 514481.90383768355, 1236449.1310469457, 541830.6619147946, 1218503.1192803124) \n",
    "Al2crop = crop('cropAlDEM_2.tif','resamp_Al_DEM_2.tif', 450815.2605629388, 1223929.9128310417, 477228.41344957944, 1204727.699233261)  \n",
    "Al3crop = crop('cropAlDEM_3.tif','resamp_Al_DEM_3.tif', 397957.2487422569, 1251934.8385985517,425182.4670500502, 1234086.2585198171) \n",
    "Al4crop = crop('cropAlDEM_4.tif','resamp_Al_DEM_4.tif',393282.9896072386, 1280321.0557472059,419319.2191957479, 1261199.193909528) \n",
    "  \n",
    "\n",
    "# close datasets to read properly to disk\n",
    "#ds = dsReproj = dsResamp = dsClip = None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "438178e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot to check DEM is reprojected, resampled and cropped to bbox\n",
    "final_DEM = gdal.Open(\"cropDEM_2.tif\")\n",
    "array = final_DEM.ReadAsArray()\n",
    "plt.imshow(array)\n",
    "plt.colorbar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96a43db4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Argentina\n",
    "import os \n",
    "from osgeo import gdal\n",
    "import glob\n",
    "import subprocess\n",
    "from gdal import gdalconst\n",
    "\n",
    "\n",
    "# set directory to location of all final DEM pics \n",
    "os.chdir('/Users/emilybirch/Documents/UCL_Dissertation/Data_collection/DEM/Directory_for_DEM/Final_DEM_pics')\n",
    "os.getcwd()\n",
    "\n",
    "def crop(out_file, source_file, ulx, uly, lrx, lry):\n",
    "    gdal.Translate(out_file, source_file,\n",
    "                  projWin = [ulx, uly, lrx, lry])\n",
    "    \n",
    "  \n",
    "\n",
    "\n",
    " \n",
    "# FIX THESE- CANT CROP BC NOT IN SAME AREA?\n",
    "# Argentina: crop .tif to boudning box coords\n",
    "Ar1crop = crop('cropArgDEM_1.tif','resamp_Arg_DEM_1.tif',5998451.786827491, 1601005.619190992,5976249.0203732345, 1625961.998551086) \n",
    "Ar2crop = crop('cropArgDEM_2.tif','resamp_Arg_DEM_2.tif',5937593.134678965, 1582258.6827567841,5916218.082539896, 1605918.8959056677)\n",
    "Ar3crop = crop('cropArgDEM_3.tif','resamp_Arg_DEM_3.tif', 4676913.660264564, 1475051.4449760758, 4656287.012900037, 1499619.73136248) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87137982",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Norway\n",
    "Nor1crop = crop('cropNorDEM_1.tif','resamp_Nor_DEM_1.tif',1611541.2847414473, -1150463.0893291135,1581199.9787365836, -1136330.787145058)\n",
    "Nor2crop = crop('cropNorDEM_2.tif','resamp_Nor_DEM_2.tif',1619389.5743942696, -854804.3331045215,1591676.3046402216, -836971.2418011383)\n",
    "Nor3crop = crop('cropNorDEM_3.tif','resamp_Nor_DEM_3.tif', 1882899.119273985, -786917.6157957469,1855046.293116921, -769771.7641124884) \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fossil-tamil",
   "metadata": {},
   "outputs": [],
   "source": [
    "# use more than one channel as input into my model. use geomorphology too.\n",
    "\n",
    "# taking the TIFF data and encoding it to a TFRecords format for some machine learning in Tensorflow.  \n",
    "# take the TIFF data, convert it to 8bit format, encode it as a string and write it to TFRecords.  \n",
    "\n",
    "\n",
    "# A guide for Spectral indicies:\n",
    "# https://www.geo.university/pages/blog?p=spectral-indices-with-multispectral-satellite-data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "electoral-concept",
   "metadata": {},
   "source": [
    "I chose a region where both water and snow are present. \n",
    "This shows that when trying to isolate snow, we also isolate water. \n",
    "\n",
    "But when isolating water, we, the snow is mostly left out.\n",
    "This means that we can use both indicies to generate some training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "working-painting",
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_mask(input_image, threshold):\n",
    "    input_image[input_image <= threshold] = np.nan\n",
    "    input_image[input_image > threshold] = 1\n",
    "    return input_image\n",
    "    \n",
    "NDVI_mask = to_mask(NDVI, 0.2)\n",
    "NDSI_mask = to_mask(NDSI, 0.)\n",
    "fig, ax = plt.subplots(1, 4, figsize=(15,10))\n",
    "ax[0].set_title('NDVI Vegetation mask')\n",
    "ax[0].imshow(basemap)\n",
    "ax[0].imshow(NDVI_mask, cmap='cubehelix')\n",
    "ax[1].set_title('NDSI Snow mask')\n",
    "ax[1].imshow(basemap)\n",
    "ax[1].imshow(NDSI_mask, cmap='cubehelix')\n",
    "\n",
    "NDVI_binary_mask = np.nan_to_num(NDVI_mask)\n",
    "NDSI_binary_mask = np.nan_to_num(NDSI_mask)\n",
    "both = NDVI_binary_mask + NDSI_binary_mask\n",
    "\n",
    "ax[2].set_title('NDSI mask + NDVI mask')\n",
    "ax[2].imshow(both, cmap='cubehelix')\n",
    "\n",
    "ax[3].set_title('Snow mask - Vegetation removed')\n",
    "snow_only = both.copy()\n",
    "snow_only[snow_only == 2] = 0\n",
    "ax[3].imshow(snow_only, cmap='cubehelix')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "gorgeous-dominant",
   "metadata": {},
   "source": [
    "CNN's usually don't accept big inputs, so the image needs to be cropped into smaller samples.\n",
    "\n",
    "The bigger and more complex the CNN, the more processing power will be required, therefore the smaller the input samples will need to be. \n",
    "\n",
    "Rather than crushing the original sample, a good idea is to splice it. \n",
    "This way we get a lot more data, and the 10m resolution is maintained. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "registered-better",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "# Split the Images\n",
    "def split_image(dim_pix, im):\n",
    "    # Find the number of sub-Images that fit in rows\n",
    "    rows = []\n",
    "    tiles = []\n",
    "    for i in range((math.floor(im.shape[0] / dim_pix))):\n",
    "        rows.append(i)\n",
    "    # Find the number of sub-Images that fit in rows\n",
    "    columns = []\n",
    "    for i in range((math.floor(im.shape[1] / dim_pix))):\n",
    "        columns.append(i)\n",
    "\n",
    "    # Numerically identify the sub-Images\n",
    "    a = 0\n",
    "    for i in rows:\n",
    "        for j in columns:\n",
    "            # Check for 244 x 244 (Mask) or 244 x 244 x 3 (TC Images)\n",
    "            if (im[0 + (dim_pix * j): dim_pix + (dim_pix * j),\n",
    "                  0 + dim_pix * i: dim_pix + (dim_pix * i)].shape[0]) == dim_pix:\n",
    "                if (im[0 + (dim_pix * j): dim_pix + (dim_pix * j),\n",
    "                  0 + dim_pix * i: dim_pix + (dim_pix * i)].shape[1]) == dim_pix:\n",
    "\n",
    "                    tile = im[0 + (dim_pix * j): dim_pix + (dim_pix * j),\n",
    "                            0 + dim_pix * i: dim_pix + (dim_pix * i)]\n",
    "\n",
    "                    # Stop white tiles for positive results\n",
    "                    count = np.count_nonzero(tile == 1) == (dim_pix * dim_pix)\n",
    "                    if count:\n",
    "                        all_black = np.tile(1, (dim_pix, dim_pix))\n",
    "                        tiles.append(tile)\n",
    "                    else:\n",
    "                        tiles.append(tile)\n",
    "                    a += 1\n",
    "                else:\n",
    "                    print(\"Out of shape\")\n",
    "    return tiles\n",
    "\n",
    "input_tensor_dimensions = 50\n",
    "                    \n",
    "basemap_tiles = split_image(dim_pix=input_tensor_dimensions, im=basemap)\n",
    "label_tiles = split_image(dim_pix=input_tensor_dimensions, im=snow_only)\n",
    "\n",
    "fig, ax = plt.subplots(len(label_tiles), 2, figsize=(2 ,len(label_tiles)))\n",
    "for index in range(len(label_tiles)):\n",
    "    ax[index, 0].axis('off')\n",
    "    ax[index, 1].axis('off')\n",
    "    ax[index, 0].imshow(basemap_tiles[index])\n",
    "    ax[index, 1].imshow(label_tiles[index], cmap='Blues')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e4b9852",
   "metadata": {},
   "outputs": [],
   "source": [
    "# EXTRA!!!!\n",
    "\n",
    "# EXTRA. func to convert bbox coords from geographic into projected system \n",
    "import os\n",
    "import pyproj\n",
    "from pyproj import Proj, transform\n",
    "\n",
    "os.environ['PROJ_NETWORK'] = 'OFF'\n",
    "\n",
    "\n",
    "def coord_conv(x1, y1, in_proj, out_proj):\n",
    "    proj = pyproj.Transformer.from_crs(in_proj, out_proj)\n",
    "    x2, y2 = proj.transform(x1, y1)\n",
    "    print((x1, y1))\n",
    "    print((x2, y2))\n",
    "    return x2,y2\n",
    "\n",
    "\n",
    " \n",
    "# 1. Canada:   #\"epsg:4326\", \"epsg:3978\"\n",
    "#can_DEM_bbox1_ulc = coord_conv(51.02521, -116.09311, 4326, 3978)\n",
    "#can_DEM_bbox1_lrc = coord_conv(50.82872, -115.73064, 4326, 3978)\n",
    "# box2\n",
    "#can_DEM_bbox2_ulc = coord_conv(49.7991, -123.27756,4326, 3978)\n",
    "#can_DEM_bbox2_lrc = coord_conv(49.60459, -122.94316,4326, 3978)\n",
    "# box3\n",
    "#can_bbox3_ulc = coord_conv(50.19571, -124.25775,4326, 3978)\n",
    "#can_bbox3_lrc = coord_conv(49.98687, -123.90537,4326, 3978)\n",
    "\n",
    "\n",
    "\n",
    "# 2. France \n",
    "# bbox 1 \n",
    "#Fr_bbox1_ulc = coord_conv(46.20907, 6.68394, 4326, 23030)\n",
    "#Fr_bbox1_lrc = coord_conv(46.00317, 7.009, 4326, 23030)\n",
    "# box2\n",
    "#Fr_bbox1_ulc = coord_conv(44.71102, 6.27264,4326, 23030)\n",
    "#Fr_bbox1_lrc = coord_conv(44.51403, 6.57913,4326, 23030)\n",
    "# box3\n",
    "#Fr_bbox1_ulc = coord_conv(48.09807, 6.75178,4326, 23030)\n",
    "#Fr_bbox1_lrc = coord_conv(47.90479, 7.07567, 4326, 23030)\n",
    "\n",
    "\n",
    "# Alaska\n",
    "#Al_bbox1_uly = coord_conv(60.78013, -144.48842,4326, 3338)\n",
    "#Al_bbox1_lrc = coord_conv(60.58568, -144.03959, 4326, 3338)\n",
    "\n",
    "#Al_bbox2_uly = coord_conv(60.74539, -145.68114, 4326, 3338)\n",
    "#Al_bbox2_lrc = coord_conv(60.54485, -145.24568, 4326, 3338)\n",
    "\n",
    "#Al_bbox3_uly = coord_conv(61.04986, -146.59057, 4326, 3338)\n",
    "#Al_bbox3_lrc = coord_conv(60.86339, -146.12749, 4326, 3338)\n",
    "\n",
    "#Al_bbox4_uly = coord_conv(61.30673, -146.61838, 4326, 3338) \n",
    "#Al_bbox4_lrc = coord_conv(61.11029, -146.17618, 4326, 3338)\n",
    "\n",
    "\n",
    "# Argentina\n",
    "#Ar_bbox1_uly = coord_conv(-36.1567, -70.87755,4326, 5343)\n",
    "#Ar_bbox1_lrc = coord_conv(-36.35381, -70.59671, 4326, 5343)\n",
    "\n",
    "#Ar_bbox2_uly = coord_conv(-36.70684, -71.0794, 4326, 5343)\n",
    "#Ar_bbox2_lrc = coord_conv(-36.89707, -70.81168, 4326, 5343)\n",
    "\n",
    "#Ar_bbox3_uly = coord_conv(-48.05909, -72.3347, 4326, 5343)\n",
    "#Ar_bbox3_lrc = coord_conv(-48.24508, -72.00512, 4326, 5343)\n",
    "\n",
    "\n",
    "# Norway. ETRS89 / UTM is the projected CRS for Norway\n",
    "Nor_bbox1_uly = coord_conv(61.39974, 6.71094,4326, 5130)\n",
    "Ar_bbox1_lrc = coord_conv(61.19466, 7.15113, 4326, 5130)\n",
    "\n",
    "Nor_bbox2_uly = coord_conv(62.31192, 11.90014, 4326, 5130)\n",
    "Ar_bbox2_lrc = coord_conv(62.12052, 12.37392, 4326, 5130)\n",
    "\n",
    "Nor_bbox3_uly = coord_conv(64.72578, 11.67157, 4326, 5130)\n",
    "Nor_bbox3_lrc = coord_conv(64.53323, 12.179, 4326, 5130)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#####################\n",
    "#can_list = []\n",
    "# [51.02521, -116.09311,(49.7991, -123.27756), (50.19571, -124.25775)]\n",
    "#x = [51.02521.....\n",
    "# y = ...\n",
    "#x.append\n",
    "#y.append\n",
    "#for coord in can_list:\n",
    "#    in_proj = 4326\n",
    "#    out_proj = 3978\n",
    "#    x1, y1 = ulc.split(',')\n",
    "#    coord_conv(x1,y1,in_proj,out_proj)\n",
    "\n",
    "\n",
    "#NZ\n",
    "#-44.42977, 168.66256\n",
    "#-44.63339, 168.99731\n",
    "\n",
    "#-44.26552, 169.14185\n",
    "#-44.45747, 169.46413\n",
    "\n",
    "#-45.37762, 167.32743\n",
    "#-45.58001, 167.63521\n",
    "\n",
    "#-44.00659, 168.70122\n",
    "#-44.19769, 169.022\n",
    "\n",
    "#EPSG:27200\n",
    "    \n",
    "    \n",
    "    \n",
    "\n",
    "# Norway\n",
    "#61.39974, 6.71094\n",
    "#61.19466, 7.15113\n",
    "\n",
    "#62.31192, 11.90014\n",
    "#62.12052, 12.37392\n",
    "\n",
    "#64.72578, 11.67157\n",
    "#64.53323, 12.179\n",
    "\n",
    "#EPSG:5776"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfa9005f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# reading/ writing rasters EXTRA CODE\n",
    "def access_raster(path, aoi=None):\n",
    "    \"\"\"\n",
    "    This func says if the raster is the bbox shape, then just get info,\n",
    "    if its not the bbox shape (aoi coords), then make a shape to cut the new tif to\n",
    "    \"\"\" \n",
    "    # aoi is canada_coords\n",
    "    if aoi == None:\n",
    "        with rasterio.open(path) as src:\n",
    "            array = src.read()\n",
    "            meta = src.meta\n",
    "            transform = src.meta['transform']\n",
    "            extent = src.bounds\n",
    "            extent_dims = {'north': extent.top, 'south': extent.bottom, 'west': extent.left, 'east': extent.right}\n",
    "            polygon_extent = polygon_generator(extent_dims)\n",
    "\n",
    " \n",
    "\n",
    "        return {'array': array, 'meta': meta, 'transform': transform, 'extent': extent, 'polygom':polygon_extent}\n",
    "\n",
    " \n",
    "\n",
    "    else:\n",
    "        with fiona.open(aoi, \"r\") as shapefile:\n",
    "            shapes = [feature[\"geometry\"] for feature in shapefile]\n",
    "\n",
    " \n",
    "\n",
    "        with rasterio.open(path) as src:\n",
    "            array, transform = rasterio.mask.mask(src, shapes, crop=True)\n",
    "            meta = src.meta\n",
    "            extent = src.bounds\n",
    "        return {'array': array, 'meta': meta, 'transform': transform, 'extent': extent}\n",
    "\n",
    "\n",
    "    \n",
    "def write_single_channel_gtiff(raster, transform, meta,  out_path):\n",
    "    assert len(raster.shape) == 2\n",
    "    print(f'Writing...{out_path}')\n",
    "    with rasterio.open(str(out_path),\n",
    "                       mode='w',\n",
    "                       crs=meta['crs'],\n",
    "                       driver=meta['driver'],\n",
    "                       nodata=np.nan,\n",
    "                       dtype=meta['dtype'],\n",
    "                       count=meta['count'],\n",
    "                       height=raster.shape[0],\n",
    "                       width=raster.shape[1],\n",
    "                       transform=transform\n",
    "                       ) as dst:\n",
    "        dst.write(raster, 1)\n",
    "        \n",
    "    \n",
    "    \n",
    "##############\n",
    "From raster.crs import CRS\n",
    "\n",
    "def get_raster_info(raster):\n",
    "    data_type = raster.dtype\n",
    "    print(data_type)\n",
    "    dim = raster.shape\n",
    "    print(dim)\n",
    "    height = dim[1]\n",
    "    width = dim[2]\n",
    "\n",
    "    \n",
    "\n",
    "transform=from_bounds(w2, s2, e2, n2, width, height)\n",
    "\n",
    "\n",
    "#With raster.open(“./output.tif”, “w”, \n",
    "#    driver = driver,\n",
    "#    height = height,\n",
    "#    width = width,\n",
    "#    count = count,\n",
    "#    typed = dtype,\n",
    "#    crs = crs,\n",
    "#    transform = transform) as dst:\n",
    "#dst.write(array)\n",
    "\n",
    "###################\n",
    "\n",
    "\n",
    "transform=from_bounds(w2, s2, e2, n2, width, height)\n",
    "# rasterio.transform.from_bounds(west, south, east, north, width, height)\n",
    "\n",
    "crs_img='EPSG:4326'\n",
    "\n",
    "from rasterio.transform import from_bounds\n",
    "with rasterio.open('test1.tif', \n",
    "                    'w',\n",
    "                    driver='GTiff',\n",
    "                    height=NDSI.shape[0],\n",
    "                    width=NDSI.shape[1],\n",
    "                    count=1,\n",
    "                    dtype=NDSI.dtype,\n",
    "                    crs=crs_img,\n",
    "                    nodata=None, # change if data has nodata value\n",
    "                    transform=transform) as dst:\n",
    "        dst.write(ndvi, 1)\n",
    " \n",
    "\n",
    "\n",
    " \n",
    "################\n",
    "# write an array into a new single band .tiff\n",
    "with rasterio.Env():\n",
    "    # write an array as a raster band to a new 8bit file\n",
    "    profile.update(\n",
    "        dtype=rasterio.unit8,\n",
    "        count=1,\n",
    "        compress='lzw')\n",
    "    \n",
    "    with rasterio.open('example.tif', 'w', **profile) as dst:\n",
    "        dst.write(array.astype(rasterio.unit8), 1) \n",
    "        \n",
    "        \n",
    "        \n",
    "############        \n",
    "import gdal\n",
    "# read raster\n",
    "gdal.AllRegister()\n",
    "inRaster ='input raster'\n",
    "inDS=gdal.Open(inRaster,1)\n",
    "geoTransform = inDs.GetGeoTransform()\n",
    "band=inDS.GetRasterBand(1)\n",
    "datatype=band.DataType\n",
    "proj=inDS.GetProjection()\n",
    "        \n",
    "# write raster\n",
    "driver = inDS.GetDriver()\n",
    "outDS= driver.Create(outRaster,No_cols,No_rows,1,datatype)\n",
    "geoTransform = inDS.GetGeoTransform()\n",
    "outDS.SetProjection(proj)\n",
    "outBand=outDS.GetRasterBand(1)\n",
    "# data is the output array written in.tiff file\n",
    "outBand.WriteArray(data,0,0)\n",
    "outDS=None\n",
    "\n",
    "            \n",
    "############\n",
    "from osgeo import gdal\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# import \n",
    "ds = gdal.Open(\"dem.tif\")\n",
    "gt = ds.GetGeoTransform()\n",
    "proj = ds.GetProjection()\n",
    "\n",
    "band = ds.GetRasterBand(1)\n",
    "array = band.ReadAsArray()\n",
    "\n",
    "plt.figure()\n",
    "plt.imshow(array)\n",
    "\n",
    "# manipulate\n",
    "#binmask = np.where((array \\&gt = np.mean(array)),1,0)\n",
    "#plt.figure()\n",
    "#plt.imshow(binmask)\n",
    "\n",
    "# export\n",
    "driver = gdal.GetDriverByName(\"GTiff\")\n",
    "driver.Register()\n",
    "outds = driver.Create(\"output.tif\", xsize = array.shape[1],\n",
    "                      ysize = array.shape[0], bands = 1, \n",
    "                      eType = gdal.GDT_Int16) # GDT_Byte \n",
    "outds.SetGeoTransform(gt)\n",
    "outds.SetProjection(proj)\n",
    "outband = outds.GetRasterBand(1)\n",
    "outband.WriteArray(array)\n",
    "outband.SetNoDataValue(np.nan)\n",
    "outband.FlushCache()\n",
    "\n",
    "# close your datasets and bands!!!\n",
    "outband = None\n",
    "outds = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c4b5b20",
   "metadata": {},
   "outputs": [],
   "source": [
    "# EXTRA FOR resample raster\n",
    "# upsampling refers to cases where we are converting to higher resolution/smaller cells.\n",
    "# nearest neighbour method of resampling is not suitable for continuous data i.e. DEM\n",
    "# use bilinear instead \n",
    "\n",
    "import rasterio\n",
    "from rasterio.enums import Resampling\n",
    "\n",
    "upscale_factor = 3\n",
    "\n",
    "with rasterio.open(\"mergedCanDEM1.tif\") as dataset:\n",
    "\n",
    "    # resample data to target shape\n",
    "    data = dataset.read(\n",
    "        out_shape=(\n",
    "            dataset.count,\n",
    "            int(dataset.height * upscale_factor),\n",
    "            int(dataset.width * upscale_factor)\n",
    "        ),\n",
    "        resampling=Resampling.bilinear\n",
    "    )\n",
    "\n",
    "    # scale image transform\n",
    "    transform = dataset.transform * dataset.transform.scale(\n",
    "        (dataset.width / data.shape[-1]),\n",
    "        (dataset.height / data.shape[-2])\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ff8de28",
   "metadata": {},
   "outputs": [],
   "source": [
    "# EXTRA FOR PLOTTING/ SAVING BAND AS PNG\n",
    "\n",
    "\n",
    "      # extra to plot the NDSI and NIR  \n",
    "      #  for channels in bands:\n",
    "       #     i += 1\n",
    "       #     print(\"i\", i)\n",
    "          #  fig, ax = plt.subplots(2, 6, figsize=(15,10))\n",
    "          #  ax[0, 2].imshow(b03, cmap='cubehelix')\n",
    "          #  ax[0, 2].set_title('Green')\n",
    "          #  ax[1, 0].imshow(b08, cmap='cubehelix')\n",
    "          #  ax[1, 0].set_title('Vegetation Red Edge ')\n",
    "          #  ax[1, 3].imshow(b11, cmap='cubehelix')\n",
    "          #  ax[1, 3].set_title('SWIR')\n",
    "          #  ax[1, 3].axis('off')\n",
    "\n",
    "        #    os.chdir('/Users/emilybirch/Documents/UCL_Dissertation/Data_collection/WMS_all_bands')\n",
    "        #    plt.savefig(\"can_bands_{}.tif\".format(i),\n",
    "        #                bbox_inches='tight',\n",
    "        #                    dpi=600)\n",
    "\n",
    "         #   plt.show()\n",
    "       \n",
    "\n",
    "      \n",
    " #   def calc_ndsi(self, b03, b11, bands):\n",
    "        \"\"\"\n",
    "        Plot ndsi using certain bands\n",
    "        EXPORT AS PNG\n",
    "        \"\"\"\n",
    "       # NDVI = (b04 – b03) / (b04 + b03)       \n",
    "        # plot true colour image:\n",
    "       # ax[0].imshow(basemap)\n",
    "       # ax[0].set_title('True Colour Composite')  \n",
    "        # Normalised difference snow index \n",
    "    \n",
    "  #      os.chdir('/Users/emilybirch/Documents/UCL_Dissertation/Data_collection/NDSI')\n",
    "  #      i = 0\n",
    "  #      NDSI = (b03 - b11)/(b03 + b11)\n",
    "  #      for ndsi_im in bands:\n",
    "  #          i += 1\n",
    "        #   ndsi_im = Image.fromarray(NDSI) #.save('can_NDSI_{}.tif'.format(i)) # NDSI.astype(np.uint8)\n",
    " #           fig, ax = plt.subplots(1, 1, figsize=(15,10))\n",
    "  #          plt.imshow(NDSI, cmap='Blues')\n",
    "   #         plt.axis('off')            \n",
    "   ##         plt.savefig('can_NDSI_{}.tif'.format(i),\n",
    "   #                     bbox_inches='tight', dpi=600, format=\"tiff\")\n",
    "   #         plt.show()  "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
