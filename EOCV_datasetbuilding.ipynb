{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "behavioral-panama",
   "metadata": {},
   "source": [
    "# Building EO training/validation/testing datasets with the Sentinelhub API"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "presidential-developer",
   "metadata": {},
   "source": [
    "#### The following modules/Libraries will be needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "9f5ea95e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentinelhub import BBox, CRS, DataCollection, SHConfig, WmsRequest, WcsRequest, DataSource, MimeType\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from datetime import date, timedelta\n",
    "from scipy.ndimage.filters import uniform_filter\n",
    "from scipy.ndimage.measurements import variance\n",
    "import rasterio\n",
    "import numpy as np\n",
    "import datetime\n",
    "\n",
    "import os \n",
    "from osgeo import gdal\n",
    "import glob\n",
    "\n",
    "import imageio\n",
    "\n",
    "from PIL import Image\n",
    "import io\n",
    "\n",
    "from rasterio.transform import from_bounds\n",
    "\n",
    "\n",
    "from matplotlib import pyplot\n",
    "from rasterio.plot import show"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "funny-nashville",
   "metadata": {},
   "source": [
    "### Prerequisites\n",
    "\n",
    "#### Sentinel Hub account\n",
    "\n",
    "In order to use Sentinel Hub services you will need a Sentinel Hub account. If you do not have one yet, you can create a free trial account at [Sentinel Hub webpage](https://services.sentinel-hub.com/oauth/subscription). If you are a researcher you can even apply for a free non-commercial account at [ESA OSEO page](https://earth.esa.int/aos/OSEO).\n",
    "\n",
    "Once you have the account set up, login to [Sentinel Hub Configurator](https://apps.sentinel-hub.com/configurator/). Inside there will already exist one configuration with an **instance ID** (alpha-numeric code of length 36). For this tutorial it is recommended that you create a new configuration (`\"Add new configuration\"`) and set the configuration to be based on **Python scripts template**. Such configuration will already contain all layers used in these examples. Otherwise you will have to define the layers for your  configuration yourself.\n",
    "\n",
    "After you have decided which configuration to use, you have two options. You can either put configuration's **instance ID** into `sentinelhub` package's configuration file following the [configuration instructions](http://sentinelhub-py.readthedocs.io/en/latest/configure.html) or you can write it down in the following cell:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "boolean-chancellor",
   "metadata": {},
   "source": [
    "Generate a configuration:\n",
    "This is done using the ID.\n",
    "This is so that sentinelhub knows you are authorised to use their service, and which parts of the service you want to use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "coral-conjunction",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"instance_id\": \"216732ac-7e0c-46f0-a5f8-243652a55bfb\",\n",
      "  \"sh_client_id\": \"\",\n",
      "  \"sh_client_secret\": \"\",\n",
      "  \"sh_base_url\": \"https://services.sentinel-hub.com\",\n",
      "  \"geopedia_wms_url\": \"https://service.geopedia.world\",\n",
      "  \"geopedia_rest_url\": \"https://www.geopedia.world/rest\",\n",
      "  \"aws_access_key_id\": \"\",\n",
      "  \"aws_secret_access_key\": \"\",\n",
      "  \"aws_metadata_url\": \"https://roda.sentinel-hub.com\",\n",
      "  \"aws_s3_l1c_bucket\": \"sentinel-s2-l1c\",\n",
      "  \"aws_s3_l2a_bucket\": \"sentinel-s2-l2a\",\n",
      "  \"opensearch_url\": \"http://opensearch.sentinel-hub.com/resto/api/collections/Sentinel2\",\n",
      "  \"max_wfs_records_per_query\": 100,\n",
      "  \"max_opensearch_records_per_query\": 500,\n",
      "  \"max_download_attempts\": 4,\n",
      "  \"download_sleep_time\": 5,\n",
      "  \"download_timeout_seconds\": 120,\n",
      "  \"number_of_download_processes\": 1\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "INSTANCE_ID = '216732ac-7e0c-46f0-a5f8-243652a55bfb'\n",
    "if INSTANCE_ID:\n",
    "    config = SHConfig()\n",
    "    config.instance_id = INSTANCE_ID\n",
    "else:\n",
    "    config = None\n",
    "\n",
    "print(config)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "virtual-civilization",
   "metadata": {},
   "source": [
    "Define a region and a random test date "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "1036f3f3",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time_from 2016-01-01\n",
      "time_to 2017-01-01\n",
      "WCS:  <sentinelhub.data_request.WcsRequest object at 0x7facbfeb4f50>\n",
      "avail dates list:  []\n",
      "time_from 2017-01-01\n",
      "time_to 2018-01-01\n",
      "WCS:  <sentinelhub.data_request.WcsRequest object at 0x7facbfd1b5d0>\n",
      "avail dates list:  []\n",
      "time_from 2018-01-01\n",
      "time_to 2019-01-01\n",
      "WCS:  <sentinelhub.data_request.WcsRequest object at 0x7facbfd1be10>\n",
      "avail dates list:  [datetime.datetime(2018, 8, 7, 19, 22, 15), datetime.datetime(2018, 8, 9, 19, 19, 41), datetime.datetime(2018, 8, 27, 19, 29, 29)]\n",
      "date 2018-08-07 19:22:15\n"
     ]
    },
    {
     "ename": "DownloadFailedException",
     "evalue": "Failed to download from:\nhttps://services.sentinel-hub.com/ogc/wcs/216732ac-7e0c-46f0-a5f8-243652a55bfb?SERVICE=wcs&WARNINGS=False&MAXCC=0.0&BBOX=49.98687%2C-124.25775%2C50.19571%2C-123.90537&FORMAT=image%2Fpng&CRS=EPSG%3A4326&TIME=2018-08-07T19%3A22%3A15Z%2F2018-08-07T19%3A22%3A15Z&RESX=10m&RESY=10m&COVERAGE=TRUE-COLOR-S2-L2A&REQUEST=GetCoverage&VERSION=1.1.2\nwith HTTPError:\n400 Client Error: Bad Request for url: https://services.sentinel-hub.com/ogc/wcs/216732ac-7e0c-46f0-a5f8-243652a55bfb?SERVICE=wcs&WARNINGS=False&MAXCC=0.0&BBOX=49.98687%2C-124.25775%2C50.19571%2C-123.90537&FORMAT=image%2Fpng&CRS=EPSG%3A4326&TIME=2018-08-07T19%3A22%3A15Z%2F2018-08-07T19%3A22%3A15Z&RESX=10m&RESY=10m&COVERAGE=TRUE-COLOR-S2-L2A&REQUEST=GetCoverage&VERSION=1.1.2\nServer response: \"Invalid request\"",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mHTTPError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m~/opt/anaconda3/envs/Dissertation_ML/lib/python3.7/site-packages/sentinelhub/download/handlers.py\u001b[0m in \u001b[0;36mnew_download_func\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m     21\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mdownload_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrequest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mrequests\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mHTTPError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mexception\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/Dissertation_ML/lib/python3.7/site-packages/sentinelhub/download/sentinelhub_client.py\u001b[0m in \u001b[0;36m_execute_download\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m     68\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatus_code\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mrequests\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatus_codes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcodes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTOO_MANY_REQUESTS\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 69\u001b[0;31m                     \u001b[0mresponse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_for_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     70\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/Dissertation_ML/lib/python3.7/site-packages/requests/models.py\u001b[0m in \u001b[0;36mraise_for_status\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    942\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mhttp_error_msg\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 943\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mHTTPError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhttp_error_msg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    944\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mHTTPError\u001b[0m: 400 Client Error: Bad Request for url: https://services.sentinel-hub.com/ogc/wcs/216732ac-7e0c-46f0-a5f8-243652a55bfb?SERVICE=wcs&WARNINGS=False&MAXCC=0.0&BBOX=49.98687%2C-124.25775%2C50.19571%2C-123.90537&FORMAT=image%2Fpng&CRS=EPSG%3A4326&TIME=2018-08-07T19%3A22%3A15Z%2F2018-08-07T19%3A22%3A15Z&RESX=10m&RESY=10m&COVERAGE=TRUE-COLOR-S2-L2A&REQUEST=GetCoverage&VERSION=1.1.2",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mDownloadFailedException\u001b[0m                   Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-94-17e63bd1c7a6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    335\u001b[0m \u001b[0;31m# plot the individual channels for Canada wms/ web req data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    336\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 337\u001b[0;31m \u001b[0mplot_canada_wms\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcanada_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_available_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    338\u001b[0m \u001b[0;31m#print(\"PLOT\", plot_canada_wms)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    339\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-94-17e63bd1c7a6>\u001b[0m in \u001b[0;36mget_available_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     66\u001b[0m             )\n\u001b[1;32m     67\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 68\u001b[0;31m             \u001b[0mbasemap\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwcs_true_color_request\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     69\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     70\u001b[0m             \u001b[0;31m# call the bands_req function to wms request for bands on available dates\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/Dissertation_ML/lib/python3.7/site-packages/sentinelhub/data_request.py\u001b[0m in \u001b[0;36mget_data\u001b[0;34m(self, save_data, redownload, data_filter, max_threads, decode_data, raise_download_errors)\u001b[0m\n\u001b[1;32m    125\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_preprocess_request\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msave_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    126\u001b[0m         return self._execute_data_download(data_filter, redownload, max_threads, raise_download_errors,\n\u001b[0;32m--> 127\u001b[0;31m                                            decode_data=decode_data)\n\u001b[0m\u001b[1;32m    128\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    129\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0msave_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata_filter\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mredownload\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_threads\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mraise_download_errors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/Dissertation_ML/lib/python3.7/site-packages/sentinelhub/data_request.py\u001b[0m in \u001b[0;36m_execute_data_download\u001b[0;34m(self, data_filter, redownload, max_threads, raise_download_errors, decode_data)\u001b[0m\n\u001b[1;32m    184\u001b[0m             \u001b[0mconfig\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    185\u001b[0m         )\n\u001b[0;32m--> 186\u001b[0;31m         \u001b[0mdata_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclient\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdownload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_download_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_threads\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_threads\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecode_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdecode_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    187\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    188\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mis_repeating_filter\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/Dissertation_ML/lib/python3.7/site-packages/sentinelhub/download/sentinelhub_client.py\u001b[0m in \u001b[0;36mdownload\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     47\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlock\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mLock\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 49\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdownload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     50\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlock\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/Dissertation_ML/lib/python3.7/site-packages/sentinelhub/download/client.py\u001b[0m in \u001b[0;36mdownload\u001b[0;34m(self, download_requests, max_threads, decode_data)\u001b[0m\n\u001b[1;32m     78\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_download_errors\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     79\u001b[0m                     \u001b[0mtraceback\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexc_info\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 80\u001b[0;31m                     \u001b[0;32mraise\u001b[0m \u001b[0mdownload_exception\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtraceback\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     81\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     82\u001b[0m                 \u001b[0mwarnings\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwarn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdownload_exception\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcategory\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mSHRuntimeWarning\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/Dissertation_ML/lib/python3.7/site-packages/sentinelhub/download/client.py\u001b[0m in \u001b[0;36mdownload\u001b[0;34m(self, download_requests, max_threads, decode_data)\u001b[0m\n\u001b[1;32m     74\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mfuture\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdownload_list\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 76\u001b[0;31m                 \u001b[0mdata_list\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfuture\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     77\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mDownloadFailedException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mdownload_exception\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     78\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_download_errors\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/Dissertation_ML/lib/python3.7/concurrent/futures/_base.py\u001b[0m in \u001b[0;36mresult\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    426\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mCancelledError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    427\u001b[0m             \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_state\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mFINISHED\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 428\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__get_result\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    429\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    430\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_condition\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/Dissertation_ML/lib/python3.7/concurrent/futures/_base.py\u001b[0m in \u001b[0;36m__get_result\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    382\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__get_result\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    383\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_exception\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 384\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_exception\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    385\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    386\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_result\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/Dissertation_ML/lib/python3.7/concurrent/futures/thread.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     55\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 57\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     58\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mBaseException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mexc\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfuture\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/Dissertation_ML/lib/python3.7/site-packages/sentinelhub/download/client.py\u001b[0m in \u001b[0;36m_single_download\u001b[0;34m(self, request, decode_data)\u001b[0m\n\u001b[1;32m     99\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    100\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 101\u001b[0;31m         \u001b[0mresponse_content\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_execute_download\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    102\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    103\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrequest_path\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mrequest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave_response\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mredownload\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexists\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/Dissertation_ML/lib/python3.7/site-packages/sentinelhub/download/handlers.py\u001b[0m in \u001b[0;36mnew_download_func\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m     42\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mattempt_num\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdownload_attempts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mdownload_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrequest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     45\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mrequests\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mRequestException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mexception\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/Dissertation_ML/lib/python3.7/site-packages/sentinelhub/download/handlers.py\u001b[0m in \u001b[0;36mnew_download_func\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m     25\u001b[0m                 \u001b[0mexception\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresponse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatus_code\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mrequests\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatus_codes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcodes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTOO_MANY_REQUESTS\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mDownloadFailedException\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_create_download_failed_message\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexception\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrequest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mexception\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mexception\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mexception\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mDownloadFailedException\u001b[0m: Failed to download from:\nhttps://services.sentinel-hub.com/ogc/wcs/216732ac-7e0c-46f0-a5f8-243652a55bfb?SERVICE=wcs&WARNINGS=False&MAXCC=0.0&BBOX=49.98687%2C-124.25775%2C50.19571%2C-123.90537&FORMAT=image%2Fpng&CRS=EPSG%3A4326&TIME=2018-08-07T19%3A22%3A15Z%2F2018-08-07T19%3A22%3A15Z&RESX=10m&RESY=10m&COVERAGE=TRUE-COLOR-S2-L2A&REQUEST=GetCoverage&VERSION=1.1.2\nwith HTTPError:\n400 Client Error: Bad Request for url: https://services.sentinel-hub.com/ogc/wcs/216732ac-7e0c-46f0-a5f8-243652a55bfb?SERVICE=wcs&WARNINGS=False&MAXCC=0.0&BBOX=49.98687%2C-124.25775%2C50.19571%2C-123.90537&FORMAT=image%2Fpng&CRS=EPSG%3A4326&TIME=2018-08-07T19%3A22%3A15Z%2F2018-08-07T19%3A22%3A15Z&RESX=10m&RESY=10m&COVERAGE=TRUE-COLOR-S2-L2A&REQUEST=GetCoverage&VERSION=1.1.2\nServer response: \"Invalid request\""
     ]
    }
   ],
   "source": [
    "class SentinelData:\n",
    "    \"\"\"\n",
    "    Retreiveing Sentinel data from Sentinel Hub\n",
    "    initialise class with coordinates list, resolution, bounding box coordinates, years and month ranges\n",
    "    make a wcs request for data between November-April\n",
    "    \"\"\"\n",
    "    def __init__(self, coords_list, years, day_month_to, day_month_from):\n",
    "        self.coords_list = coords_list\n",
    "        self.resolution = '10m'\n",
    "        self.area_coords = BBox(bbox=self.coords_list, crs=CRS.WGS84)\n",
    "        self.year_range = years # make a set of years to iterate over \n",
    "        self.day_month_to = day_month_to\n",
    "        self.day_month_from = day_month_from\n",
    "        \n",
    "        \n",
    "        \n",
    "    def retrieve_data(self):\n",
    "        \"\"\" \n",
    "        Create a bounding box and assign CRS. \n",
    "        Create a wcs data request from Sentinel for Sentinel-2 data. \n",
    "        Define max clouds as 20%\n",
    "        \"\"\"\n",
    "        for year in self.year_range:\n",
    "            time_from = \"{}-{}\".format(year, self.day_month_from)\n",
    "            print(\"time_from\", time_from)\n",
    "            time_to = \"{}-{}\".format(year + 1,  self.day_month_to)\n",
    "            print(\"time_to\", time_to)\n",
    "            # make the request for the desired date range \n",
    "            wcs_true_color_request = WcsRequest (\n",
    "                data_collection=DataCollection.SENTINEL2_L1C,\n",
    "                layer='TRUE-COLOR-S2-L2A', # Layer you have configured\n",
    "                bbox=self.area_coords,\n",
    "                time= (time_from, time_to),\n",
    "                resx=self.resolution, # Stick to 10m resolution as this the maximum possible \n",
    "                resy=self.resolution, \n",
    "                config=config,\n",
    "                maxcc=0 # You can define the maximum ammount of cloud coverage you want to allow. \n",
    "            )\n",
    "            print(\"WCS: \", wcs_true_color_request)\n",
    "    \n",
    "            available_dates_list = wcs_true_color_request.get_dates()\n",
    "            print(\"avail dates list: \", available_dates_list)\n",
    "            yield from available_dates_list\n",
    "            \n",
    "    \n",
    "    def get_available_data(self):\n",
    "        \"\"\"\n",
    "        Use get_data() function from Sentinel to retrieve available data for the dates.\n",
    "        \"\"\"\n",
    "        available_dates_list = self.retrieve_data()\n",
    "        i = 0\n",
    "        for date in available_dates_list:\n",
    "            i += 1\n",
    "            print(\"date\", date)\n",
    "            \n",
    "            wcs_true_color_request = WcsRequest(\n",
    "                data_collection=DataCollection.SENTINEL2_L1C,\n",
    "                layer='TRUE-COLOR-S2-L2A', # Layer you have configured\n",
    "                bbox=self.area_coords, \n",
    "                time= date,\n",
    "                resx=self.resolution, # Stick to 10m resolution as this the maximum possible \n",
    "                resy=self.resolution, \n",
    "                config=config,\n",
    "                maxcc=0,# You can define the maximum ammount of cloud coverage you want to allow.\n",
    "                data_folder='/Users/emilybirch/Documents/UCL_Dissertation' \n",
    "            )\n",
    "            \n",
    "            basemap = wcs_true_color_request.get_data()[0] \n",
    "            \n",
    "            # call the bands_req function to wms request for bands on available dates\n",
    "            call_wms = self.bands_req(basemap, date, i) # basemap,\n",
    "            \n",
    "            print('Returned data is of type = %s and length %d.' % (type(basemap), len(basemap)))\n",
    "            print(f'Single element in the list is of type {type(basemap[-1])} and has shape {basemap[-1].shape}')\n",
    "           \n",
    "            \n",
    "            \n",
    "\n",
    "            \n",
    "    def bands_req(self, basemap, date, i):\n",
    "        \"\"\"\n",
    "        wms bands request for the bands making up the Sentinel pic\n",
    "        \"\"\"\n",
    "       # for basemap in self.get_available_wms_data():\n",
    "        basemap = np.array(basemap)\n",
    "        wms_bands_request = WmsRequest(\n",
    "            data_collection=DataCollection.SENTINEL2_L1C,\n",
    "            layer='BANDS-S2-L2A', # We are using the 'BANDS-S2-L2A layer now'\n",
    "            bbox= self.area_coords, # [50.19571, -124.25775, 49.98687, -123.90537], \n",
    "            width=basemap.shape[1], # 10m resolution dims are sourced from the basemap. \n",
    "            height=basemap.shape[0],\n",
    "            time=(date),\n",
    "            image_format=MimeType.TIFF, \n",
    "            maxcc=0,\n",
    "            #resx='10m',\n",
    "           # resy = '10',\n",
    "            config=config,\n",
    "            data_folder='/Users/emilybirch/Documents/UCL_Dissertation/Data_collection/WMS_all_bands' \n",
    "        )        \n",
    "        \n",
    "        bands = wms_bands_request.get_data()[-1] # save_data=True\n",
    "        bands = np.array(bands)\n",
    "        bands = bands.astype('float32') \n",
    "           \n",
    "        # call the split_bands function\n",
    "        get_channels = self.split_bands(bands, basemap, i)\n",
    "\n",
    " \n",
    " \n",
    "# Four coordinates representing the top-left and bottom-right of the bounding box must be separated by comma\n",
    "# The bounding box in WGS84 coordinate system is (longitude and latitude coordinates of upper left and lower right corners)\n",
    "# n,w, s,e\n",
    "\n",
    " #a list of comma-separated numbers of the form \"minx,miny,maxx,maxy\".       \n",
    " # s2, w2 = 49.98434, -124.25091 w,s,n,e\n",
    "#n2, e2 = 50.19579, -123.90758   \n",
    "\n",
    "# wms should be latitude, long\n",
    "\n",
    "\n",
    "    \n",
    "    def plot_data(self):   \n",
    "        \"\"\"\n",
    "        Plot the RGB satellite pics to check its correct/cloud cover is acceptable\n",
    "        and that the image is not cropped.\n",
    "        \"\"\"\n",
    "        basemap = self.get_available_data()\n",
    "        i = 0\n",
    "        for sat_img in basemap:\n",
    "            i += 1\n",
    "            print(\"i\", i)\n",
    "            fig, ax = plt.subplots(1, 1, figsize=(10,10))\n",
    "            plt.imshow(sat_img)\n",
    "            plt.axis('off')\n",
    "            plt.savefig('ala_sat_4_{}.png'.format(i),\n",
    "                        bbox_inches='tight',\n",
    "                        dpi=300)\n",
    "            plt.show()\n",
    "          \n",
    "\n",
    "        \n",
    "        \n",
    "    # Download NIR (b08), DEM and Raw NDSI (no thresholding)          \n",
    "    def split_bands(self, bands, basemap, i):\n",
    "        \"\"\"\n",
    "        Split the bands req into individual bands\n",
    "        Download NIR b08 as single band .tif\n",
    "        Calculate NDSI and download this as .tif\n",
    "        \"\"\"\n",
    "        #bands = self.get_available_wms_data()\n",
    "            \n",
    "        b01 = bands[:,:,0] # Coastal Aerosol\n",
    "        b02 = bands[:,:,1] # Blue\n",
    "        b03 = bands[:,:,2] # Green\n",
    "        b04 = bands[:,:,3] # Red\n",
    "        b05 = bands[:,:,4] # Vegetation Red Edge \n",
    "        b06 = bands[:,:,5] # Vegetation Red Edge\n",
    "        b07 = bands[:,:,6] # Vegetation Red Edge\n",
    "        b08 = bands[:,:,7] # NIR\n",
    "        b08a = bands[:,:,8] # Vegetation Red Edge\n",
    "        b09 = bands[:,:,9] # Water Vapour\n",
    "        b11 = bands[:,:,10] # SWIR\n",
    "        b12 = bands[:,:,11] # SWIR\n",
    "        \n",
    "        \n",
    "        # check b08 is array\n",
    "        print(\"TYPE OF B08:\",(type(b08)))\n",
    " \n",
    "        # get NIR band as .tif\n",
    "        raster = b08\n",
    "        dim = raster.shape\n",
    "        print(dim)\n",
    "        height = dim[0] \n",
    "        print(\"height\", height)\n",
    "        width = dim[1] \n",
    "        print(\"width\", width)\n",
    "       # transform - NEEDS TO BE W,S,E,N. CURRENTLY THE BBOX COORDS ARE S,W,N,E. SO NEED TO SWITCH TO 116,50 NOT 50,116\n",
    "        transform=from_bounds(-123.27264, 49.60259, -122.94511, 49.80043, width, height)  # self.coords_list\n",
    "        print(\"TRANSFORM:\", transform)\n",
    "        os.chdir('/Users/emilybirch/Documents/UCL_Dissertation/Data_collection/NIR')\n",
    "        out_path = ('b08_can_bbox3_{}.tif'.format(i)) \n",
    "        print(\"OUT PATH\", out_path)\n",
    "\n",
    "        write_NIR_band = write_single_channel_gtiff(raster, width, height, transform, out_path)  # self. ?\n",
    "        print(write_NIR_band)\n",
    "\n",
    "        ###########\n",
    "        # calc NDSI from bands\n",
    "        #NDSI = (b03 - b11)/(b03 + b11)\n",
    "        # raster = NDSI\n",
    "       # dim = raster.shape\n",
    "       # print(dim)\n",
    "       # height = dim[0] \n",
    "       # print(\"height\", height)\n",
    "       # width = dim[1] \n",
    "       # print(\"width\", width)\n",
    "       # transform - NEEDS TO BE W,S,E,N. CURRENTLY THE BBOX COORDS ARE S,W,N,E. SO NEED TO SWITCH TO 116,50 NOT 50,116\n",
    "       # transform=from_bounds(-123.27264, 49.60259, -122.94511, 49.80043, width, height)  # self.coords_list\n",
    "       # print(\"TRANSFORM:\", transform)\n",
    "        #os.chdir('/Users/emilybirch/Documents/UCL_Dissertation/Data_collection/NDSI')\n",
    "        # out_path = ('NDSI_can_bbox1_{}.tif'.format(i)) \n",
    "        #print(\"OUT PATH\", out_path)\n",
    "\n",
    "       # write_NDSI_band = write_single_channel_gtiff(raster, width, height, transform, out_path)  # self. ?\n",
    "       # print(write_NDSI_band)\n",
    "\n",
    "        \n",
    "\n",
    "# W,S,E,N. SO NEED TO SWITCH TO 116,50\n",
    "\n",
    "# canbb0x 2. -123.27264, 49.60259, -122.94511, 49.80043. b08_can_bbox2_{}.tif\n",
    "# can box3. -124.25091, 49.98434, -123.90758, 50.19579. b08_can_bbox3_{}.tif\n",
    "\n",
    "# france box1. 6.68625, 46.00263, 7.00556, 46.21018. b08_fr_bbox1_{}.tif\n",
    "# fr box2. 6.26995, 44.5032, 6.57683, 44.71395. b08_fr_bbox2_{}.tif\n",
    "# fr box3. 6.75874, 47.89925, 7.0709, 48.0968. b08_fr_bbox3_{}.tif\n",
    "\n",
    "# Nz box1. 168.67527, -44.64093, 168.99039, -44.42578. b08_nz_bbox1_{}.tif\n",
    "# nz box 2. 169.15172, -44.46215, 169.4559,-44.26874. b08_nz_bbox2_{}.tif\n",
    "# nz box 3. 167.32814, -45.57742, 167.63988, -45.37906. b08_nz_bbox3_{}.tif\n",
    "# nz box 4. 168.7185, -44.21029, 169.00415, -43.99234. b08_nz_bbox4_{}.tif\n",
    "\n",
    "# norway box1. 6.71053, 61.19427, 7.14765, 61.39842. b08_nor_bbox1_{}.tif\n",
    "# nor box2. 11.91172, 62.11413, 12.35366, 62.31454. b08_nor_bbox2_{}.tif\n",
    "# nor box3. 11.68324, 64.5321, 12.17067, 64.72623. b08_nor_bbox3_{}.tif\n",
    "\n",
    "# argentina box1. -70.60757, -36.1615, -70.87261, -36.35363. b08_arg_bbox1_{}.tif\n",
    "# arg box2. -71.07906, -36.90052,-70.80853, -36.7103. b08_arg_bbox2_{}.tif\n",
    "# arg box3. -72.33129, -48.25276, -72.0168, -48.05762. b08_arg_bbox3_{}.tif\n",
    "\n",
    "# alaska box1. -144.4895, 60.58666, -144.04753, 60.78174. b08_al_bbox1_{}.tif\n",
    "# al box2. -145.6761, 60.54723, -145.24079, 60.74312. b08_al_bbox2_{}.tif\n",
    "# al box 3. -146.57959, 60.86118, -146.14288, 61.05052. b08_al_bbox3_{}.tif\n",
    "# al box 4. -146.62525, 61.10963, -146.18168, 61.30145. b08_al_bbox4_{}.tif\n",
    "\n",
    "\n",
    "def write_single_channel_gtiff(raster, width, height, transform, out_path): \n",
    "    \"\"\"\n",
    "    Function to write a single channel .tif file. \n",
    "    Retains the geographic info- extent, crs etc. \n",
    "    \"\"\"\n",
    "    assert len(raster.shape) == 2\n",
    "    print(f'Writing...{out_path}')\n",
    "    with rasterio.open(str(out_path),\n",
    "                       mode='w',\n",
    "                       crs= 'EPSG:4326',   # wgs84         \n",
    "                       driver= 'GTIFF',                \n",
    "                       nodata=  np.nan,\n",
    "                       dtype= raster.dtype,      #  rasterio.uint8,               \n",
    "                       count= 1,                 \n",
    "                       height= height,         \n",
    "                       width= width,     \n",
    "                       # compress='lzw'\n",
    "                       transform=transform # w2, s2, e2, n2, width, height. From bbox\n",
    "                       ) as dst:\n",
    "        dst.write(raster, 1) #.astype(np.uint8)\n",
    "        \n",
    "\n",
    "\n",
    " \n",
    "    \n",
    "    \n",
    "\n",
    "# make sure to only keep the pics that match the good pics used from snow labelled            \n",
    "# duplicate DEM tiles for the amount of pics at each bbox\n",
    "# crop tiles to extent of NIR band pics \n",
    "# resample ?\n",
    "    \n",
    "    \n",
    "# get NDSI single band .tif  \n",
    "# open NDSI, NIR and DEM and stack- put each 3 bands (NIR,DEM,NDSI) into one folder and stack\n",
    "\n",
    "\n",
    "# split into tiny inputs\n",
    "\n",
    "# model\n",
    "\n",
    "\n",
    "\n",
    "#######################################\n",
    "# Call:\n",
    " \n",
    "# FORESTED:\n",
    "\n",
    "# 1. \n",
    "\n",
    "# FRANCE BBOX 1. 0%CC\n",
    "s, w = 46.00263, 6.68625\n",
    "n, e = 46.21018, 7.00556\n",
    "\n",
    "\n",
    "# FRANCE BBOX 2. 0%CC\n",
    "s2, w2 = 44.5032, 6.26995\n",
    "n2, e2 = 44.71395, 6.57683\n",
    "\n",
    "# FRANCE BBOX 3. 0%CC. in Vosges mountains. \n",
    "s3, w3 = 47.89925, 6.75874\n",
    "n3, e3 = 48.0968, 7.0709\n",
    "    \n",
    "coords_fr1 = [w, s, e, n]\n",
    "coords_fr2 = [w2, s2, e2, n2]\n",
    "coords_fr3 = [w3, s3, e3, n3]\n",
    "\n",
    "fr_data1 = SentinelData(coords_fr1, canada_years, canada_day_month_to, canada_day_month_from)\n",
    "fr_data2 = SentinelData(coords_fr2, canada_years, canada_day_month_to, canada_day_month_from)\n",
    "fr_data3 = SentinelData(coords_fr3, canada_years, canada_day_month_to, canada_day_month_from)\n",
    "\n",
    "\n",
    "# get wms\n",
    "plot_fr_wms1 = fr_data1.get_available_data()\n",
    "plot_fr_wms2 = fr_data2.get_available_data()\n",
    "plot_fr_wms3 = fr_data3.get_available_data()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# 2.\n",
    "# define the years and month ranges for data. Nov-April so there is snow cover.\n",
    "# Sentinel 2 data is only available from 2015 onwards\n",
    "canada_years = {2014, 2015, 2016, 2017, 2018, 2019, 2020}\n",
    "\n",
    "# define the years and month ranges for data. Nov-April\n",
    "canada_day_month_to = \"01-01\"\n",
    "canada_day_month_from = \"01-01\"\n",
    "\n",
    "\n",
    "\n",
    "# canada 0%CC. BBOX1. CANADIAN ROCKIES\n",
    "s4, w4 = 50.82675, -116.08768\n",
    "n4, e4 = 51.02583, -115.73474       \n",
    "\n",
    "\n",
    "# CANADA BBOX2 0%CC. VANCOUVER. takes a long time to plot (90 plots)\n",
    "s5, w5 = 49.60259, -123.27264\n",
    "n5, e5 = 49.80043, -122.94511\n",
    "    \n",
    "\n",
    "# canada BBOX3. nr vancouver \n",
    "s6, w6 = 49.98434, -124.25091\n",
    "n6, e6 = 50.19579, -123.90758\n",
    "       \n",
    "    \n",
    "coords_canada1 = [w4, s4, e4, n4]\n",
    "coords_canada2 = [w5, s5, e5, n5]\n",
    "coords_canada3 = [w6, s6, e6, n6]\n",
    "\n",
    "can_data1 = SentinelData(coords_canada1, canada_years, canada_day_month_to, canada_day_month_from)\n",
    "can_data2 = SentinelData(coords_canada2, canada_years, canada_day_month_to, canada_day_month_from)\n",
    "can_data3 = SentinelData(coords_canada3, canada_years, canada_day_month_to, canada_day_month_from)\n",
    "\n",
    "# wcs \n",
    "#plot_data_1 = canada_data.plot_data()\n",
    "\n",
    "\n",
    "# get wms\n",
    "plot_canada_wms1 = can_data1.get_available_data()\n",
    "plot_canada_wms2 = can_data2.get_available_data()\n",
    "plot_canada_wms3 = can_data3.get_available_data()   \n",
    "\n",
    " \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# 3. \n",
    "\n",
    "\n",
    "# NEW ZEALAND 0% CC. BBOX1. FORESTED. gets 3 3/4 pics \n",
    "s7, w7 = -44.64093, 168.67527\n",
    "n7,e7 = -44.42578, 168.99039\n",
    "\n",
    "\n",
    "# NZ BBOX 2 FORESTED. 3 pics  \n",
    "s8,w8 = -44.46215, 169.15172\n",
    "n8,e8 = -44.26874, 169.4559\n",
    "\n",
    "\n",
    "# NZ BBOX 3. 3 pics \n",
    "s9,w9 = -45.57742, 167.32814\n",
    "n9,e9 = -45.37906, 167.63988\n",
    "\n",
    "\n",
    "# NZ bbox 4. \n",
    "s9,w9 = -44.21029, 168.7185\n",
    "n9, e9 = -43.99234, 169.00415\n",
    "    \n",
    "\n",
    "\n",
    "coords_nz1 = [w7, s7, e7, n7]\n",
    "coords_nz2 = [w8, s8, e8, n8]\n",
    "coords_nz3 = [w9, s9, e9, n9]\n",
    "coords_nz4 = [w10, s10, e10, n10]\n",
    "\n",
    "\n",
    "nz_data1 = SentinelData(coords_nz1, canada_years, canada_day_month_to, canada_day_month_from)\n",
    "nz_data2 = SentinelData(coords_nz2, canada_years, canada_day_month_to, canada_day_month_from)\n",
    "nz_data3 = SentinelData(coords_nz3, canada_years, canada_day_month_to, canada_day_month_from)\n",
    "nz_data4 = SentinelData(coords_nz4, canada_years, canada_day_month_to, canada_day_month_from)\n",
    "\n",
    "\n",
    "# get wms\n",
    "plot_nz_wms1 = nz_data1.get_available_data()\n",
    "plot_nz_wms2 = nz_data2.get_available_data()\n",
    "plot_nz_wms3 = nz_data3.get_available_data()\n",
    "plot_nz_wms4 = nz_data4.get_available_data()\n",
    "        \n",
    "    \n",
    "    \n",
    "##################################    \n",
    "    \n",
    "# NON-FORESTED:  \n",
    "\n",
    "\n",
    "# 4. \n",
    "\n",
    "\n",
    "\n",
    "# Norway. scandy mountains. \n",
    "s11, w11 = 61.19427, 6.71053\n",
    "n11, e11 = 61.39842, 7.14765\n",
    "  \n",
    "\n",
    "# BBOX 2 \n",
    "s12, w12 = 62.11413, 11.91172\n",
    "n12, e12 = 62.31454, 12.35366\n",
    "\n",
    "\n",
    "# BBOX 3. nr namsos\n",
    "s13, w13 = 64.5321, 11.68324\n",
    "n13, e13 = 64.72623, 12.17067\n",
    "\n",
    "\n",
    "\n",
    "coords_nor1 = [w11, s11, e11, n11]\n",
    "coords_nor2 = [w12, s12, e12, n12]\n",
    "coords_nor3 = [w13, s13, e13, n13]\n",
    "\n",
    "nor_data1 = SentinelData(coords_nor1, canada_years, canada_day_month_to, canada_day_month_from)\n",
    "nor_data2 = SentinelData(coords_nor2, canada_years, canada_day_month_to, canada_day_month_from)\n",
    "nor_data3 = SentinelData(coords_nor3, canada_years, canada_day_month_to, canada_day_month_from)\n",
    "\n",
    "\n",
    "# get wms\n",
    "plot_nor_wms1 = nor_data1.get_available_data()\n",
    "plot_nor_wms2 = nor_data2.get_available_data()\n",
    "plot_nor_wms3 = nor_data3.get_available_data()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# 5. \n",
    "\n",
    "\n",
    "# Argentina. bbox 1. \n",
    "s14, w14 = -36.1615, -70.60757\n",
    "n14, e14 = -36.35363, -70.87261\n",
    "    \n",
    "\n",
    "# Argentina BBOX2\n",
    "s15, w15 = -36.90052, -71.07906\n",
    "n15, e15 = -36.7103, -70.80853\n",
    "    \n",
    "   \n",
    " # Argentina BBOX3\n",
    "s16, w16 = -48.25276, -72.33129\n",
    "n16, e16 = -48.05762, -72.0168\n",
    "       \n",
    "coords_arg1 = [w14, s14, e14, n14]\n",
    "coords_arg2 = [w15, s15, e15, n15]\n",
    "coords_arg3 = [w16, s16, e16, n16]\n",
    "\n",
    "arg_data1 = SentinelData(coords_arg1, canada_years, canada_day_month_to, canada_day_month_from)\n",
    "arg_data2 = SentinelData(coords_arg2, canada_years, canada_day_month_to, canada_day_month_from)\n",
    "arg_data3 = SentinelData(coords_arg3, canada_years, canada_day_month_to, canada_day_month_from)\n",
    "\n",
    "\n",
    "# get wms\n",
    "plot_arg_wms1 = arg_data1.get_available_data()\n",
    "plot_arg_wms2 = arg_data2.get_available_data()\n",
    "plot_arg_wms3 = arg_data3.get_available_data()\n",
    "  \n",
    "\n",
    "\n",
    "\n",
    " \n",
    " \n",
    "# 6. \n",
    "\n",
    " # Alaska bbox1 3 pics\n",
    "s17, w17 = 60.58666, -144.4895\n",
    "n17, e17 = 60.78174, -144.04753\n",
    "    \n",
    "    \n",
    "    \n",
    "# alaska bbox 2 2 pics\n",
    "s18, w18 = 60.54723, -145.6761\n",
    "n18, e18 = 60.74312, -145.24079\n",
    "    \n",
    "\n",
    "    \n",
    "# alaska bbox 3. 3 pics\n",
    "s19, w19 = 60.86118, -146.57959\n",
    "n19, e19 = 61.05052, -146.14288\n",
    "\n",
    "\n",
    "# alaska bbox 4. 3 pics \n",
    "s20, w20 = 61.10963, -146.62525\n",
    "n20, e20 = 61.30145, -146.18168\n",
    "\n",
    "\n",
    "coords_al1 = [w17, s17, e17, n17]\n",
    "coords_al2 = [w18, s18, e18, n18]\n",
    "coords_al3 = [w19, s19, e19, n19]\n",
    "coords_al4 = [w20, s20, e20, n20]\n",
    "\n",
    "\n",
    "al_data1 = SentinelData(coords_al1, canada_years, canada_day_month_to, canada_day_month_from)\n",
    "al_data2 = SentinelData(coords_al2, canada_years, canada_day_month_to, canada_day_month_from)\n",
    "al_data3 = SentinelData(coords_al3, canada_years, canada_day_month_to, canada_day_month_from)\n",
    "al_data4 = SentinelData(coords_al4, canada_years, canada_day_month_to, canada_day_month_from)\n",
    "\n",
    "\n",
    "# get wms\n",
    "plot_al_wms1 = al_data1.get_available_data()\n",
    "plot_al_wms2 = al_data2.get_available_data()\n",
    "plot_al_wms3 = al_data3.get_available_data()\n",
    "plot_al_wms4 = al_data4.get_available_data()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fb432b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ON QGIS CONVERT DEM FROM INT 16 TO FLOAT 32\n",
    "#Algorithm Translate (convert format) starting…\n",
    "#Input parameters:\n",
    "#{'COPY_SUBDATASETS': True,\n",
    "#'DATA_TYPE': 6,\n",
    "#'EXTRA': '',\n",
    "#'INPUT': 'mergedNzDEM4_3381f8a4_705b_4477_982b_57a90f59bddb',\n",
    "#'NODATA': None,\n",
    "#'OPTIONS': '',\n",
    "#'OUTPUT': <QgsProcessingOutputLayerDefinition {'sink':/Users/emilybirch/Documents/UCL_Dissertation/Data_collection/DEM/Directory_for_DEM/DEM_float32/al_DEM1mergedNzDEM4.tif, 'createOptions': {}}>,\n",
    "#'TARGET_CRS': None}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "3cbe6f84",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-127-195b68071562>, line 81)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-127-195b68071562>\"\u001b[0;36m, line \u001b[0;32m81\u001b[0m\n\u001b[0;31m    dem_file4 =\u001b[0m\n\u001b[0m                ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "# https://stackoverflow.com/questions/10454316/how-to-project-and-resample-a-grid-to-match-another-grid-with-gdal-python \n",
    "# crops AND resamples!!\n",
    "\n",
    "from osgeo import gdal, gdalconst\n",
    "\n",
    "# dems have already been converted to the same data type float 32 on qgis\n",
    "# cropping and matching the resolution of DEMs to the b08 band\n",
    "# only need to resample and crop 1 dem per bbox. \n",
    "# then duplicate this for however many pics are at this bbox:\n",
    "# - canada: box1 x 4 , b2 x 3, b3 x 5\n",
    "# - France: box1 x 4, b2 x 4, b3 x 4\n",
    "# - NZ: box1 x 3, b2 x 3, b3 x 3, b4 x 3\n",
    "# - Alaska: box1 x 4, b2 x 2, b3 x 3, b4 x 3\n",
    "# - Argentina: b1 x 5, b2 x 3, b3 x 4 \n",
    "#- Norway: b1 x5, b2 x 4, b3 x 4\n",
    "\n",
    "# 20 boxes in total so need to resamp and crop 20 DEM pics\n",
    "\n",
    "\n",
    "def resamp_crop(dem_file, nir_file, out_file):\n",
    "    \"\"\"\n",
    "    resample the DEM to the same resolution as the NIR band\n",
    "    crop the DEM to the same extent as the NIR band\n",
    "    \"\"\"\n",
    "    # Source. the DEM from DEM_float32 folder \n",
    "    os.chdir('/Users/emilybirch/Documents/UCL_Dissertation/Data_collection/DEM/Directory_for_DEM/DEM_float32')\n",
    "    src_filename = dem_file\n",
    "    print(\"DEM_PATH\", dem_file)\n",
    "    src = gdal.Open(src_filename, gdalconst.GA_ReadOnly)\n",
    "    src_proj = src.GetProjection()\n",
    "    src_geotrans = src.GetGeoTransform()\n",
    "\n",
    "    # section of source that matches this. using band 8 (NIR) as the one to crop and resample to\n",
    "    os.chdir('/Users/emilybirch/Documents/UCL_Dissertation/Data_collection/NIR')\n",
    "    match_filename = nir_file\n",
    "    match_ds = gdal.Open(match_filename, gdalconst.GA_ReadOnly)\n",
    "    match_proj = match_ds.GetProjection()\n",
    "    match_geotrans = match_ds.GetGeoTransform()\n",
    "    wide = match_ds.RasterXSize\n",
    "    high = match_ds.RasterYSize\n",
    "\n",
    "    # Output / destination\n",
    "    os.chdir('/Users/emilybirch/Documents/UCL_Dissertation/Data_collection/DEM/resamp_crop_DEM')\n",
    "    dst_filename = out_path\n",
    "    dst = gdal.GetDriverByName('GTiff').Create(dst_filename, wide, high, 1, gdalconst.GDT_Float32)\n",
    "    dst.SetGeoTransform( match_geotrans )\n",
    "    dst.SetProjection( match_proj)\n",
    "\n",
    "    # Do the work\n",
    "    gdal.ReprojectImage(src, dst, src_proj, match_proj, gdalconst.GRA_Bilinear)\n",
    "\n",
    "    del dst # Flush\n",
    "    \n",
    "    \n",
    "\n",
    "    \n",
    "# call. Canada bbox1 \n",
    "dem_file1 = 'al_DEM1mergedCanDEM1.tif'\n",
    "nir_file1 = 'b08_can_bbox1_1.tif'\n",
    "out_file1 = 'Resampled_Canb1.tif'\n",
    "call_can1 = resamp_crop(dem_file1, nir_path1, out_path1)\n",
    "\n",
    "\n",
    "# call. Canada bbox2\n",
    "dem_file2 = 'al_DEM1mergedCanDEM2.tif'\n",
    "nir_file2 = 'b08_can_bbox1_2.tif'\n",
    "out_file2 = 'Resampled_Canb2.tif'\n",
    "call_can2 = resamp_crop(dem_file2, nir_path2, out_path2)\n",
    "\n",
    "\n",
    "\n",
    "# call. Canada bbox3 \n",
    "dem_file3 = 'al_DEM1mergedCanDEM3.tif'\n",
    "nir_file3 = 'b08_can_bbox3_1.tif'\n",
    "out_file3 = 'Resampled_Canb3.tif'\n",
    "call_can3 = resamp_crop(dem_file3, nir_path3, out_path3)\n",
    "\n",
    "\n",
    "\n",
    "# call. FR bbox1 \n",
    "dem_file4 = 'al_DEM1mergedFrDEM1.tif'\n",
    "nir_file4 = 'b08_fr_bbox1_1.tif'\n",
    "out_file4 = 'Resampled_Frb1.tif'\n",
    "call_fr4 = resamp_crop(dem_file4, nir_file4, out_file4)\n",
    "\n",
    "# call. FR bbox2 \n",
    "dem_file5 = 'al_DEM1mergedFrDEM2.tif'\n",
    "nir_file5 = 'b08_fr_bbox2_1.tif'\n",
    "out_file5 = 'Resampled_Frb2.tif'\n",
    "call_fr5 = resamp_crop(dem_file5, nir_file5, out_file5)\n",
    "\n",
    "# call. FR bbox3 \n",
    "dem_file6 ='al_DEM1mergedFrDEM3.tif'\n",
    "nir_file6 = 'b08_fr_bbox3_1.tif'\n",
    "out_file6 = 'Resampled_Frb2.tif'\n",
    "call_fr6 = resamp_crop(dem_file6, nir_file6, out_file6)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# call. NZ bbox1 \n",
    "dem_file7 = 'al_DEM1mergedNzDEM1.tif'\n",
    "nir_file7 = 'b08_nz_bbox1_1.tif'\n",
    "out_file7 = 'Resampled_Nzb1.tif'\n",
    "callnz7 = resamp_crop(dem_file7, nir_file7, out_file7)\n",
    "\n",
    "# call. NZ bbox2 \n",
    "dem_file8 = 'al_DEM1mergedNzDEM2.tif'\n",
    "nir_file8 = 'b08_nz_bbox2_1.tif'\n",
    "out_file8 = 'Resampled_Nzb2.tif'\n",
    "callnz8 = resamp_crop(dem_file8, nir_file8, out_file8)\n",
    "\n",
    "# call. NZ bbox3 \n",
    "dem_file9 = 'al_DEM1mergedNzDEM3.tif'\n",
    "nir_file9 = 'b08_nz_bbox3_1.tif'\n",
    "out_file9 = 'Resampled_Nzb3.tif'\n",
    "callnz9 = resamp_crop(dem_file9, nir_file9, out_file9)\n",
    "\n",
    "# call. NZ bbox4\n",
    "dem_file10 = 'al_DEM1mergedNzDEM4.tif'\n",
    "nir_file10 = 'b08_nz_bbox4_1.tif'\n",
    "out_file10 = 'Resampled_Nzb4.tif'\n",
    "callnz10 = resamp_crop(dem_file10, nir_file10, out_file10)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# call. Alaska bbox1 \n",
    "dem_file11 = 'al_DEM1mergedAlDEM1.tif'\n",
    "nir_file11 = 'b08_al_bbox1_1.tif'\n",
    "out_file11 = 'Resampled_Alb1.tif'\n",
    "callAl11 = resamp_crop(dem_file11, nir_file11, out_file11)\n",
    "\n",
    "\n",
    "# call. Al bbox2 \n",
    "dem_file12 = 'al_DEM1mergedAlDEM2.tif'\n",
    "nir_file12 = 'b08_al_bbox2_1.tif'\n",
    "out_file12 = 'Resampled_Alb2.tif'\n",
    "callAl12 = resamp_crop(dem_file12, nir_file12, out_file12)\n",
    "\n",
    "\n",
    "# call. Al bbox3 \n",
    "dem_file13 = 'al_DEM1mergedAlDEM3.tif'\n",
    "nir_file13 = 'b08_al_bbox3_1.tif'\n",
    "out_file13 = 'Resampled_Alb3.tif'\n",
    "callAl13 = resamp_crop(dem_file13, nir_file13, out_file13)\n",
    "\n",
    "\n",
    "# call. Arg bbox1 \n",
    "dem_file14 = 'al_DEM1mergedArgDEM1.tif'\n",
    "nir_file14 = 'b08_arg_bbox1_1.tif'\n",
    "out_file14 = 'Resampled_Argb1.tif'\n",
    "callArg14 = resamp_crop(dem_file14, nir_file14, out_file14)\n",
    "\n",
    "\n",
    "# call. Arg bbox2 \n",
    "dem_file15 = 'al_DEM1mergedArgDEM2.tif'\n",
    "nir_file15 = 'b08_arg_bbox2_1.tif'\n",
    "out_file15 = 'Resampled_Argb2.tif'\n",
    "callArg15 = resamp_crop(dem_file15, nir_file15, out_file15)\n",
    "\n",
    "\n",
    "# call. Arg bbox3 \n",
    "dem_file16 = 'al_DEM1mergedArgDEM3.tif'\n",
    "nir_file16 = 'b08_arg_bbox3_1.tif'\n",
    "out_file14 = 'Resampled_Argb3.tif'\n",
    "callArg14 = resamp_crop(dem_file14, nir_file14, out_file14)\n",
    "\n",
    "\n",
    "# call. Arg bbox4\n",
    "dem_file166 = 'al_DEM1mergedArgDEM4.tif'\n",
    "nir_file166 = 'b08_arg_bbox4_1.tif'\n",
    "out_file166 = 'Resampled_Argb3.tif'\n",
    "callArg166 = resamp_crop(dem_file166, nir_file166, out_file166)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# call. Norway bbox1 \n",
    "dem_file17 = 'al_DEM1mergedNorDEM1.tif'\n",
    "nir_file17 = 'b08_nor_bbox1_1.tif'\n",
    "out_file17 = 'Resampled_Norb1.tif'\n",
    "callArg17 = resamp_crop(dem_file17, nir_file17, out_file17)\n",
    "\n",
    "\n",
    "# call. Nor bbox2 \n",
    "dem_file18 = 'al_DEM1mergedNorDEM2.tif'\n",
    "nir_file18 = 'b08_nor_bbox2_1.tif'\n",
    "out_file18 = 'Resampled_Norb2.tif'\n",
    "callArg18 = resamp_crop(dem_file18, nir_file18, out_file18)\n",
    "\n",
    "\n",
    "# call. Nor bbox3 \n",
    "dem_file19 = 'al_DEM1mergedNorDEM3.tif'\n",
    "nir_file19 = 'b08_nor_bbox3_1.tif'\n",
    "out_file19 = 'Resampled_Norb3.tif'\n",
    "callArg19 = resamp_crop(dem_file19, nir_file19, out_file19)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "fac2b7dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:rasterio._env:CPLE_AppDefined in Setting nodata to nan on band 2, but band 1 has nodata at nan. The TIFFTAG_GDAL_NODATA only support one value per dataset. This value of nan will be used for all bands on re-opening\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ALL BANDS path: ['/Users/emilybirch/Documents/UCL_Dissertation/Data_collection/stacked/CanB1_pic1/Can_box1_pic1_band2.tif', '/Users/emilybirch/Documents/UCL_Dissertation/Data_collection/stacked/CanB1_pic1/Can_box1_pic1_band1.tif']\n",
      "META: {'driver': 'GTiff', 'dtype': 'float32', 'nodata': nan, 'width': 2474, 'height': 2214, 'count': 1, 'crs': CRS.from_epsg(4326), 'transform': Affine(0.00014265966046887786, 0.0, -116.08768,\n",
      "       0.0, -8.991869918699284e-05, 51.02583)}\n",
      "NEW TIF: canb1_pic1_stacked.tif\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "plot_rgb() got an unexpected keyword argument 'stcaked'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-122-204d7273a601>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     73\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m \u001b[0;31m# call stack func\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 75\u001b[0;31m \u001b[0mcall_stack\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstack_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mall_bands_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnew_tif_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     76\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     77\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-122-204d7273a601>\u001b[0m in \u001b[0;36mstack_array\u001b[0;34m(all_bands_list, new_tif_path)\u001b[0m\n\u001b[1;32m     54\u001b[0m             \u001b[0mstretch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m             \u001b[0mfigsize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m6\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 56\u001b[0;31m             title=\"Stacked NIR, DEM Image\")\n\u001b[0m\u001b[1;32m     57\u001b[0m         \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: plot_rgb() got an unexpected keyword argument 'stcaked'"
     ]
    }
   ],
   "source": [
    "# stack DEM, NIR and NDSI and save as final .tif\n",
    "# EarthPy has a stack() function that allows you to take a set of .tif files that are all in the same \n",
    "# spatial extent, CRS and resolution and either export them together a single stacked .tif file or work with them in Python directly as a stacked numpy array.\n",
    "\n",
    "# use es.stack() function of earthpy library to create a raster stack of multi-band raster. It need three steps:\n",
    "\n",
    "#Create a raster list using glob() function\n",
    "#Create a path and define a name for mutli-band raster\n",
    "#Apply es.stack() to creat new stacked raster with all bands save as multi tif\n",
    "#Then apply rio.open to read the raster bands\n",
    "\n",
    "\n",
    "\n",
    "import glob\n",
    "import earthpy.plot as ep\n",
    "import earthpy.spatial as es\n",
    "import rasterio as rio\n",
    "\n",
    "\n",
    "\n",
    "def stack_array(all_bands_list, new_tif_path):  # ADD THE NDSI!!!\n",
    "    \"\"\"\n",
    "    stack DEM, raw NDSI and NIR (b08)\n",
    "    download multi-band .tif of all three bands\n",
    "\n",
    "    \"\"\" \n",
    "    all_bands_list = all_bands_list \n",
    "    print(\"ALL BANDS path:\", all_bands_list)\n",
    "    with rio.open(all_bands_list[0]) as src:\n",
    "        meta = src.meta\n",
    "        print(\"META:\",meta)\n",
    "        # Update meta to reflect the number of layers\n",
    "        meta.update(count = len(all_bands_list))\n",
    "\n",
    "        new_stacked_tif = new_tif_path\n",
    "        print(\"NEW TIF:\", new_stacked_tif)\n",
    "        band_stack, bands_meta = es.stack(all_bands_list,\n",
    "                                        new_stacked_tif)      \n",
    "\n",
    "        with rio.open(new_stacked_tif) as src:\n",
    "            sentinel_multi = src.read() \n",
    "\n",
    "        # plot all bands\n",
    "        band_titles = [\"NIR\", \"DEM\"]\n",
    "        ep.plot_bands(sentinel_multi,\n",
    "                  title=band_titles, cbar=False)\n",
    "        plt.show()\n",
    "  \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    " \n",
    "# set dir\n",
    "os.chdir('/Users/emilybirch/Documents/UCL_Dissertation/Data_collection/stacked/CanB1_pic1')\n",
    "os.getcwd()\n",
    "\n",
    "canb1_pic1_bands_list = ['Can_box1_pic1_band1.tif', 'Can_box1_pic1_band2.tif']\n",
    "\n",
    "\n",
    "\n",
    "# export as same name as snow labelled pis  \n",
    "new_tif_path = \"canb1_pic1_stacked.tif\"\n",
    "\n",
    "# call stack func\n",
    "call_stack = stack_array(canb1_pic1_bands_list, new_tif_path)\n",
    "            \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5202f5a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "###################################################"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "matched-setup",
   "metadata": {},
   "source": [
    "If you just wanted to download a true colour composite, you could use WcsRequest()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "touched-thread",
   "metadata": {},
   "source": [
    "If you want to access the full Sentinel-2 product (with all channels) you can use wms request. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "objective-tribune",
   "metadata": {},
   "source": [
    "We can  then use band 2 and band 11 (SWIR and Blue) to create a normalised difference snow index (NDSI) and the normalised difference water index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "f7b16386",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/Users/emilybirch/Documents/UCL_Dissertation/Data_collection/DEM/France/BOX2/tifs/ALPSMLC30_N044E006_DSM.tif'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m~/opt/anaconda3/envs/Dissertation_ML/lib/python3.7/shutil.py\u001b[0m in \u001b[0;36mmove\u001b[0;34m(src, dst, copy_function)\u001b[0m\n\u001b[1;32m    565\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 566\u001b[0;31m         \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrename\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreal_dst\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    567\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mOSError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/Users/emilybirch/Documents/UCL_Dissertation/Data_collection/DEM/France/BOX2/tifs/ALPSMLC30_N044E006_DSM.tif' -> '/Users/emilybirch/Documents/UCL_Dissertation/Data_collection/DEM/Directory_for_DEM/Final_DEM_pics/mergedFrDEM2.tif'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-65-e6eb94a5d629>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;31m# France bbox 2. only 1 tile, so move to final DEMs folder and rename\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mshutil\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mshutil\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmove\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/Users/emilybirch/Documents/UCL_Dissertation/Data_collection/DEM/France/BOX2/tifs/ALPSMLC30_N044E006_DSM.tif'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'/Users/emilybirch/Documents/UCL_Dissertation/Data_collection/DEM/Directory_for_DEM/Final_DEM_pics/mergedFrDEM2.tif'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;31m# Alaska: only 1 tif per. bbox2 and bbox4\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/Dissertation_ML/lib/python3.7/shutil.py\u001b[0m in \u001b[0;36mmove\u001b[0;34m(src, dst, copy_function)\u001b[0m\n\u001b[1;32m    578\u001b[0m             \u001b[0mrmtree\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    579\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 580\u001b[0;31m             \u001b[0mcopy_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreal_dst\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    581\u001b[0m             \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munlink\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    582\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mreal_dst\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/Dissertation_ML/lib/python3.7/shutil.py\u001b[0m in \u001b[0;36mcopy2\u001b[0;34m(src, dst, follow_symlinks)\u001b[0m\n\u001b[1;32m    264\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdst\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    265\u001b[0m         \u001b[0mdst\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdst\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbasename\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 266\u001b[0;31m     \u001b[0mcopyfile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdst\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfollow_symlinks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfollow_symlinks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    267\u001b[0m     \u001b[0mcopystat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdst\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfollow_symlinks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfollow_symlinks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    268\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mdst\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/Dissertation_ML/lib/python3.7/shutil.py\u001b[0m in \u001b[0;36mcopyfile\u001b[0;34m(src, dst, follow_symlinks)\u001b[0m\n\u001b[1;32m    118\u001b[0m         \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msymlink\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreadlink\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdst\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    119\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 120\u001b[0;31m         \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'rb'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mfsrc\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    121\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdst\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'wb'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mfdst\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    122\u001b[0m                 \u001b[0mcopyfileobj\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfsrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfdst\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/Users/emilybirch/Documents/UCL_Dissertation/Data_collection/DEM/France/BOX2/tifs/ALPSMLC30_N044E006_DSM.tif'"
     ]
    }
   ],
   "source": [
    "# FILES HAVE MOVED, DO NOT NEED TO RUN AGAIN\n",
    "\n",
    "# mMove and rename the single .tif tiles which do not need merging\n",
    "# France bbox 2. only 1 tile, so move to final DEMs folder and rename\n",
    "import shutil\n",
    "shutil.move('/Users/emilybirch/Documents/UCL_Dissertation/Data_collection/DEM/France/BOX2/tifs/ALPSMLC30_N044E006_DSM.tif', '/Users/emilybirch/Documents/UCL_Dissertation/Data_collection/DEM/Directory_for_DEM/Final_DEM_pics/mergedFrDEM2.tif')\n",
    "\n",
    "# Alaska: only 1 tif per. bbox2 and bbox4\n",
    "import shutil\n",
    "shutil.move('/Users/emilybirch/Documents/UCL_Dissertation/Data_collection/DEM/Alaska/BOX2/tifs/ALPSMLC30_N060W145_DSM.tif', '/Users/emilybirch/Documents/UCL_Dissertation/Data_collection/DEM/Directory_for_DEM/Final_DEM_pics/mergedAlDEM2.tif')\n",
    "shutil.move('/Users/emilybirch/Documents/UCL_Dissertation/Data_collection/DEM/Alaska/BOX4/tifs/ALPSMLC30_N061W146_DSM.tif', '/Users/emilybirch/Documents/UCL_Dissertation/Data_collection/DEM/Directory_for_DEM/Final_DEM_pics/mergedAlDEM4.tif')\n",
    "\n",
    "# Argentina\n",
    "import shutil\n",
    "shutil.move(\"/Users/emilybirch/Documents/UCL_Dissertation/Data_collection/DEM/Argentina/BOX1/tifs/ALPSMLC30_S036W070_DSM.tif\", '/Users/emilybirch/Documents/UCL_Dissertation/Data_collection/DEM/Directory_for_DEM/Final_DEM_pics/mergedArgDEM1.tif')\n",
    "shutil.move(\"/Users/emilybirch/Documents/UCL_Dissertation/Data_collection/DEM/Argentina/BOX2/tifs/ALPSMLC30_S036W071_DSM.tif\", '/Users/emilybirch/Documents/UCL_Dissertation/Data_collection/DEM/Directory_for_DEM/Final_DEM_pics/mergedArgDEM2.tif') \n",
    "shutil.move(\"/Users/emilybirch/Documents/UCL_Dissertation/Data_collection/DEM/Argentina/BOX3/tifs/ALPSMLC30_S048W072_DSM.tif\", '/Users/emilybirch/Documents/UCL_Dissertation/Data_collection/DEM/Directory_for_DEM/Final_DEM_pics/mergedArgDEM3.tif') \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "b74fef92",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['/Users/emilybirch/Documents/UCL_Dissertation/Data_collection/DEM/Canada/BBOX2/tifs/ALPSMLC30_N050W122_DSM.tif', '/Users/emilybirch/Documents/UCL_Dissertation/Data_collection/DEM/Canada/BBOX2/tifs/ALPSMLC30_N049W123_DSM.tif', '/Users/emilybirch/Documents/UCL_Dissertation/Data_collection/DEM/Canada/BBOX2/tifs/ALPSMLC30_N050W123_DSM.tif', '/Users/emilybirch/Documents/UCL_Dissertation/Data_collection/DEM/Canada/BBOX2/tifs/ALPSMLC30_N049W122_DSM.tif', '/Users/emilybirch/Documents/UCL_Dissertation/Data_collection/DEM/Canada/BBOX2/tifs/ALPSMLC30_N049W124_DSM.tif']\n",
      "['/Users/emilybirch/Documents/UCL_Dissertation/Data_collection/DEM/Canada/BBOX2/tifs/ALPSMLC30_N050W122_DSM.tif', '/Users/emilybirch/Documents/UCL_Dissertation/Data_collection/DEM/Canada/BBOX2/tifs/ALPSMLC30_N049W123_DSM.tif', '/Users/emilybirch/Documents/UCL_Dissertation/Data_collection/DEM/Canada/BBOX2/tifs/ALPSMLC30_N050W123_DSM.tif', '/Users/emilybirch/Documents/UCL_Dissertation/Data_collection/DEM/Canada/BBOX2/tifs/ALPSMLC30_N049W122_DSM.tif', '/Users/emilybirch/Documents/UCL_Dissertation/Data_collection/DEM/Canada/BBOX2/tifs/ALPSMLC30_N049W124_DSM.tif']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# merge DEM tiles for each bbox\n",
    "import os \n",
    "from osgeo import gdal\n",
    "import glob\n",
    "import subprocess\n",
    "import gdal\n",
    "from gdalconst import GA_ReadOnly\n",
    "\n",
    "\n",
    "# set dir\n",
    "os.chdir('/Users/emilybirch/Documents/UCL_Dissertation/Data_collection/DEM/Directory_for_DEM/DEM_merged')\n",
    "os.getcwd()\n",
    "\n",
    "# CANADA. make a list of DEM files to merge. get all with .tif extension\n",
    "can_bbox1_path = \"/Users/emilybirch/Documents/UCL_Dissertation/Data_collection/DEM/Canada/BBOX1/tifs/*.tif\"\n",
    "can_bbox2_path = \"/Users/emilybirch/Documents/UCL_Dissertation/Data_collection/DEM/Canada/BBOX2/tifs/*.tif\"\n",
    "can_bbox3_path = \"/Users/emilybirch/Documents/UCL_Dissertation/Data_collection/DEM/Canada/BBOX2/tifs/*.tif\"\n",
    "# retrieve files with this path name and extension\n",
    "CanDEMList_1 = glob.glob(can_bbox1_path)\n",
    "CanDEMList_2 = glob.glob(can_bbox2_path)\n",
    "CanDEMList_3 = glob.glob(can_bbox3_path)\n",
    "print(CanDEMList_3)\n",
    "\n",
    "# call subprocess gdal merge to merge the DEM tiles\n",
    "cmd = \"gdal_merge.py -o mergedCanDEM1.tif\"\n",
    "subprocess.call(cmd.split()+CanDEMList_1)\n",
    "# Canada bbox2 merge\n",
    "cmd = \"gdal_merge.py -o mergedCanDEM2.tif\"\n",
    "subprocess.call(cmd.split()+CanDEMList_2)\n",
    "# Canada bbox3 merge\n",
    "cmd = \"gdal_merge.py -o mergedCanDEM3.tif\"\n",
    "subprocess.call(cmd.split()+CanDEMList_3)\n",
    "\n",
    "\n",
    "# France. Set path to DEM tif files\n",
    "fr_bbox1 = \"/Users/emilybirch/Documents/UCL_Dissertation/Data_collection/DEM/France/BBOX1/tifs/*.tif\"\n",
    "fr_bbox3 = \"/Users/emilybirch/Documents/UCL_Dissertation/Data_collection/DEM/France/BOX3/tifs/*.tif\"\n",
    "#retrieve files with this path name and extension\n",
    "fr_list1 = glob.glob(fr_bbox1)\n",
    "fr_list3 = glob.glob(fr_bbox3)\n",
    "\n",
    "# merge the DEM tiles. bbox1\n",
    "cmd = \"gdal_merge.py -o mergedFrDEM1.tif\"\n",
    "subprocess.call(cmd.split()+fr_list1)\n",
    "# Fr bbox3 merge\n",
    "cmd = \"gdal_merge.py -o mergedFrDEM3.tif\"\n",
    "subprocess.call(cmd.split()+fr_list3)\n",
    "\n",
    "\n",
    "\n",
    "# Alaska. Set path to DEM tif files\n",
    "alask_path1 = \"/Users/emilybirch/Documents/UCL_Dissertation/Data_collection/DEM/Alaska/BBOX1/tifs/*.tif\"\n",
    "alask_path3 = \"/Users/emilybirch/Documents/UCL_Dissertation/Data_collection/DEM/Alaska/BOX3/tifs/*.tif\"\n",
    "#retrieve files with this path name and extension\n",
    "al_DEM_list1 = glob.glob(alask_path1)\n",
    "al_DEM_list3 = glob.glob(alask_path3)\n",
    "\n",
    "# call subprocess gdal merge to merge the DEM tiles\n",
    "cmd = \"gdal_merge.py -o mergedAlDEM1.tif\"\n",
    "subprocess.call(cmd.split()+al_DEM_list1)\n",
    "# bbox3 merge\n",
    "cmd = \"gdal_merge.py -o mergedAlDEM3.tif\"\n",
    "subprocess.call(cmd.split()+al_DEM_list3)\n",
    "\n",
    "\n",
    "# NZ. 4 bbox\n",
    "nz_path3 = '/Users/emilybirch/Documents/UCL_Dissertation/Data_collection/DEM/NZ/BBOX3/tifs/*.tif'\n",
    "nz_path4 = '/Users/emilybirch/Documents/UCL_Dissertation/Data_collection/DEM/NZ/BBOX4/tifs/*.tif'\n",
    "\n",
    "nz_DEM_list3 = glob.glob(nz_path3)\n",
    "nz_DEM_list4 = glob.glob(nz_path4)\n",
    "\n",
    "# call subprocess gdal merge to merge the DEM tiles\n",
    "cmd = \"gdal_merge.py -o mergedNzDEM3.tif\"\n",
    "subprocess.call(cmd.split()+nz_DEM_list3)\n",
    "# bbox3 merge\n",
    "cmd = \"gdal_merge.py -o mergedNzDEM4.tif\"\n",
    "subprocess.call(cmd.split()+nz_DEM_list4)\n",
    "\n",
    "\n",
    "# Norway\n",
    "nor_path1 = '/Users/emilybirch/Documents/UCL_Dissertation/Data_collection/DEM/Norway/bbox1/tifs/*.tif'\n",
    "nor_path2 = '/Users/emilybirch/Documents/UCL_Dissertation/Data_collection/DEM/Norway/bbox2/tifs/*.tif'\n",
    "nor_path3 = '/Users/emilybirch/Documents/UCL_Dissertation/Data_collection/DEM/Norway/bbox3/tifs/*.tif'\n",
    "\n",
    "NorDEMList_1 = glob.glob(nor_path1)\n",
    "NorDEMList_2 = glob.glob(nor_path2)\n",
    "NorDEMList_3 = glob.glob(nor_path3)\n",
    "print(CanDEMList_3)\n",
    "\n",
    "# call subprocess gdal merge to merge the DEM tiles\n",
    "cmd = \"gdal_merge.py -o mergedNorDEM1.tif\"\n",
    "subprocess.call(cmd.split()+NorDEMList_1)\n",
    "# Canada bbox2 merge\n",
    "cmd = \"gdal_merge.py -o mergedNorDEM2.tif\"\n",
    "subprocess.call(cmd.split()+NorDEMList_2)\n",
    "# Canada bbox3 merge\n",
    "cmd = \"gdal_merge.py -o mergedNorDEM3.tif\"\n",
    "subprocess.call(cmd.split()+NorDEMList_3)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3391be64",
   "metadata": {},
   "outputs": [],
   "source": [
    "# clip to extent of another raster file\n",
    "data = gdal.Open('can_sat_1_1.png', GA_ReadOnly)\n",
    "print(data)\n",
    "geoTransform = data.GetGeoTransform()\n",
    "print(\"GEO\", geoTransform)\n",
    "minx = geoTransform[0]\n",
    "print(\"MIN\", minx)\n",
    "maxy = geoTransform[3]\n",
    "print(\"MAX\", maxy)\n",
    "maxx = minx + geoTransform[1] * data.RasterXSize\n",
    "miny = maxy + geoTransform[5] * data.RasterYSize\n",
    "call('gdal_translate -projwin ' + ' '.join([str(x) for x in [minx, maxy, maxx, miny]]) + ' -of GTiff mergedCanDEM1.tif cropCanDEM1.tif', shell=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f531e589",
   "metadata": {},
   "outputs": [],
   "source": [
    "# clip to extent of sample pic\n",
    "import numpy as np\n",
    "import rasterio\n",
    "from rasterio import features\n",
    "from rasterio.mask import mask\n",
    "\n",
    "\n",
    "# ****** make this path have both dem and NIR pics in\n",
    "os.chdir('/Users/emilybirch/Documents/UCL_Dissertation/Data_collection/DEM/Directory_for_DEM/DEM_pics')\n",
    "os.getcwd()\n",
    "\n",
    "# the first one is your raster on the right. use the single band NIR .tif to crop to\n",
    "# and the second one your red raster\n",
    "with rasterio.open('b08_can_bbox1_1') as src, \\\n",
    "        rasterio.open('mergedCanDEM1.tif') as src_to_crop:\n",
    "    src_affine = src.meta.get(\"transform\") # this is s,w,n,e, height, width, pixel size etc.\n",
    "\n",
    "    # Read the first band of the \"mask\" raster\n",
    "    band = src.read(1)\n",
    "    # Use the same value on each pixel with data\n",
    "    # in order to speedup the vectorization\n",
    "    band[np.where(band!=src.nodata)] = 1\n",
    "\n",
    "    geoms = []\n",
    "    for geometry, raster_value in features.shapes(band, transform=src_affine):\n",
    "        # get the shape of the part of the raster\n",
    "        # not containing \"nodata\"\n",
    "        if raster_value == 1:\n",
    "            geoms.append(geometry)\n",
    "\n",
    "    # crop the second raster using the\n",
    "    # previously computed shapes\n",
    "    out_img, out_transform = mask(\n",
    "        dataset=src_to_crop,\n",
    "        shapes=geoms,\n",
    "        crop=True,\n",
    "    )\n",
    "\n",
    "    # save the result\n",
    "    # (don't forget to set the appropriate metadata)\n",
    "    with rasterio.open(\n",
    "        'result.tif',\n",
    "        'w',\n",
    "        driver='GTiff',\n",
    "        height=out_img.shape[1],\n",
    "        width=out_img.shape[2],\n",
    "        count=src.count,\n",
    "        dtype=out_img.dtype,\n",
    "        transform=out_transform,\n",
    "    ) as dst:\n",
    "        dst.write(out_img)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d1055eb",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Process DEM geomorphology pics \n",
    "# merge DEM tiles, reproject to projected crs with m units, resample to 10x10m pixel size, crop to bbox\n",
    "import os \n",
    "from osgeo import gdal\n",
    "import glob\n",
    "import subprocess\n",
    "from gdal import gdalconst\n",
    "\n",
    "\n",
    "\n",
    "# set directory to location of all final DEM pics \n",
    "os.chdir('/Users/emilybirch/Documents/UCL_Dissertation/Data_collection/DEM/Directory_for_DEM/Final_DEM_pics')\n",
    "os.getcwd()\n",
    "\n",
    "# can_list = [can_bbox1_path, can_bbox2_path, can_bbox3_path]\n",
    "# i = 0\n",
    "#for f in can_list:\n",
    "    # i += 1\n",
    "    # glob.glob(f)\n",
    "    # cmd = \"gdal_merge.py -o 'mergedCanDEM1_{}.tif'.format(i)\"\n",
    "    # subprocess.call(cmd.split()+f)\n",
    "\n",
    "# CANADA. make a list of DEM files to merge. get all with .tif extension\n",
    "can_bbox1_path = \"/Users/emilybirch/Documents/UCL_Dissertation/Data_collection/DEM/Canada/BBOX1/tifs/*.tif\"\n",
    "can_bbox2_path = \"/Users/emilybirch/Documents/UCL_Dissertation/Data_collection/DEM/Canada/BBOX2/tifs/*.tif\"\n",
    "can_bbox3_path = \"/Users/emilybirch/Documents/UCL_Dissertation/Data_collection/DEM/Canada/BBOX2/tifs/*.tif\"\n",
    "# retrieve files with this path name and extension\n",
    "CanDEMList_1 = glob.glob(can_bbox1_path)\n",
    "CanDEMList_2 = glob.glob(can_bbox2_path)\n",
    "CanDEMList_3 = glob.glob(can_bbox3_path)\n",
    "print(CanDEMList_3)\n",
    "\n",
    "# call subprocess gdal merge to merge the DEM tiles\n",
    "cmd = \"gdal_merge.py -o mergedCanDEM1.tif\"\n",
    "subprocess.call(cmd.split()+CanDEMList_1)\n",
    "# Canada bbox2 merge\n",
    "cmd = \"gdal_merge.py -o mergedCanDEM2.tif\"\n",
    "subprocess.call(cmd.split()+CanDEMList_2)\n",
    "# Canada bbox3 merge\n",
    "cmd = \"gdal_merge.py -o mergedCanDEM3.tif\"\n",
    "subprocess.call(cmd.split()+CanDEMList_3)\n",
    "\n",
    "\n",
    "\n",
    "# France. Set path to DEM tif files\n",
    "fr_bbox1 = \"/Users/emilybirch/Documents/UCL_Dissertation/Data_collection/DEM/France/BBOX1/tifs/*.tif\"\n",
    "fr_bbox3 = \"/Users/emilybirch/Documents/UCL_Dissertation/Data_collection/DEM/France/BOX3/tifs/*.tif\"\n",
    "#retrieve files with this path name and extension\n",
    "fr_list1 = glob.glob(fr_bbox1)\n",
    "fr_list3 = glob.glob(fr_bbox3)\n",
    "\n",
    "# merge the DEM tiles. bbox1\n",
    "cmd = \"gdal_merge.py -o mergedFrDEM1.tif\"\n",
    "subprocess.call(cmd.split()+fr_list1)\n",
    "# Fr bbox3 merge\n",
    "cmd = \"gdal_merge.py -o mergedFrDEM3.tif\"\n",
    "subprocess.call(cmd.split()+fr_list3)\n",
    "\n",
    "\n",
    "\n",
    "# Alaska. Set path to DEM tif files\n",
    "alask_path1 = \"/Users/emilybirch/Documents/UCL_Dissertation/Data_collection/DEM/Alaska/BBOX1/tifs/*.tif\"\n",
    "alask_path3 = \"/Users/emilybirch/Documents/UCL_Dissertation/Data_collection/DEM/Alaska/BOX3/tifs/*.tif\"\n",
    "#retrieve files with this path name and extension\n",
    "al_DEM_list1 = glob.glob(alask_path1)\n",
    "al_DEM_list3 = glob.glob(alask_path3)\n",
    "\n",
    "# call subprocess gdal merge to merge the DEM tiles\n",
    "cmd = \"gdal_merge.py -o mergedAlDEM1.tif\"\n",
    "subprocess.call(cmd.split()+al_DEM_list1)\n",
    "# bbox3 merge\n",
    "cmd = \"gdal_merge.py -o mergedAlDEM3.tif\"\n",
    "subprocess.call(cmd.split()+al_DEM_list3)\n",
    "\n",
    "\n",
    "\n",
    "# reproject coordinate system into UTM to use metres as units \n",
    "def reproj(out_file, in_file, dstSRS):\n",
    "    gdal.Warp(out_file, in_file, dstSRS = crs)\n",
    "\n",
    "# zip over lists?\n",
    "# reproj for Canada: into EPSG:3978\n",
    "canada_reproj_list = ['mergedCanDEM1.tif', 'mergedCanDEM2.tif', 'mergedCanDEM3.tif']\n",
    "i = 0\n",
    "# for in_file in zip_longest(canada_reproj_list, fr_reproj_list,al_reproj_list,... )\n",
    "for in_file in canada_reproj_list:\n",
    "    i += 1\n",
    "    print(\"I:\", i)\n",
    "    out_file = 'reprojCanDEM_{}.tif'.format(i)\n",
    "    crs = 'EPSG:3978'\n",
    "    call = reproj(out_file, in_file, crs)\n",
    "    print(call)\n",
    "    \n",
    "    \n",
    "# France: into EPSG:23030 ED50 / UTM zone 30N\n",
    "fr_reproj_list =  ['mergedFrDEM1.tif', 'mergedFrDEM2.tif', 'mergedFrDEM3.tif']\n",
    "i = 0\n",
    "for in_file in fr_reproj_list:\n",
    "    i += 1\n",
    "    print(\"I:\", i)\n",
    "    out_file = 'reprojFrDEM_{}.tif'.format(i)\n",
    "    crs = 'EPSG:23030'\n",
    "    call = reproj(out_file, in_file, crs)\n",
    "    print(call)\n",
    " \n",
    " \n",
    "# reproj for Alaska: into EPSG:3338\n",
    "al_reproj_list = ['mergedAlDEM1.tif', 'mergedAlDEM2.tif', 'mergedAlDEM3.tif', 'mergedAlDEM4.tif']\n",
    "i = 0\n",
    "for in_file in al_reproj_list:\n",
    "    i += 1\n",
    "    print(\"I:\", i)\n",
    "    out_file = 'reprojAlDEM_{}.tif'.format(i)\n",
    "    crs = 'EPSG:3338'\n",
    "    call = reproj(out_file, in_file, crs)\n",
    "    print(call)\n",
    "    \n",
    "# reproj for Argentina: into EPSG:5343\n",
    "Arg_reproj_list = ['mergedArgDEM1.tif', 'mergedArgDEM2.tif', 'mergedArgDEM3.tif']\n",
    "i = 0\n",
    "\n",
    "for in_file in Arg_reproj_list:\n",
    "    i += 1\n",
    "    print(\"I:\", i)\n",
    "    out_file = 'reprojArgDEM_{}.tif'.format(i)\n",
    "    crs = 'EPSG:5343'\n",
    "    call = reproj(out_file, in_file, crs)\n",
    "    print(call)\n",
    "    \n",
    "    \n",
    "    \n",
    "\n",
    "# Resample to 10x10m pixel size to match Sentinel images\n",
    "def resample(out_file, in_file):\n",
    "    gdal.Warp(out_file, in_file, xRes = 10, yRes = 10, resampleAlg = \"bilinear\")\n",
    "    print(\"HI\")\n",
    "        \n",
    "\n",
    "# list the files to resample and process then in a loop \n",
    "resamp_files_list = ['reprojCanDEM_1.tif', 'reprojCanDEM_2.tif', 'reprojCanDEM_3.tif']    \n",
    "i = 0\n",
    "for in_file in resamp_files_list:\n",
    "    i += 1\n",
    "    print(\"i\", i)\n",
    "    out_file = \"resamp_Can_DEM_{}.tif\".format(i)\n",
    "    print(\"OUTfile\", out_file)\n",
    "    resample(out_file, in_file)\n",
    "            \n",
    "\n",
    "# France: resample\n",
    "resamp_list = ['reprojFrDEM_1.tif', 'reprojFrDEM_2.tif', 'reprojFrDEM_3.tif']    \n",
    "i = 0\n",
    "for in_file in resamp_list:\n",
    "    i += 1\n",
    "    print(\"i\", i)\n",
    "    out_file = \"resamp_Fr_DEM_{}.tif\".format(i)\n",
    "    print(\"OUTfile\", out_file)\n",
    "    resample(out_file, in_file)\n",
    "\n",
    "    \n",
    "# Alaska resample. \n",
    "# list of files to resample\n",
    "resamp_list = ['reprojAlDEM_1.tif', 'reprojalDEM_2.tif', 'reprojAlDEM_3.tif', 'reprojAlDEM_4.tif']    \n",
    "i = 0\n",
    "for in_file in resamp_list:\n",
    "    i += 1\n",
    "    print(\"i\", i)\n",
    "    out_file = \"resamp_Al_DEM_{}.tif\".format(i)\n",
    "    print(\"OUTfile\", out_file)\n",
    "    resample(out_file, in_file)\n",
    "\n",
    "\n",
    "\n",
    "# list the files to resample and process then in a loop \n",
    "resamp_files_list = ['reprojArgDEM_1.tif', 'reprojArgDEM_2.tif', 'reprojArgDEM_3.tif']    \n",
    "i = 0\n",
    "for in_file in resamp_files_list:\n",
    "    i += 1\n",
    "    print(\"i\", i)\n",
    "    out_file = \"resamp_Arg_DEM_{}.tif\".format(i)\n",
    "    print(\"OUTfile\", out_file)\n",
    "    resample(out_file, in_file)\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "# Crop .tif to boudning box coords\n",
    "def crop(out_file, source_file, ulx, uly, lrx, lry):\n",
    "    gdal.Translate(out_file, source_file,\n",
    "                  projWin = [ulx, uly, lrx, lry])\n",
    "  \n",
    "\n",
    " \n",
    "# Canada: crop .tif to boudning box coords\n",
    "can1crop = crop('cropCanDEM_1.tif','resamp_Can_DEM_1.tif', -1442222.5901271082, 465767.00799028383, -1425280.668026976, 437053.54995778797) \n",
    "can2crop = crop('cropCanDEM_2.tif','resamp_Can_DEM_2.tif', -1963467.662479708, 532524.2456295489, -1950948.5651828928, 502730.9493941085)  \n",
    "can3crop = crop('cropCanDEM_3.tif','resamp_Can_DEM_3.tif',-2007237.3331321548, 602651.3553773408, -1994916.2627411576, 570806.9080293514) \n",
    "       \n",
    "# France: crop .tif to boudning box coords\n",
    "Fr1crop = crop('cropFrDEM_1.tif','resamp_Can_DEM_1.tif',1246969.3962645088, 5163267.284300569,1274934.6912586447, 5143545.166937985) \n",
    "Fr2crop = crop('cropFrDEM_2.tif','resamp_Can_DEM_2.tif',1234624.7084396454, 4993062.539814649, 1261497.750934254, 4974014.1117675835)  \n",
    "Fr3crop = crop('cropFrDEM_3.tif','resamp_Can_DEM_3.tif', 1225777.8855382334, 5373591.730970369,1252683.6911129407, 5355278.076760378) \n",
    "\n",
    "# Alaska: Crop .tif to boudning box coords\n",
    "Al1crop = crop('cropAlDEM_1.tif','resamp_Al_DEM_1.tif', 514481.90383768355, 1236449.1310469457, 541830.6619147946, 1218503.1192803124) \n",
    "Al2crop = crop('cropAlDEM_2.tif','resamp_Al_DEM_2.tif', 450815.2605629388, 1223929.9128310417, 477228.41344957944, 1204727.699233261)  \n",
    "Al3crop = crop('cropAlDEM_3.tif','resamp_Al_DEM_3.tif', 397957.2487422569, 1251934.8385985517,425182.4670500502, 1234086.2585198171) \n",
    "Al4crop = crop('cropAlDEM_4.tif','resamp_Al_DEM_4.tif',393282.9896072386, 1280321.0557472059,419319.2191957479, 1261199.193909528) \n",
    "  \n",
    "\n",
    "# close datasets to read properly to disk\n",
    "#ds = dsReproj = dsResamp = dsClip = None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "438178e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot to check DEM is reprojected, resampled and cropped to bbox\n",
    "final_DEM = gdal.Open(\"cropDEM_2.tif\")\n",
    "array = final_DEM.ReadAsArray()\n",
    "plt.imshow(array)\n",
    "plt.colorbar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96a43db4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Argentina\n",
    "import os \n",
    "from osgeo import gdal\n",
    "import glob\n",
    "import subprocess\n",
    "from gdal import gdalconst\n",
    "\n",
    "\n",
    "# set directory to location of all final DEM pics \n",
    "os.chdir('/Users/emilybirch/Documents/UCL_Dissertation/Data_collection/DEM/Directory_for_DEM/Final_DEM_pics')\n",
    "os.getcwd()\n",
    "\n",
    "def crop(out_file, source_file, ulx, uly, lrx, lry):\n",
    "    gdal.Translate(out_file, source_file,\n",
    "                  projWin = [ulx, uly, lrx, lry])\n",
    "    \n",
    "  \n",
    "\n",
    "\n",
    " \n",
    "# FIX THESE- CANT CROP BC NOT IN SAME AREA?\n",
    "# Argentina: crop .tif to boudning box coords\n",
    "Ar1crop = crop('cropArgDEM_1.tif','resamp_Arg_DEM_1.tif',5998451.786827491, 1601005.619190992,5976249.0203732345, 1625961.998551086) \n",
    "Ar2crop = crop('cropArgDEM_2.tif','resamp_Arg_DEM_2.tif',5937593.134678965, 1582258.6827567841,5916218.082539896, 1605918.8959056677)\n",
    "Ar3crop = crop('cropArgDEM_3.tif','resamp_Arg_DEM_3.tif', 4676913.660264564, 1475051.4449760758, 4656287.012900037, 1499619.73136248) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87137982",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Norway\n",
    "Nor1crop = crop('cropNorDEM_1.tif','resamp_Nor_DEM_1.tif',1611541.2847414473, -1150463.0893291135,1581199.9787365836, -1136330.787145058)\n",
    "Nor2crop = crop('cropNorDEM_2.tif','resamp_Nor_DEM_2.tif',1619389.5743942696, -854804.3331045215,1591676.3046402216, -836971.2418011383)\n",
    "Nor3crop = crop('cropNorDEM_3.tif','resamp_Nor_DEM_3.tif', 1882899.119273985, -786917.6157957469,1855046.293116921, -769771.7641124884) \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fossil-tamil",
   "metadata": {},
   "outputs": [],
   "source": [
    "# use more than one channel as input into my model. use geomorphology too.\n",
    "\n",
    "# taking the TIFF data and encoding it to a TFRecords format for some machine learning in Tensorflow.  \n",
    "# take the TIFF data, convert it to 8bit format, encode it as a string and write it to TFRecords.  \n",
    "\n",
    "\n",
    "# A guide for Spectral indicies:\n",
    "# https://www.geo.university/pages/blog?p=spectral-indices-with-multispectral-satellite-data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "electoral-concept",
   "metadata": {},
   "source": [
    "I chose a region where both water and snow are present. \n",
    "This shows that when trying to isolate snow, we also isolate water. \n",
    "\n",
    "But when isolating water, we, the snow is mostly left out.\n",
    "This means that we can use both indicies to generate some training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "working-painting",
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_mask(input_image, threshold):\n",
    "    input_image[input_image <= threshold] = np.nan\n",
    "    input_image[input_image > threshold] = 1\n",
    "    return input_image\n",
    "    \n",
    "NDVI_mask = to_mask(NDVI, 0.2)\n",
    "NDSI_mask = to_mask(NDSI, 0.)\n",
    "fig, ax = plt.subplots(1, 4, figsize=(15,10))\n",
    "ax[0].set_title('NDVI Vegetation mask')\n",
    "ax[0].imshow(basemap)\n",
    "ax[0].imshow(NDVI_mask, cmap='cubehelix')\n",
    "ax[1].set_title('NDSI Snow mask')\n",
    "ax[1].imshow(basemap)\n",
    "ax[1].imshow(NDSI_mask, cmap='cubehelix')\n",
    "\n",
    "NDVI_binary_mask = np.nan_to_num(NDVI_mask)\n",
    "NDSI_binary_mask = np.nan_to_num(NDSI_mask)\n",
    "both = NDVI_binary_mask + NDSI_binary_mask\n",
    "\n",
    "ax[2].set_title('NDSI mask + NDVI mask')\n",
    "ax[2].imshow(both, cmap='cubehelix')\n",
    "\n",
    "ax[3].set_title('Snow mask - Vegetation removed')\n",
    "snow_only = both.copy()\n",
    "snow_only[snow_only == 2] = 0\n",
    "ax[3].imshow(snow_only, cmap='cubehelix')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "gorgeous-dominant",
   "metadata": {},
   "source": [
    "CNN's usually don't accept big inputs, so the image needs to be cropped into smaller samples.\n",
    "\n",
    "The bigger and more complex the CNN, the more processing power will be required, therefore the smaller the input samples will need to be. \n",
    "\n",
    "Rather than crushing the original sample, a good idea is to splice it. \n",
    "This way we get a lot more data, and the 10m resolution is maintained. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "registered-better",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "# Split the Images\n",
    "def split_image(dim_pix, im):\n",
    "    # Find the number of sub-Images that fit in rows\n",
    "    rows = []\n",
    "    tiles = []\n",
    "    for i in range((math.floor(im.shape[0] / dim_pix))):\n",
    "        rows.append(i)\n",
    "    # Find the number of sub-Images that fit in rows\n",
    "    columns = []\n",
    "    for i in range((math.floor(im.shape[1] / dim_pix))):\n",
    "        columns.append(i)\n",
    "\n",
    "    # Numerically identify the sub-Images\n",
    "    a = 0\n",
    "    for i in rows:\n",
    "        for j in columns:\n",
    "            # Check for 244 x 244 (Mask) or 244 x 244 x 3 (TC Images)\n",
    "            if (im[0 + (dim_pix * j): dim_pix + (dim_pix * j),\n",
    "                  0 + dim_pix * i: dim_pix + (dim_pix * i)].shape[0]) == dim_pix:\n",
    "                if (im[0 + (dim_pix * j): dim_pix + (dim_pix * j),\n",
    "                  0 + dim_pix * i: dim_pix + (dim_pix * i)].shape[1]) == dim_pix:\n",
    "\n",
    "                    tile = im[0 + (dim_pix * j): dim_pix + (dim_pix * j),\n",
    "                            0 + dim_pix * i: dim_pix + (dim_pix * i)]\n",
    "\n",
    "                    # Stop white tiles for positive results\n",
    "                    count = np.count_nonzero(tile == 1) == (dim_pix * dim_pix)\n",
    "                    if count:\n",
    "                        all_black = np.tile(1, (dim_pix, dim_pix))\n",
    "                        tiles.append(tile)\n",
    "                    else:\n",
    "                        tiles.append(tile)\n",
    "                    a += 1\n",
    "                else:\n",
    "                    print(\"Out of shape\")\n",
    "    return tiles\n",
    "\n",
    "input_tensor_dimensions = 50\n",
    "                    \n",
    "basemap_tiles = split_image(dim_pix=input_tensor_dimensions, im=basemap)\n",
    "label_tiles = split_image(dim_pix=input_tensor_dimensions, im=snow_only)\n",
    "\n",
    "fig, ax = plt.subplots(len(label_tiles), 2, figsize=(2 ,len(label_tiles)))\n",
    "for index in range(len(label_tiles)):\n",
    "    ax[index, 0].axis('off')\n",
    "    ax[index, 1].axis('off')\n",
    "    ax[index, 0].imshow(basemap_tiles[index])\n",
    "    ax[index, 1].imshow(label_tiles[index], cmap='Blues')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74a8ee61",
   "metadata": {},
   "outputs": [],
   "source": [
    "# EXTRA!!!!\n",
    "\n",
    "# EXTRA. func to convert bbox coords from geographic into projected system \n",
    "import os\n",
    "import pyproj\n",
    "from pyproj import Proj, transform\n",
    "\n",
    "os.environ['PROJ_NETWORK'] = 'OFF'\n",
    "\n",
    "\n",
    "def coord_conv(x1, y1, in_proj, out_proj):\n",
    "    proj = pyproj.Transformer.from_crs(in_proj, out_proj)\n",
    "    x2, y2 = proj.transform(x1, y1)\n",
    "    print((x1, y1))\n",
    "    print((x2, y2))\n",
    "    return x2,y2\n",
    "\n",
    "\n",
    " \n",
    "# 1. Canada:   #\"epsg:4326\", \"epsg:3978\"\n",
    "#can_DEM_bbox1_ulc = coord_conv(51.02521, -116.09311, 4326, 3978)\n",
    "#can_DEM_bbox1_lrc = coord_conv(50.82872, -115.73064, 4326, 3978)\n",
    "# box2\n",
    "#can_DEM_bbox2_ulc = coord_conv(49.7991, -123.27756,4326, 3978)\n",
    "#can_DEM_bbox2_lrc = coord_conv(49.60459, -122.94316,4326, 3978)\n",
    "# box3\n",
    "#can_bbox3_ulc = coord_conv(50.19571, -124.25775,4326, 3978)\n",
    "#can_bbox3_lrc = coord_conv(49.98687, -123.90537,4326, 3978)\n",
    "\n",
    "\n",
    "\n",
    "# 2. France \n",
    "# bbox 1 \n",
    "#Fr_bbox1_ulc = coord_conv(46.20907, 6.68394, 4326, 23030)\n",
    "#Fr_bbox1_lrc = coord_conv(46.00317, 7.009, 4326, 23030)\n",
    "# box2\n",
    "#Fr_bbox1_ulc = coord_conv(44.71102, 6.27264,4326, 23030)\n",
    "#Fr_bbox1_lrc = coord_conv(44.51403, 6.57913,4326, 23030)\n",
    "# box3\n",
    "#Fr_bbox1_ulc = coord_conv(48.09807, 6.75178,4326, 23030)\n",
    "#Fr_bbox1_lrc = coord_conv(47.90479, 7.07567, 4326, 23030)\n",
    "\n",
    "\n",
    "# Alaska\n",
    "#Al_bbox1_uly = coord_conv(60.78013, -144.48842,4326, 3338)\n",
    "#Al_bbox1_lrc = coord_conv(60.58568, -144.03959, 4326, 3338)\n",
    "\n",
    "#Al_bbox2_uly = coord_conv(60.74539, -145.68114, 4326, 3338)\n",
    "#Al_bbox2_lrc = coord_conv(60.54485, -145.24568, 4326, 3338)\n",
    "\n",
    "#Al_bbox3_uly = coord_conv(61.04986, -146.59057, 4326, 3338)\n",
    "#Al_bbox3_lrc = coord_conv(60.86339, -146.12749, 4326, 3338)\n",
    "\n",
    "#Al_bbox4_uly = coord_conv(61.30673, -146.61838, 4326, 3338) \n",
    "#Al_bbox4_lrc = coord_conv(61.11029, -146.17618, 4326, 3338)\n",
    "\n",
    "\n",
    "# Argentina\n",
    "#Ar_bbox1_uly = coord_conv(-36.1567, -70.87755,4326, 5343)\n",
    "#Ar_bbox1_lrc = coord_conv(-36.35381, -70.59671, 4326, 5343)\n",
    "\n",
    "#Ar_bbox2_uly = coord_conv(-36.70684, -71.0794, 4326, 5343)\n",
    "#Ar_bbox2_lrc = coord_conv(-36.89707, -70.81168, 4326, 5343)\n",
    "\n",
    "#Ar_bbox3_uly = coord_conv(-48.05909, -72.3347, 4326, 5343)\n",
    "#Ar_bbox3_lrc = coord_conv(-48.24508, -72.00512, 4326, 5343)\n",
    "\n",
    "\n",
    "# Norway. ETRS89 / UTM is the projected CRS for Norway\n",
    "Nor_bbox1_uly = coord_conv(61.39974, 6.71094,4326, 5130)\n",
    "Ar_bbox1_lrc = coord_conv(61.19466, 7.15113, 4326, 5130)\n",
    "\n",
    "Nor_bbox2_uly = coord_conv(62.31192, 11.90014, 4326, 5130)\n",
    "Ar_bbox2_lrc = coord_conv(62.12052, 12.37392, 4326, 5130)\n",
    "\n",
    "Nor_bbox3_uly = coord_conv(64.72578, 11.67157, 4326, 5130)\n",
    "Nor_bbox3_lrc = coord_conv(64.53323, 12.179, 4326, 5130)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#####################\n",
    "#can_list = []\n",
    "# [51.02521, -116.09311,(49.7991, -123.27756), (50.19571, -124.25775)]\n",
    "#x = [51.02521.....\n",
    "# y = ...\n",
    "#x.append\n",
    "#y.append\n",
    "#for coord in can_list:\n",
    "#    in_proj = 4326\n",
    "#    out_proj = 3978\n",
    "#    x1, y1 = ulc.split(',')\n",
    "#    coord_conv(x1,y1,in_proj,out_proj)\n",
    "\n",
    "\n",
    "#NZ\n",
    "#-44.42977, 168.66256\n",
    "#-44.63339, 168.99731\n",
    "\n",
    "#-44.26552, 169.14185\n",
    "#-44.45747, 169.46413\n",
    "\n",
    "#-45.37762, 167.32743\n",
    "#-45.58001, 167.63521\n",
    "\n",
    "#-44.00659, 168.70122\n",
    "#-44.19769, 169.022\n",
    "\n",
    "#EPSG:27200\n",
    "    \n",
    "    \n",
    "    \n",
    "\n",
    "# Norway\n",
    "#61.39974, 6.71094\n",
    "#61.19466, 7.15113\n",
    "\n",
    "#62.31192, 11.90014\n",
    "#62.12052, 12.37392\n",
    "\n",
    "#64.72578, 11.67157\n",
    "#64.53323, 12.179\n",
    "\n",
    "#EPSG:5776"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1793e95",
   "metadata": {},
   "outputs": [],
   "source": [
    "# reading/ writing rasters EXTRA CODE\n",
    "def access_raster(path, aoi=None):\n",
    "    \"\"\"\n",
    "    This func says if the raster is the bbox shape, then just get info,\n",
    "    if its not the bbox shape (aoi coords), then make a shape to cut the new tif to\n",
    "    \"\"\" \n",
    "    # aoi is canada_coords\n",
    "    if aoi == None:\n",
    "        with rasterio.open(path) as src:\n",
    "            array = src.read()\n",
    "            meta = src.meta\n",
    "            transform = src.meta['transform']\n",
    "            extent = src.bounds\n",
    "            extent_dims = {'north': extent.top, 'south': extent.bottom, 'west': extent.left, 'east': extent.right}\n",
    "            polygon_extent = polygon_generator(extent_dims)\n",
    "\n",
    " \n",
    "\n",
    "        return {'array': array, 'meta': meta, 'transform': transform, 'extent': extent, 'polygom':polygon_extent}\n",
    "\n",
    " \n",
    "\n",
    "    else:\n",
    "        with fiona.open(aoi, \"r\") as shapefile:\n",
    "            shapes = [feature[\"geometry\"] for feature in shapefile]\n",
    "\n",
    " \n",
    "\n",
    "        with rasterio.open(path) as src:\n",
    "            array, transform = rasterio.mask.mask(src, shapes, crop=True)\n",
    "            meta = src.meta\n",
    "            extent = src.bounds\n",
    "        return {'array': array, 'meta': meta, 'transform': transform, 'extent': extent}\n",
    "\n",
    "\n",
    "    \n",
    "def write_single_channel_gtiff(raster, transform, meta,  out_path):\n",
    "    assert len(raster.shape) == 2\n",
    "    print(f'Writing...{out_path}')\n",
    "    with rasterio.open(str(out_path),\n",
    "                       mode='w',\n",
    "                       crs=meta['crs'],\n",
    "                       driver=meta['driver'],\n",
    "                       nodata=np.nan,\n",
    "                       dtype=meta['dtype'],\n",
    "                       count=meta['count'],\n",
    "                       height=raster.shape[0],\n",
    "                       width=raster.shape[1],\n",
    "                       transform=transform\n",
    "                       ) as dst:\n",
    "        dst.write(raster, 1)\n",
    "        \n",
    "    \n",
    "    \n",
    "##############\n",
    "From raster.crs import CRS\n",
    "\n",
    "def get_raster_info(raster):\n",
    "    data_type = raster.dtype\n",
    "    print(data_type)\n",
    "    dim = raster.shape\n",
    "    print(dim)\n",
    "    height = dim[1]\n",
    "    width = dim[2]\n",
    "\n",
    "    \n",
    "\n",
    "transform=from_bounds(w2, s2, e2, n2, width, height)\n",
    "\n",
    "\n",
    "#With raster.open(“./output.tif”, “w”, \n",
    "#    driver = driver,\n",
    "#    height = height,\n",
    "#    width = width,\n",
    "#    count = count,\n",
    "#    typed = dtype,\n",
    "#    crs = crs,\n",
    "#    transform = transform) as dst:\n",
    "#dst.write(array)\n",
    "\n",
    "###################\n",
    "\n",
    "\n",
    "transform=from_bounds(w2, s2, e2, n2, width, height)\n",
    "# rasterio.transform.from_bounds(west, south, east, north, width, height)\n",
    "\n",
    "crs_img='EPSG:4326'\n",
    "\n",
    "from rasterio.transform import from_bounds\n",
    "with rasterio.open('test1.tif', \n",
    "                    'w',\n",
    "                    driver='GTiff',\n",
    "                    height=NDSI.shape[0],\n",
    "                    width=NDSI.shape[1],\n",
    "                    count=1,\n",
    "                    dtype=NDSI.dtype,\n",
    "                    crs=crs_img,\n",
    "                    nodata=None, # change if data has nodata value\n",
    "                    transform=transform) as dst:\n",
    "        dst.write(ndvi, 1)\n",
    " \n",
    "\n",
    "\n",
    " \n",
    "################\n",
    "# write an array into a new single band .tiff\n",
    "with rasterio.Env():\n",
    "    # write an array as a raster band to a new 8bit file\n",
    "    profile.update(\n",
    "        dtype=rasterio.unit8,\n",
    "        count=1,\n",
    "        compress='lzw')\n",
    "    \n",
    "    with rasterio.open('example.tif', 'w', **profile) as dst:\n",
    "        dst.write(array.astype(rasterio.unit8), 1) \n",
    "        \n",
    "        \n",
    "        \n",
    "############        \n",
    "import gdal\n",
    "# read raster\n",
    "gdal.AllRegister()\n",
    "inRaster ='input raster'\n",
    "inDS=gdal.Open(inRaster,1)\n",
    "geoTransform = inDs.GetGeoTransform()\n",
    "band=inDS.GetRasterBand(1)\n",
    "datatype=band.DataType\n",
    "proj=inDS.GetProjection()\n",
    "        \n",
    "# write raster\n",
    "driver = inDS.GetDriver()\n",
    "outDS= driver.Create(outRaster,No_cols,No_rows,1,datatype)\n",
    "geoTransform = inDS.GetGeoTransform()\n",
    "outDS.SetProjection(proj)\n",
    "outBand=outDS.GetRasterBand(1)\n",
    "# data is the output array written in.tiff file\n",
    "outBand.WriteArray(data,0,0)\n",
    "outDS=None\n",
    "\n",
    "            \n",
    "############\n",
    "from osgeo import gdal\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# import \n",
    "ds = gdal.Open(\"dem.tif\")\n",
    "gt = ds.GetGeoTransform()\n",
    "proj = ds.GetProjection()\n",
    "\n",
    "band = ds.GetRasterBand(1)\n",
    "array = band.ReadAsArray()\n",
    "\n",
    "plt.figure()\n",
    "plt.imshow(array)\n",
    "\n",
    "# manipulate\n",
    "#binmask = np.where((array \\&gt = np.mean(array)),1,0)\n",
    "#plt.figure()\n",
    "#plt.imshow(binmask)\n",
    "\n",
    "# export\n",
    "driver = gdal.GetDriverByName(\"GTiff\")\n",
    "driver.Register()\n",
    "outds = driver.Create(\"output.tif\", xsize = array.shape[1],\n",
    "                      ysize = array.shape[0], bands = 1, \n",
    "                      eType = gdal.GDT_Int16) # GDT_Byte \n",
    "outds.SetGeoTransform(gt)\n",
    "outds.SetProjection(proj)\n",
    "outband = outds.GetRasterBand(1)\n",
    "outband.WriteArray(array)\n",
    "outband.SetNoDataValue(np.nan)\n",
    "outband.FlushCache()\n",
    "\n",
    "# close your datasets and bands!!!\n",
    "outband = None\n",
    "outds = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb806efb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# EXTRA FOR resample raster\n",
    "# upsampling refers to cases where we are converting to higher resolution/smaller cells.\n",
    "# nearest neighbour method of resampling is not suitable for continuous data i.e. DEM\n",
    "# use bilinear instead \n",
    "\n",
    "import rasterio\n",
    "from rasterio.enums import Resampling\n",
    "\n",
    "upscale_factor = 3\n",
    "\n",
    "with rasterio.open(\"mergedCanDEM1.tif\") as dataset:\n",
    "\n",
    "    # resample data to target shape\n",
    "    data = dataset.read(\n",
    "        out_shape=(\n",
    "            dataset.count,\n",
    "            int(dataset.height * upscale_factor),\n",
    "            int(dataset.width * upscale_factor)\n",
    "        ),\n",
    "        resampling=Resampling.bilinear\n",
    "    )\n",
    "\n",
    "    # scale image transform\n",
    "    transform = dataset.transform * dataset.transform.scale(\n",
    "        (dataset.width / data.shape[-1]),\n",
    "        (dataset.height / data.shape[-2])\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4629f7be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# EXTRA FOR PLOTTING/ SAVING BAND AS PNG\n",
    "\n",
    "\n",
    "      # extra to plot the NDSI and NIR  \n",
    "      #  for channels in bands:\n",
    "       #     i += 1\n",
    "       #     print(\"i\", i)\n",
    "          #  fig, ax = plt.subplots(2, 6, figsize=(15,10))\n",
    "          #  ax[0, 2].imshow(b03, cmap='cubehelix')\n",
    "          #  ax[0, 2].set_title('Green')\n",
    "          #  ax[1, 0].imshow(b08, cmap='cubehelix')\n",
    "          #  ax[1, 0].set_title('Vegetation Red Edge ')\n",
    "          #  ax[1, 3].imshow(b11, cmap='cubehelix')\n",
    "          #  ax[1, 3].set_title('SWIR')\n",
    "          #  ax[1, 3].axis('off')\n",
    "\n",
    "        #    os.chdir('/Users/emilybirch/Documents/UCL_Dissertation/Data_collection/WMS_all_bands')\n",
    "        #    plt.savefig(\"can_bands_{}.tif\".format(i),\n",
    "        #                bbox_inches='tight',\n",
    "        #                    dpi=600)\n",
    "\n",
    "         #   plt.show()\n",
    "       \n",
    "\n",
    "      \n",
    " #   def calc_ndsi(self, b03, b11, bands):\n",
    "        \"\"\"\n",
    "        Plot ndsi using certain bands\n",
    "        EXPORT AS PNG\n",
    "        \"\"\"\n",
    "       # NDVI = (b04 – b03) / (b04 + b03)       \n",
    "        # plot true colour image:\n",
    "       # ax[0].imshow(basemap)\n",
    "       # ax[0].set_title('True Colour Composite')  \n",
    "        # Normalised difference snow index \n",
    "    \n",
    "  #      os.chdir('/Users/emilybirch/Documents/UCL_Dissertation/Data_collection/NDSI')\n",
    "  #      i = 0\n",
    "  #      NDSI = (b03 - b11)/(b03 + b11)\n",
    "  #      for ndsi_im in bands:\n",
    "  #          i += 1\n",
    "        #   ndsi_im = Image.fromarray(NDSI) #.save('can_NDSI_{}.tif'.format(i)) # NDSI.astype(np.uint8)\n",
    " #           fig, ax = plt.subplots(1, 1, figsize=(15,10))\n",
    "  #          plt.imshow(NDSI, cmap='Blues')\n",
    "   #         plt.axis('off')            \n",
    "   ##         plt.savefig('can_NDSI_{}.tif'.format(i),\n",
    "   #                     bbox_inches='tight', dpi=600, format=\"tiff\")\n",
    "   #         plt.show()  "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
